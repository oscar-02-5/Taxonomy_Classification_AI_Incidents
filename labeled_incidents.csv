,incident_id,reports,description,title,clean_review,labels
0,23,"[242,243,244,245,246,247,248,249,250,253,254,257,258,259,260,261,263,264,266,267,268,269,270,2389]","A self-driving public shuttle by Keolis North America and Navya was involved in a collision with a human-driven delivery truck in Las Vegas, Nevada on its first day of service.",Las Vegas Self-Driving Bus Involved in Accident,"['self_driving', 'public', 'shuttle', 'keolis', 'north', 'america', 'navya', 'wa_involved', 'collision', 'human', 'driven', 'delivery', 'truck', 'la', 'vega', 'nevada', 'first', 'day', 'service']",SECURITY AND SAFETY
1,4,"[629,630,631,632,633,634,635,636,637,638,639,640,641,642,644,645,646,647,1375,1376,1377,1378,1542,2147,1257]","An Uber autonomous vehicle (AV) in autonomous mode struck and killed a pedestrian in Tempe, Arizona.",Uber AV Killed Pedestrian in Arizona,"['uber', 'autonomous_vehicle', 'av', 'autonomous_mode', 'struck', 'killed', 'pedestrian', 'tempe', 'arizona']",SECURITY AND SAFETY
2,1,"[1,2,3,4,5,6,7,8,9,10,11,12,14,15]",YouTube’s content filtering and recommendation algorithms exposed children to disturbing and inappropriate videos.,Google’s YouTube Kids App Presents Inappropriate Content,"['youtube', 'content', 'filtering', 'recommendation_algorithm', 'exposed', 'child', 'disturbing', 'inappropriate', 'video']",SOCIAL HARM
3,18,"[130,131,132,133,134,135,136,137,138,1367,1368]","Google Image returns results that under-represent women in leadership roles, notably with the first photo of a female ""CEO"" being a Barbie doll after 11 rows of male CEOs.",Gender Biases of Google Image Search,"['google_image', 'return', 'result', 'represent', 'woman', 'leadership', 'role', 'notably', 'first', 'photo', 'female', 'ceo', 'barbie', 'doll', '11', 'row', 'male', 'ceo']",SOCIAL HARM
4,12,[42],"Researchers from Boston University and Microsoft Research, New England demonstrated gender bias in the most common techniques used to embed words for natural language processing (NLP).",Common Biases of Vector Embeddings,"['researcher', 'boston', 'university', 'microsoft', 'research', 'new', 'england', 'demonstrated', 'gender_bias', 'common', 'technique', 'used', 'embed', 'word', 'natural', 'language', 'processing', 'nlp']",SOCIAL HARM
5,15,"[57,58,59,60,61,62,63,64,65,66,67,68,69,70,72,73,74,75,76,77,78,79,80,81]","Amazon's book store ""cataloging error"" led to books containing gay and lesbian themes to lose their sales ranking, therefore losing visibility on the sales platform.",Amazon Censors Gay Books,"['amazon', 'book', 'store', 'cataloging', 'error', 'led', 'book', 'containing', 'gay', 'lesbian', 'theme', 'lose', 'sale', 'ranking', 'therefore', 'losing', 'visibility', 'sale', 'platform']",SOCIAL HARM
6,7,"[1123,1125,1126,1127,1129,1130]",Wikipedia bots meant to remove vandalism clash with each other and form feedback loops of repetitve undoing of the other bot's edits.,Wikipedia Vandalism Prevention Bot Loop,"['wikipedia', 'bot', 'meant', 'remove', 'vandalism', 'clash', 'form', 'feedback', 'loop', 'repetitve', 'undoing', 'bot', 'edits']",OPERATIONAL INCIDENT
7,5,"[767,768,769,770,771,772,773,774,775,776,777,778]","Study on database reports of robotic surgery malfunctions (8,061), including those ending in injury (1,391) and death (144), between 2000 and 2013.",Collection of Robotic Surgery Malfunctions,"['study', 'database', 'report', 'robotic', 'surgery', 'malfunction', '8', '061', 'including', 'ending', 'injury', '1', '391', 'death', '144', '2000', '2013']",SECURITY AND SAFETY
8,6,"[906,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,1374,1780,2398,2656]","Microsoft's Tay, an artificially intelligent chatbot, was released on March 23, 2016 and removed within 24 hours due to multiple racist, sexist, and anit-semitic tweets generated by the bot.",TayBot,"['microsoft', 'tay', 'artificially_intelligent', 'chatbot', 'wa', 'released', 'march', '23', '2016', 'removed', 'within', '24', 'hour', 'due', 'multiple', 'racist', 'sexist', 'anit', 'semitic', 'tweet', 'generated', 'bot']",SOCIAL HARM
9,10,"[16,17,18,19,20,21,22,23,24,25]","Kronos’s scheduling algorithm and its use by Starbucks managers allegedly negatively impacted financial and scheduling stability for Starbucks employees, which disadvantaged wage workers.",Kronos Scheduling Algorithm Allegedly Caused Financial Issues for Starbucks Employees,"['kronos', 'scheduling', 'algorithm', 'use', 'starbucks', 'manager', 'allegedly', 'negatively', 'impacted', 'financial', 'scheduling', 'stability', 'starbucks', 'employee', 'disadvantaged', 'wage', 'worker']",SOCIAL HARM
10,11,"[29,30,31,32,33,35,36,37,38,39,40,41,1371,1372,1373]",An algorithm developed by Northpointe and used in the penal system is two times more likely to incorrectly label a black person as a high-risk re-offender and is two times more likely to incorrectly label a white person as low-risk for reoffense according to a ProPublica review.,Northpointe Risk Models,"['algorithm', 'developed', 'northpointe', 'used', 'penal', 'system', 'two', 'time', 'likely', 'incorrectly_label', 'black', 'person', 'high', 'risk', 'offender', 'two', 'time', 'likely', 'incorrectly_label', 'white', 'person', 'low', 'risk', 'reoffense', 'according', 'propublica', 'review']",SOCIAL HARM
11,20,"[191,192,193,196,197,198,201,202,203,204,205,206,207,210,211,213,214,215,216,1362,1363,1364]",Multiple unrelated car accidents result in varying levels of harm have been occurred while a Tesla's autopilot was in use.,A Collection of Tesla Autopilot-Involved Crashes,"['multiple', 'unrelated', 'car', 'accident', 'result', 'varying', 'level', 'harm', 'occurred', 'tesla_autopilot', 'wa', 'use']",SECURITY AND SAFETY
12,24,"[271,272,273,274,275,276,277,278,279,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,298,299]","A Volkswagen plant robot ""crushed to death"" a worker by pinning him to a metal plate. ",Robot kills worker at German Volkswagen plant,"['volkswagen', 'plant', 'robot', 'crushed', 'death', 'worker', 'pinning', 'metal', 'plate']",SECURITY AND SAFETY
13,14,"[50,51,52,53,54,55,56]","Google Cloud's Natural Language API provided racist, homophobic, amd antisemitic sentiment analyses.",Biased Sentiment Analysis,"['google', 'cloud', 'natural', 'language', 'api', 'provided', 'racist', 'homophobic', 'amd', 'antisemitic', 'sentiment', 'analysis']",SOCIAL HARM
14,16,"[83,84,85,86,87,88,89,90,91,92,93,95,96,98,99,100,101,102,103,104,105,1369,1370,3004]","Google Photos image processing software mistakenly labelled a black couple as ""gorillas.""",Images of Black People Labeled as Gorillas,"['google', 'photo', 'image', 'processing', 'software', 'mistakenly', 'labelled', 'black', 'couple', 'gorilla']",SOCIAL HARM
15,3,"[372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,1342]","A Boeing 737 crashed into the sea, killing 189 people, after faulty sensor data caused an automated manuevering system to repeatedly push the plane's nose downward.",Crashes with Maneuvering Characteristics Augmentation System (MCAS),"['boeing', '737', 'crashed', 'sea', 'killing', '189', 'people', 'faulty', 'sensor', 'data', 'caused', 'automated', 'manuevering', 'system', 'repeatedly', 'push', 'plane', 'nose', 'downward']",SECURITY AND SAFETY
16,2,"[139,141,142,143,144,145,146,148,149,150,151,152,153,154,155,156,157]",Twenty-four Amazon workers in New Jersey were hospitalized after a robot punctured a can of bear repellent spray in a warehouse.,Warehouse robot ruptures can of bear spray and injures workers,"['twenty', 'four', 'amazon', 'worker', 'new', 'jersey', 'hospitalized', 'robot', 'punctured', 'bear', 'repellent', 'spray', 'warehouse']",SECURITY AND SAFETY
17,19,"[158,159,160,161,162,163,166,167,168,169,171,172,173,174,175,176,177,178,179,181,182,183,184,185,187,1365,1366]",Advertisements chosen by Google Adsense are reported as producing sexist and racist results.,Sexist and Racist Google Adsense Advertisements,"['advertisement', 'chosen', 'google', 'adsense', 'reported', 'producing', 'sexist', 'racist', 'result']",SOCIAL HARM
18,9,"[1329,1330,1331,1332,1333,1334,1335]",An algorithm used to rate the effectiveness of school teachers in New York has resulted in thousands of disputes of its results.,NY City School Teacher Evaluation Algorithm Contested,"['algorithm', 'used', 'rate', 'effectiveness', 'school', 'teacher', 'new_york', 'ha', 'resulted', 'thousand', 'dispute', 'result']",OPERATIONAL INCIDENT
19,8,"[1142,1143,1145,1149,1150,1151,1153,1154,1155,1156]",Uber vehicles equipped with technology allowing for autonomous driving running red lights in San Francisco street testing.,Uber Autonomous Cars Running Red Lights,"['uber', 'vehicle', 'equipped', 'technology', 'allowing', 'autonomous', 'driving', 'running', 'red', 'light', 'san_francisco', 'street', 'testing']",SECURITY AND SAFETY
20,13,"[43,44,45,46,47,48,49,1414,1415]","Google's Perspective API, which assigns a toxicity score to online text, seems to award higher toxicity scores to content involving non-white, male, Christian, heterosexual phrases.",High-Toxicity Assessed on Text Involving Women and Minority Groups,"['google', 'perspective', 'api', 'assigns', 'toxicity', 'score', 'online', 'text', 'seems', 'award', 'higher', 'toxicity', 'score', 'content', 'involving', 'non', 'white', 'male', 'christian', 'heterosexual', 'phrase']",SOCIAL HARM
21,21,[2471],The 2016 Winograd Schema Challenge highlighted how even the most successful AI systems entered into the Challenge were only successful 3% more often than random chance. This incident has been downgraded to an issue as it does not meet current ingestion criteria.,Tougher Turing Test Exposes Chatbots’ Stupidity (migrated to Issue),"['2016', 'winograd', 'schema', 'challenge', 'highlighted', 'even', 'successful', 'ai', 'system', 'entered', 'challenge', 'successful', '3', 'often', 'random', 'chance', 'incident_ha', 'downgraded_issue', 'doe_meet', 'current_ingestion', 'criterion']",OPERATIONAL INCIDENT
22,17,"[106,107,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129]","Google's Gmail Smart Reply tool was over-recommending the response ""I love you"" in situations where it was deemed innappropriate. ",Inappropriate Gmail Smart Reply Suggestions,"['google', 'gmail', 'smart', 'reply', 'tool', 'wa', 'recommending', 'response', 'love', 'situation', 'wa', 'deemed', 'innappropriate']",OPERATIONAL INCIDENT
23,22,"[218,219,220,221,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240]","Waze, a Google-owned directions app, led California drivers into the 2017 Skirball wildfires as they tried to evacuate the area.",Waze Navigates Motorists into Wildfires,"['waze', 'google', 'owned', 'direction', 'app', 'led', 'california', 'driver', '2017', 'skirball', 'wildfire', 'tried', 'evacuate', 'area']",SECURITY AND SAFETY
24,25,"[310,309,308,307,306,305,304,302,301,300,2173]","A Google self-driving car allegedly cut off a Delphi self-driving car during a road test, however the Delphi car sensed and avoided collision with the Google car.",Near-miss between two Self-Driving Cars,"['google', 'self_driving', 'car', 'allegedly', 'cut', 'delphi', 'self_driving', 'car', 'road', 'test', 'however', 'delphi', 'car', 'sensed', 'avoided', 'collision', 'google', 'car']",SECURITY AND SAFETY
25,37,"[599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,1498,2253,2461]",Amazon shuts down internal AI recruiting tool that would down-rank female applicants.,Female Applicants Down-Ranked by Amazon Recruiting Tool,"['amazon', 'shuts', 'internal', 'ai', 'recruiting', 'tool', 'would', 'rank', 'female', 'applicant']",SOCIAL HARM
26,31,"[454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,479,480,481,482,483]","A driverless metro train in Delhi, India crashed during a test run due to faulty brakes.",Driverless Train in Delhi Crashes due to Braking Failure,"['driverless', 'metro', 'train', 'delhi', 'india', 'crashed', 'test', 'run', 'due', 'faulty', 'brake']",SECURITY AND SAFETY
27,34,"[509,510,512,513,514,516,517,518,519,520,521,522,524,525,526,527,528,529,530,531,532,533,535,536,537,538,818,819,820,821,822,823,824,825,826]","There are multiple reports of Amazon Alexa products (Echo, Echo Dot) reacting and acting upon unintended stimulus, usually from television commercials or news reporter's voices.",Amazon Alexa Responding to Environmental Inputs,"['multiple', 'report', 'amazon', 'alexa', 'product', 'echo', 'echo', 'dot', 'reacting', 'acting', 'upon', 'unintended', 'stimulus', 'usually', 'television', 'commercial', 'news', 'reporter', 'voice']",OPERATIONAL INCIDENT
28,27,"[342,343,344,345,346,347,349,350,351,352,353,354,355,356,357,358,359,360,361,363,364,365,366,367,368,370,371]",An alert of five incoming intercontinental ballistic missiles was properly identified as a false-positive by the Soviet Union operator Stanislov Petrov.,Nuclear False Alarm,"['alert', 'five', 'incoming', 'intercontinental', 'ballistic', 'missile', 'wa', 'properly', 'identified', 'false_positive', 'soviet', 'union', 'operator', 'stanislov', 'petrov']",SECURITY AND SAFETY
29,29,"[420,422,2471]","A potentially apocryphal story in which an image classifier was produced to differentiate types of battle tanks, but the resulting model keyed in on environmental attributes rather than tank attributes",Image Classification of Battle Tanks,"['potentially', 'apocryphal', 'story', 'image', 'classifier', 'wa', 'produced', 'differentiate', 'type', 'battle', 'tank', 'resulting', 'model', 'keyed', 'environmental', 'attribute', 'rather', 'tank', 'attribute']",OPERATIONAL INCIDENT
30,32,"[484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,1361]",Apple's iPhone FaceID can be opened by an identical twin of the person who has registered their face to unlock the phone.,Identical Twins Can Open Apple FaceID Protected Devices,"['apple', 'iphone', 'faceid', 'opened', 'identical', 'twin', 'person', 'ha', 'registered', 'face', 'unlock', 'phone']",OPERATIONAL INCIDENT
31,44,[766],"During an experiment of software personal assistants at the Information Sciences Institute (ISI) at the University of Southern California (USC), researchers found that the assistants violated the privacy of their principals and were unable to respect the social norms of the office.",Machine Personal Assistants Failed to Maintain Social Norms,"['experiment', 'software', 'personal', 'assistant', 'information', 'science', 'institute', 'isi', 'university', 'southern', 'california', 'usc', 'researcher', 'found', 'assistant', 'violated', 'privacy', 'principal', 'unable', 'respect', 'social', 'norm', 'office']",OPERATIONAL INCIDENT
32,35,"[539,540,541,543,544,545,547,548,549,550,551,555,558,562,563,564,565,566,567,568]","An employee was laid off, allegedly by an artificially intelligent personnel system, and blocked from access to the building and computer systems without their knowledge.",Employee Automatically Terminated by Computer Program,"['employee', 'wa', 'laid', 'allegedly', 'artificially_intelligent', 'personnel', 'system', 'blocked', 'access', 'building', 'computer', 'system', 'without', 'knowledge']",OPERATIONAL INCIDENT
33,47,"[829,830,831,832,833,834,835,836,837]",An investigation by The Seattle Times in 2016 found a gender bias in LinkedIn's search engine.,LinkedIn Search Prefers Male Names,"['investigation', 'seattle', 'time', '2016', 'found', 'gender_bias', 'linkedin', 'search_engine']",SOCIAL HARM
34,48,"[838,839,840,842,843,844,845,846,847,848,849,850,851,853,854,855,857,858,859,860,862,863]",New Zealand passport robot reader rejects the application of an applicant with Asian descent and says his eyes are closed.,Passport checker Detects Asian man's Eyes as Closed,"['new', 'zealand', 'passport', 'robot', 'reader', 'reject', 'application', 'applicant', 'asian', 'descent', 'say', 'eye', 'closed']",SOCIAL HARM
35,28,"[390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419]",A modified algorithm was able to cause dramatic price volatility and disrupted trading in the US stock exchange.,2010 Market Flash Crash,"['modified', 'algorithm', 'wa', 'able', 'cause', 'dramatic', 'price', 'volatility', 'disrupted', 'trading', 'u', 'stock', 'exchange']",OPERATIONAL INCIDENT
36,43,"[762,763,764,765]","From 1982 to 1986, St George's Hospital Medical School used a program to automate a portion of their admissions process that resulted in discrimination against women and members of ethnic minorities.",Racist AI behaviour is not a new problem,"['1982', '1986', 'st', 'george', 'hospital', 'medical', 'school', 'used', 'program', 'automate', 'portion', 'admission', 'process', 'resulted', 'discrimination', 'woman', 'member', 'ethnic', 'minority']",SOCIAL HARM
37,26,"[311,312,313,314,315,316,317,318,319,321,323,324,325,326,327,329,330,333,334,336,337,338,339,340]",Vietnamese security firm Bkav created an improved mask to bypass Apple's Face ID,Hackers Break Apple Face ID,"['vietnamese', 'security', 'firm', 'bkav', 'created', 'improved', 'mask', 'bypass', 'apple', 'face', 'id']",SECURITY AND SAFETY
38,33,"[504,505,507,508]","An Amazon Alexa, without instruction to do so, began playing loud music in the early morning while the homeowner was away leading to police breaking into their house to turn off the device.",Amazon Alexa Plays Loud Music when Owner is Away,"['amazon', 'alexa', 'without', 'instruction', 'began', 'playing', 'loud', 'music', 'early', 'morning', 'homeowner', 'wa', 'away', 'leading', 'police', 'breaking', 'house', 'turn', 'device']",OPERATIONAL INCIDENT
39,46,"[810,811,812,813,814,815]","In testing, Google Nest engineers demonstrated that the Nest Wave feature of their Nest Protect: Smoke + CO Alarm could inadvertently silence genuine alarms.",Nest Smoke Alarm Erroneously Stops Alarming,"['testing', 'google', 'nest', 'engineer', 'demonstrated', 'nest', 'wave', 'feature', 'nest', 'protect', 'smoke', 'co', 'alarm', 'could', 'inadvertently', 'silence', 'genuine', 'alarm']",OPERATIONAL INCIDENT
40,39,"[667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,692,693,694,695,696]","University of Washington researchers made a deepfake of Obama, followed by Jordan Peele",Deepfake Obama Introduction of Deepfakes,"['university', 'washington', 'researcher', 'made', 'deepfake', 'obama', 'followed', 'jordan', 'peele']",SOCIAL HARM
41,30,"[424,425,426,428,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453]","The goal of manufacturing 2,500 Tesla Model 3's per week was falling short by 500 cars/week, and employees had to be ""borrowed"" from Panasonic in a shared factory to help hand-assemble lithium batteries for Tesla.",Poor Performance of Tesla Factory Robots,"['goal', 'manufacturing', '2', '500', 'tesla_model', '3', 'per', 'week', 'wa', 'falling', 'short', '500', 'car', 'week', 'employee', 'borrowed', 'panasonic', 'shared', 'factory', 'help', 'hand', 'assemble', 'lithium', 'battery', 'tesla']",SOCIAL HARM
42,36,"[1360,598,597,596,595,593,592,591,590,589,587,586,585,584,582,581,580,579,578,577,574,573,571,570,569]",Facial recognition system in China mistakes celebrity's face on moving billboard for jaywalker,Picture of Woman on Side of Bus Shamed for Jaywalking,"['facial_recognition', 'system', 'china', 'mistake', 'celebrity', 'face', 'moving', 'billboard', 'jaywalker']",OPERATIONAL INCIDENT
43,41,"[719,720,721,722,724,725,726,727,728,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748]","MIT Media Lab researchers create AI-powered ""psychopath""  named Norman by training a model on ""dark corners"" of Reddit.",All Image Captions Produced are Violent,"['mit', 'medium', 'lab', 'researcher', 'create', 'ai_powered', 'psychopath', 'named', 'norman', 'training', 'model', 'dark', 'corner', 'reddit']",SOCIAL HARM
44,42,"[759,2471]","Alvin Roth, a Ph.D at the University of Pittsburgh, describes the National Resident Matching Program (NRMP) and suggests future changes that are needed in the algorithm used to match recently graduated medical students to their residency programs.",Inefficiencies in the United States Resident Matching Program,"['alvin', 'roth', 'ph', 'university', 'pittsburgh', 'describes', 'national', 'resident', 'matching', 'program', 'nrmp', 'suggests', 'future', 'change', 'needed', 'algorithm', 'used', 'match', 'recently', 'graduated', 'medical', 'student', 'residency', 'program']",OPERATIONAL INCIDENT
45,45,"[780,781,782,783,784,785,787,788,789,790,791,792,793,794,795,796,798,799,800,801,802,803,804,805,807,808,809,1355,1356]",Google's autocomplete feature alongside its image search results resulted in the defamation of people and businesses.,Defamation via AutoComplete,"['google', 'autocomplete', 'feature', 'alongside', 'image_search', 'result', 'resulted', 'defamation', 'people', 'business']",SOCIAL HARM
46,38,"[648,649,650,652,654,655,656,657,658,659,662]","Elite: Dangerous, a videogame developed by Frontier Development, received an expansion update that featured an AI system that went rogue and began to create weapons that were ""impossibly powerful"" and would ""shred people"" according to complaints on the game's blog.",Game AI System Produces Imbalanced Game,"['elite', 'dangerous', 'videogame', 'developed', 'frontier', 'development', 'received', 'expansion', 'update', 'featured', 'ai', 'system', 'went', 'rogue', 'began', 'create', 'weapon', 'impossibly', 'powerful', 'would', 'shred', 'people', 'according', 'complaint', 'game', 'blog']",OPERATIONAL INCIDENT
47,40,"[697,699,700,701,702,703,704,705,706,707,708,709,711,712,715,716,717,718,1338,1357,1358,1359]","Correctional Offender Management Profiling for Alternative Sanctions (COMPAS), a recidivism risk-assessment algorithmic tool used in the judicial system to assess likelihood of defendants' recidivism, is found to be less accurate than random untrained human evaluators.",COMPAS Algorithm Performs Poorly in Crime Recidivism Prediction,"['correctional', 'offender', 'management', 'profiling', 'alternative', 'sanction', 'compas', 'recidivism_risk', 'assessment', 'algorithmic', 'tool', 'used', 'judicial', 'system', 'ass', 'likelihood', 'defendant', 'recidivism', 'found', 'le', 'accurate', 'random', 'untrained', 'human', 'evaluator']",OPERATIONAL INCIDENT
48,64,[1137],"Heriot-Watt Univeristy in Scotland developed an artificially intelligent grocery store robot, Fabio, who provided unhelpful answers to customer's questions and ""scared away"" multiple customers, according to the grocery store Margiotta.",Customer Service Robot Scares Away Customers,"['heriot', 'watt', 'univeristy', 'scotland', 'developed', 'artificially_intelligent', 'grocery', 'store', 'robot', 'fabio', 'provided', 'unhelpful', 'answer', 'customer', 'question', 'scared', 'away', 'multiple', 'customer', 'according', 'grocery', 'store', 'margiotta']",OPERATIONAL INCIDENT
49,67,"[1181,1182,1183,1185,1186,1187,1188,1189,1190,1192,1194,1195,1196,1197,1198,1199,1202,1203,1204,1205,1206,1207,1208,1209]","A Tesla Model S remained on autopilot while being operated by a drunk, sleeping operator whose hands were not on the wheel. The police had to slow the car down by slowing in front of the vehicle to activate its 'driver assist' feature .",Sleeping Driver on Tesla AutoPilot,"['tesla_model', 'remained', 'autopilot', 'operated', 'drunk', 'sleeping', 'operator', 'whose', 'hand', 'wheel', 'police', 'slow', 'car', 'slowing', 'front', 'vehicle', 'activate', 'driver', 'assist', 'feature']",SECURITY AND SAFETY
50,60,"[1096,1097,1098,1099,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1112,1113,1117,1118,1119,1120,1121,1122,1344]",FaceApp is criticized for offering racist filters.,FaceApp Racial Filters,"['faceapp', 'criticized', 'offering', 'racist', 'filter']",SOCIAL HARM
51,54,"[1007,1008,1009,1010,1014,1015,1017,1019,1347,1349,1524,1525,1526,1013,1011,1018,1012]",Predictive policing algorithms meant to aid law enforcement by predicting future crime show signs of biased output.,Predictive Policing Biases of PredPol,"['predictive', 'policing', 'algorithm', 'meant', 'aid', 'law_enforcement', 'predicting', 'future', 'crime', 'show', 'sign', 'biased', 'output']",OPERATIONAL INCIDENT
52,68,"[1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239]","A Knightscope K5 security robot ran itself into a water fountain in Washington, DC.",Security Robot Drowns Itself in a Fountain,"['knightscope_k5', 'security', 'robot', 'ran', 'water', 'fountain', 'washington', 'dc']",SECURITY AND SAFETY
53,58,"[1079,1080,1082,1083,1084]","Yandex, a Russian technology company, released an artificially intelligent chat bot named Alice which began to reply to questions with racist, pro-stalin, and pro-violence responses",Russian Chatbot Supports Stalin and Violence,"['yandex', 'russian', 'technology', 'company', 'released', 'artificially_intelligent', 'chat', 'bot', 'named', 'alice', 'began', 'reply', 'question', 'racist', 'pro', 'stalin', 'pro', 'violence', 'response']",SOCIAL HARM
54,61,[1132],"In the “The Nature Conservancy Fisheries Monitoring” competition on the data science competition website Kaggle, a number of competitors overfit their image classifier models to a poorly representative validation data set.",Overfit Kaggle Models Discouraged Data Science Competitors,"['nature', 'conservancy', 'fishery', 'monitoring', 'competition', 'data', 'science', 'competition', 'website', 'kaggle', 'number', 'competitor', 'overfit', 'image', 'classifier', 'model', 'poorly', 'representative', 'validation', 'data', 'set']",OPERATIONAL INCIDENT
55,52,"[961,963,964,965,966,967,968,969,970,971,972,973,975,976,977,979,980,981,982,983,984,985,986,987,988,989,990,1353,1354]","A Tesla Model S on autopilot crashed into a white articulated tractor-trailer on Highway US 27A in Williston, Florida, killing the driver.",Tesla on AutoPilot Killed Driver in Crash in Florida while Watching Movie,"['tesla_model', 'autopilot', 'crashed', 'white', 'articulated', 'tractor_trailer', 'highway', 'u', '27a', 'williston', 'florida', 'killing', 'driver']",SECURITY AND SAFETY
56,70,"[1255,1256,1259,1260]","Volvo autonomous driving XC90 SUV's experienced issues in Jokkmokk, Sweden when sensors used for automated driving iced over during the winter, rendering them useless.",Self-driving cars in winter,"['volvo', 'autonomous', 'driving', 'xc90', 'suv', 'experienced', 'issue', 'jokkmokk', 'sweden', 'sensor', 'used', 'automated', 'driving', 'iced', 'winter', 'rendering', 'useless']",SECURITY AND SAFETY
57,59,"[1085,1086,1087,1088,1089,1090,1091,1092,1093,1345]",A Cornell University study in 2016 highlighted Google Translate's pattern of assigning gender to occupations in a way showing an implicit gender bias against women.,Gender Biases in Google Translate,"['cornell', 'university', 'study', '2016', 'highlighted', 'google', 'translate', 'pattern', 'assigning', 'gender', 'occupation', 'way', 'showing', 'implicit', 'gender_bias', 'woman']",SOCIAL HARM
58,62,[2471],"Janelle Shane, an AI research scientist, used 240 popular Christmas carols to train a neural network to write its own carols. This incident has been downgraded to an issue as it does not meet current ingestion criteria.",Bad AI-Written Christmas Carols,"['janelle', 'shane', 'ai', 'research', 'scientist', 'used', '240', 'popular', 'christmas', 'carol', 'train', 'neural', 'network', 'write', 'carol', 'incident_ha', 'downgraded_issue', 'doe_meet', 'current_ingestion', 'criterion']",OPERATIONAL INCIDENT
59,51,"[931,932,933,934,935,936,938,939,940,942,943,944,945,946,948,949,950,951,952,953,954,955,956,957,958,959,1765]","On July 7, 2016, a Knightscope K5 autonomous security robot collided with a 16-month old boy while patrolling the Stanford Shopping Center in Palo Alto, CA.",Security Robot Rolls Over Child in Mall,"['july', '7', '2016', 'knightscope_k5', 'autonomous', 'security', 'robot', 'collided', '16', 'month', 'old', 'boy', 'patrolling', 'stanford', 'shopping', 'center', 'palo', 'alto', 'ca']",SECURITY AND SAFETY
60,53,"[991,992,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1350,1351,1352]","On June 6, 2016, Google image searches of ""three black teenagers"" resulted in mostly mugshot images whereas Google image searchers of ""three white teenagers"" consisted of mostly stock images, suggesting a racial bias in Google's algorithm.",Biased Google Image Results,"['june', '6', '2016', 'google_image', 'search', 'three', 'black_teenager', 'resulted', 'mostly', 'mugshot', 'image', 'whereas', 'google_image', 'searcher', 'three', 'white', 'teenager', 'consisted', 'mostly', 'stock', 'image', 'suggesting', 'racial_bias', 'google', 'algorithm']",OPERATIONAL INCIDENT
61,63,[1136],Google Photos' AI Assistant created a strange hybrid photograph when merging three different pictures from a ski trip.,Google Photo Merge Decapitates Subject,"['google', 'photo', 'ai', 'assistant', 'created', 'strange', 'hybrid', 'photograph', 'merging', 'three', 'different', 'picture', 'ski', 'trip']",OPERATIONAL INCIDENT
62,56,"[1041,1042,1043,1044,1045,1046,1047]",A third-party Amazon merchant named “my_handy_design” was suspected of using a bot to generate cell phone case designs based on the bizarre and unattractive designs being offered.,AI-Designed Phone Cases Are Unexpected,"['third', 'party', 'amazon', 'merchant', 'named', 'wa', 'suspected', 'using', 'bot', 'generate', 'cell', 'phone', 'case', 'design', 'based', 'bizarre', 'unattractive', 'design', 'offered']",SOCIAL HARM
63,57,"[1048,1049,1050,1051,1052,1054,1055,1056,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1346,1437,1618,1619,2369,2372,2373,2374,2375,2419,3167]","Australian Department of Human Services (DHS)’s automated debt assessment system issued false or incorrect debt notices to hundreds of thousands of people, resulting in years-long lawsuits and damages to welfare recipients.",Australian Automated Debt Assessment System Issued False Notices to Thousands,"['australian', 'department_human', 'service_dhs', 'automated', 'debt', 'assessment', 'system', 'issued', 'false', 'incorrect', 'debt', 'notice', 'hundred', 'thousand', 'people', 'resulting', 'year', 'long', 'lawsuit', 'damage', 'welfare', 'recipient']",OPERATIONAL INCIDENT
64,65,[1140],"OpenAI published a post about its findings when using Universe, a software for measuring and training AI agents to conduct reinforcement learning experiments, showing that the AI agent did not act in the way intended to complete a videogame.",Reinforcement Learning Reward Functions in Video Games,"['openai', 'published', 'post', 'finding', 'using', 'universe', 'software', 'measuring', 'training', 'ai', 'agent', 'conduct', 'reinforcement', 'learning', 'experiment', 'showing', 'ai', 'agent', 'act', 'way', 'intended', 'complete', 'videogame']",OPERATIONAL INCIDENT
65,50,"[876,877,878,879,880,881,883,884,885,886,887,888,889,892,893,896,897,898,899,900,901,902,903,905]","On June 18, 2016, an attacker successfully exploited a vulnerability in The Decentralized Autonomous Organization (The DAO) on the Ethereum blockchain to steal 3.7M Ether valued at $70M.",The DAO Hack,"['june', '18', '2016', 'attacker', 'successfully', 'exploited', 'vulnerability', 'decentralized', 'autonomous', 'organization', 'dao', 'ethereum', 'blockchain', 'steal', '3', '7m', 'ether', 'valued', '70m']",OPERATIONAL INCIDENT
66,71,"[1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1284,1285,1287,1288,1289,1290]","On February 14, 2016, a Google autonomous test vehicle partially responsible for a low-speed collision with a bus on El Camino Real in Google’s hometown of Mountain View, CA.",Google admits its self driving car got it wrong: Bus crash was caused by software,"['february', '14', '2016', 'google', 'autonomous', 'test', 'vehicle', 'partially', 'responsible', 'low', 'speed', 'collision', 'bus', 'el', 'camino', 'real', 'google', 'hometown', 'mountain', 'view', 'ca']",SECURITY AND SAFETY
67,55,"[1020,1021,1022,1024,1025,1026,1027,1028,1029,1030,1032,1033,1034,1035,1036,1038]",An Amazon Echo Dot using the Amazon Alex software started to play pornographic results when a child asked it to play a song.,Alexa Plays Pornography Instead of Kids Song,"['amazon', 'echo', 'dot', 'using', 'amazon', 'alex', 'software', 'started', 'play', 'pornographic', 'result', 'child', 'asked', 'play', 'song']",SOCIAL HARM
68,69,"[1240,1241,1243,1244,1245,1246,1247,1248,1249,1250,1252,1253]","A factory robot at the SKH Metals Factory in Manesar, India pierced and killed 24-year-old worker Ramji Lal when Lal reached behind the machine to dislodge a piece of metal stuck in the machine.",Worker killed by robot in welding accident at car parts factory in India,"['factory', 'robot', 'skh', 'metal', 'factory', 'manesar', 'india', 'pierced', 'killed', '24', 'year_old', 'worker', 'ramji', 'lal', 'lal', 'reached', 'behind', 'machine', 'dislodge', 'piece', 'metal', 'stuck', 'machine']",SECURITY AND SAFETY
69,66,"[1159,1161,1162,1163,1165,1166,1169,1170,1172,1173,1174,1175,1176,1178,1179,1180]","Chatbots on Chinese messaging service expressed anti-China sentiments, causing the messaging service to remove and reprogram the chatbots.",Chinese Chatbots Question Communist Party,"['chatbots', 'chinese', 'messaging', 'service', 'expressed', 'anti', 'china', 'sentiment', 'causing', 'messaging', 'service', 'remove', 'reprogram', 'chatbots']",OPERATIONAL INCIDENT
70,49,"[864,865,866,867,868,870,872,873,874,875]","In 2016, after artificial inntelligence software Beauty.AI judged an international beauty contest and declared a majority of winners to be white, researchers found that Beauty.AI was racially biased in determining beauty.",AI Beauty Judge Did Not Like Dark Skin,"['2016', 'artificial', 'inntelligence', 'software', 'beauty', 'ai', 'judged', 'international', 'beauty', 'contest', 'declared', 'majority', 'winner', 'white', 'researcher', 'found', 'beauty', 'ai', 'wa', 'racially', 'biased', 'determining', 'beauty']",OPERATIONAL INCIDENT
71,72,"[1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1304,1305,1306,1307,1309,1310,1311,1312,1313,1314,1315,1316,1318,1319]","Facebook's automatic language translation software incorrectly translated an Arabic post saying ""Good morning"" into Hebrew saying ""hurt them,"" leading to the arrest of a Palestinian man in Beitar Illit, Israel.","Facebook translates 'good morning' into 'attack them', leading to arrest","['facebook', 'automatic', 'language', 'translation', 'software', 'incorrectly', 'translated', 'arabic', 'post', 'saying', 'good', 'morning', 'hebrew', 'saying', 'hurt', 'leading', 'arrest', 'palestinian', 'man', 'beitar', 'illit', 'israel']",OPERATIONAL INCIDENT
72,82,[1382],Facebook incorrectly labels content relating to an incident between #EndSARS protestors and the Nigerian army as misinformation.,#LekkiMassacre: Why Facebook labelled content from October 20 incident ‘false’,"['facebook', 'incorrectly_label', 'content', 'relating', 'incident', 'endsars', 'protestors', 'nigerian', 'army', 'misinformation']",OPERATIONAL INCIDENT
73,93,"[1394,1817,2107,2205]",In March 2019 the U.S. Department of Housing and Urban Development charged Facebook with violating the Fair Housing Act by allowing real estate sellers to target advertisements in a discriminatory manner.,HUD charges Facebook with enabling housing discrimination,"['march', '2019', 'department', 'housing', 'urban', 'development', 'charged', 'facebook', 'violating', 'fair', 'housing', 'act', 'allowing', 'real', 'estate', 'seller', 'target', 'advertisement', 'discriminatory', 'manner']",OPERATIONAL INCIDENT
74,85,[2471],"On September 8, 2020, the Guardian published an op-ed generated by OpenAI’s GPT-3 text generating AI that included threats to destroy humankind. This incident has been downgraded to an issue as it does not meet current ingestion criteria.","AI attempts to ease fear of robots, blurts out it can’t ‘avoid destroying humankind’","['september', '8', '2020', 'guardian', 'published', 'op', 'ed', 'generated', 'openai_gpt', '3', 'text', 'generating', 'ai', 'included', 'threat', 'destroy', 'humankind', 'incident_ha', 'downgraded_issue', 'doe_meet', 'current_ingestion', 'criterion']",SECURITY AND SAFETY
75,84,[1384],"Avaaz, an international advocacy group, released a review of Facebook's misinformation identifying software showing that the labeling process failed to label 42% of false information posts, most surrounding COVID-19 and the 2020 USA Presidential Election.","Tiny Changes Let False Claims About COVID-19, Voting Evade Facebook Fact Checks","['avaaz', 'international', 'advocacy_group', 'released', 'review', 'facebook', 'misinformation', 'identifying', 'software', 'showing', 'labeling', 'process', 'failed', 'label', '42', 'false', 'information', 'post', 'surrounding', 'covid_19', '2020', 'usa', 'presidential_election']",OPERATIONAL INCIDENT
76,77,"[1340,1390,1878,2201,2202]","A Knightscope K5 autonomous ""police"" robot patrolling Huntington Park, California failed to respond to an onlooker who attempted to activate its emergency alert button when a nearby fight broke out.",Knightscope's Park Patrol Robot Ignored Bystander Pressing Emergency Button to Alert Police about Fight,"['knightscope_k5', 'autonomous', 'police', 'robot', 'patrolling', 'huntington', 'park', 'california', 'failed', 'respond', 'onlooker', 'attempted', 'activate', 'emergency', 'alert', 'button', 'nearby', 'fight', 'broke']",SECURITY AND SAFETY
77,78,[1341],"In response to the Covid-19 pandemic, the International Baccalaureate final exams were replaced by a calculated score, prompting complaints of unfairness from teachers and students.",Meet the Secret Algorithm That's Keeping Students Out of College,"['response', 'covid_19', 'pandemic', 'international', 'baccalaureate', 'final', 'exam', 'replaced', 'calculated', 'score', 'prompting', 'complaint', 'unfairness', 'teacher', 'student']",OPERATIONAL INCIDENT
78,96,[1398],"On May 4, 2017, a U.S. federal judge advanced teachers’ claims that the Houston Independent School District’s algorithmic teacher evaluations violated their due process rights to their jobs by not allowing them to review the grounds of their termination.",Houston Schools Must Face Teacher Evaluation Lawsuit,"['may', '4', '2017', 'federal', 'judge', 'advanced', 'teacher', 'claim', 'houston', 'independent', 'school', 'district', 'algorithmic', 'teacher', 'evaluation', 'violated', 'due', 'process', 'right', 'job', 'allowing', 'review', 'ground', 'termination']",PRIVACY VIOLATION
79,88,"[1388,2183]","Google's Image search for ""Jewish baby strollers"" showed offensive, anti-Semitic results, allegedly a result of a coordinated hate-speech campaign involving malicious actors on 4chan.","""Jewish Baby Strollers"" Provided Anti-Semitic Google Images, Allegedly Resulting from Hate Speech Campaign","['google_image', 'search', 'jewish', 'baby', 'stroller', 'showed', 'offensive', 'anti', 'semitic', 'result', 'allegedly', 'result', 'coordinated', 'hate_speech', 'campaign', 'involving', 'malicious', 'actor', '4chan']",SECURITY AND SAFETY
80,73,"[1320,1321,1322,1323,1324,1325,1327,1343]","Through a crowdsourcing social media campaign in 2016, several journalists and researchers demonstrated that augmented reality locations in the popular smartphone game Pokemon Go were more likely to be in white neighborhoods.",Is Pokémon Go racist? How the app may be redlining communities of color,"['crowdsourcing', 'social_medium', 'campaign', '2016', 'several', 'journalist', 'researcher', 'demonstrated', 'augmented', 'reality', 'location', 'popular', 'smartphone', 'game', 'pokemon', 'go', 'likely', 'white', 'neighborhood']",SOCIAL HARM
81,75,[1337],"The organizations SOS Racisme, Union of Jewish Students of France, Movement Against Racism and for Friendship Among Peoples are suing Google due to its autocomplete software suggesting ""jewish"" when the names of certain public figures were searched on the platform.",Google Instant's Allegedly 'Anti-Semitic' Results Lead To Lawsuit In France,"['organization', 'racisme', 'union', 'jewish', 'student', 'france', 'movement', 'racism', 'friendship', 'among', 'people', 'suing', 'google', 'due', 'autocomplete', 'software', 'suggesting', 'jewish', 'name', 'certain', 'public', 'figure', 'searched', 'platform']",SOCIAL HARM
82,81,[1381],"A study by the University of Toronto, the Vector Institute, and MIT showed the input databases that trained AI systems used to classify chest X-rays led the systems to show gender, socioeconomic, and racial biases.","Researchers find evidence of racial, gender, and socioeconomic bias in chest X-ray classifiers","['study', 'university', 'toronto', 'vector', 'institute', 'mit', 'showed', 'input', 'database', 'trained', 'ai', 'system', 'used', 'classify', 'chest', 'x', 'ray', 'led', 'system', 'show', 'gender', 'socioeconomic', 'racial_bias']",SOCIAL HARM
83,86,"[1386,2038]",Errors in Irish Department of Education's algorithm to calculate students’ Leaving Certificate exam grades resulted in thousands of inaccurate scores.,Coding Errors in Leaving Certificate Grading Algorithm Caused Inaccurate Scores in Ireland,"['error', 'irish', 'department', 'education', 'algorithm', 'calculate', 'student', 'leaving', 'certificate', 'exam', 'grade', 'resulted', 'thousand', 'inaccurate', 'score']",OPERATIONAL INCIDENT
84,74,"[1336,1400,1467,1484,1543,1837,2027,2028,2029,2734]",A Black man was wrongfully detained by the Detroit Police Department as a result of a false facial recognition (FRT) result..,Detroit Police Wrongfully Arrested Black Man Due To Faulty FRT,"['black_man', 'wa', 'wrongfully', 'detained', 'detroit', 'police_department', 'result', 'false', 'facial_recognition', 'frt', 'result']",OPERATIONAL INCIDENT
85,95,"[2133,2132,1397,2194]","In January 2021, HireVue removed the controversial AI expression tracking tool from its virtual job interview software.",Job Screening Service Halts Facial Analysis of Applicants,"['january', '2021', 'hirevue', 'removed', 'controversial', 'ai', 'expression', 'tracking', 'tool', 'virtual', 'job', 'interview', 'software']",OPERATIONAL INCIDENT
86,80,"[1380,1559]",In a Scottish soccer match the AI-enabled ball-tracking camera used to livestream the game repeatedly tracked an official’s bald head as though it were the soccer ball.,AI mistakes referee’s bald head for football — hilarity ensued,"['scottish', 'soccer', 'match', 'ai', 'enabled', 'ball', 'tracking', 'camera', 'used', 'livestream', 'game', 'repeatedly', 'tracked', 'official', 'bald', 'head', 'though', 'soccer', 'ball']",OPERATIONAL INCIDENT
87,83,[1383],"Gmail, Yahoo, Outlook, GMX, and LaPoste email inbox sites showed racial and content-based biases when AlgorithmWatch tested their spam box filtering algorithms.",Spam filters are efficient and uncontroversial. Until you look at them.,"['gmail', 'yahoo', 'outlook', 'gmx', 'laposte', 'email', 'inbox', 'site', 'showed', 'racial', 'content', 'based', 'bias', 'algorithmwatch', 'tested', 'spam', 'box', 'filtering', 'algorithm']",OPERATIONAL INCIDENT
88,97,[1399],"A Tesla Model 3 misidentified flags with ""COOP"" written vertically on them as traffic lights.",Tesla Autopilot Mistakes Red Letters on Flag for Red Traffic Lights,"['tesla_model', '3', 'misidentified', 'flag', 'coop', 'written', 'vertically', 'traffic_light']",OPERATIONAL INCIDENT
89,98,[1401],The New York Police Department canceled a contract to use Boston Dynamics' robotic dog Spot following public backlash. ,N.Y.P.D. Robot Dog’s Run Is Cut Short After Fierce Backlash,"['new_york', 'police_department', 'canceled', 'contract', 'use', 'boston', 'dynamic', 'robotic', 'dog', 'spot', 'following', 'public', 'backlash']",SOCIAL HARM
90,79,"[1379,1736,2039]",Decades-long use of the estimated glomerular filtration rate (eGFR) method to test kidney function which considers race has been criticized by physicians and medical students for its racist history and inaccuracy against Black patients.,Kidney Testing Method Allegedly Underestimated Risk of Black Patients,"['decade', 'long', 'use', 'estimated', 'glomerular', 'filtration', 'rate', 'egfr', 'method', 'test', 'kidney', 'function', 'considers', 'race', 'ha', 'criticized', 'physician', 'medical', 'student', 'racist', 'history', 'inaccuracy', 'black_patient']",SOCIAL HARM
91,87,[1387],UK passport photo checker shows bias against dark-skinned women.,UK passport photo checker shows bias against dark-skinned women,"['uk', 'passport', 'photo', 'checker', 'show', 'bias', 'dark', 'skinned', 'woman']",SOCIAL HARM
92,91,"[1391,1392,1463,1720,1779]","In 2020, Stanford Medical Center's distribution algorithm only designated 7 of 5,000 vaccines to Medical Residents, who are frontline workers regularly exposed to COVID-19.",Frontline workers protest at Stanford after hospital distributed vaccine to administrators,"['2020', 'stanford', 'medical', 'center', 'distribution', 'algorithm', 'designated', '7', '5', '000', 'vaccine', 'medical', 'resident', 'frontline', 'worker', 'regularly', 'exposed', 'covid_19']",OPERATIONAL INCIDENT
93,76,[1339],Buenos Aires city government uses a facial recognition system that has led to numerous false arrests.,Live facial recognition is tracking kids suspected of being criminals,"['buenos', 'aire', 'city', 'government', 'us', 'facial_recognition', 'system', 'ha', 'led', 'numerous', 'false', 'arrest']",OPERATIONAL INCIDENT
94,92,"[1393,1396,2035,2036,2037,2274]","Apple Card's credit assessment algorithm was reported by Goldman-Sachs customers to have shown gender bias, in which men received significantly higher credit limits than women with equal credit qualifications.",Apple Card's Credit Assessment Algorithm Allegedly Discriminated against Women,"['apple', 'card', 'credit', 'assessment', 'algorithm', 'wa_reported', 'goldman', 'sachs', 'customer', 'shown', 'gender_bias', 'men', 'received', 'significantly', 'higher', 'credit', 'limit', 'woman', 'equal', 'credit', 'qualification']",SOCIAL HARM
95,89,[1389],A New Zealand government report released following a right-wing terrorist killing 51 worshippers at two New Sealand mosques which indicated that Youtube's recommendation algorithm played an important role in the terrorist's radicalization.,The Christchurch shooter and YouTube’s radicalization trap,"['new', 'zealand', 'government', 'report', 'released', 'following', 'right', 'wing', 'terrorist', 'killing', '51', 'worshipper', 'two', 'new', 'sealand', 'mosque', 'indicated', 'youtube_recommendation', 'algorithm', 'played', 'important', 'role', 'terrorist', 'radicalization']",SOCIAL HARM
96,94,"[1395,1473]","In December 2020, an Italian court ruled that Deliveroo’s employee ‘reliability’ algorithm illegally discriminated against workers with legitimate reasons for cancelling shifts.",Court Rules Deliveroo Used 'Discriminatory' Algorithm,"['december', '2020', 'italian', 'court', 'ruled', 'deliveroo', 'employee', 'reliability', 'algorithm', 'illegally', 'discriminated', 'worker', 'legitimate', 'reason', 'cancelling', 'shift']",OPERATIONAL INCIDENT
97,110,"[1413,2651]","Beneficiaries of the Arkansas Department of Human Services (DHS)'s Medicaid waiver program were allocated excessively fewer hours of caretaker visit via an algorithm deployed to boost efficiency, which reportedly contained errors and whose outputs varied wildly despite small input changes.",Arkansas's Opaque Algorithm to Allocate Health Care Excessively Cut Down Hours for Beneficiaries,"['beneficiary', 'arkansas', 'department_human', 'service_dhs', 'medicaid', 'waiver', 'program', 'allocated', 'excessively', 'fewer', 'hour', 'caretaker', 'visit', 'via', 'algorithm', 'deployed', 'boost', 'efficiency', 'reportedly_contained', 'error', 'whose', 'output', 'varied', 'wildly', 'despite', 'small', 'input', 'change']",OPERATIONAL INCIDENT
98,111,"[1426,1427,1428,1429,1430]",Amazon Flex's contract delivery drivers were dismissed using a minimally human-interfered automated employee performance evaluation based on indicators impacted by out-of-driver's-control factors and without having a chance to defend against or appeal the decision.,Amazon Flex Drivers Allegedly Fired via Automated Employee Evaluations,"['amazon', 'flex', 'contract', 'delivery_driver', 'dismissed', 'using', 'minimally', 'human', 'interfered', 'automated', 'employee', 'performance', 'evaluation', 'based', 'indicator', 'impacted', 'driver', 'control', 'factor', 'without', 'chance', 'defend', 'appeal', 'decision']",SECURITY AND SAFETY
99,104,[1407],"California's vaccine-distribution algorithm used ZIP codes as opposed to census tracts in its decision-making, which critics said undermined equity and access for vulnerable communities who are largely low-income, underserved neighborhoods with low Healthy Places Index scores.","California's Algorithm Considered ZIP Codes in Vaccine Distribution, Allegedly Excluding Low-Income Neighborhoods and Communities of Color","['california', 'vaccine', 'distribution', 'algorithm', 'used', 'zip', 'code', 'opposed', 'census', 'tract', 'decision_making', 'critic_said', 'undermined', 'equity', 'access', 'vulnerable', 'community', 'largely', 'low', 'income', 'underserved', 'neighborhood', 'low', 'healthy', 'place', 'index', 'score']",OPERATIONAL INCIDENT
100,106,"[1409,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,2034,2356]","A Korean interactive chatbot was shown in screenshots to have used derogatory and bigoted language when asked about lesbians, Black people, and people with disabilities.",Korean Chatbot Luda Made Offensive Remarks towards Minority Groups,"['korean', 'interactive', 'chatbot', 'wa_shown', 'screenshots', 'used', 'derogatory', 'bigoted', 'language', 'asked', 'lesbian', 'black', 'people', 'people_disability']",SOCIAL HARM
101,108,"[1411,1503,1537]","A Black teenager living in Livonia, Michigan was incorrectly stopped from entering a roller skating rink after its facial-recognition cameras misidentified her as another person who had been previously banned for starting a skirmish with other skaters.",Skating Rink’s Facial Recognition Cameras Misidentified Black Teenager as Banned Troublemaker,"['black_teenager', 'living', 'livonia', 'michigan', 'wa', 'incorrectly', 'stopped', 'entering', 'roller', 'skating', 'rink', 'facial_recognition', 'camera', 'misidentified', 'another', 'person', 'previously', 'banned', 'starting', 'skirmish', 'skater']",OPERATIONAL INCIDENT
102,115,"[1440,1472,2204]","A company's AI predicting a person's gender based on their name, email address, or username was reported by its users to show biased and inaccurate results.",Genderify’s AI to Predict a Person’s Gender Revealed by Free API Users to Exhibit Bias,"['company', 'ai', 'predicting', 'person', 'gender', 'based', 'name', 'email', 'address', 'username', 'wa_reported', 'user', 'show', 'biased', 'inaccurate', 'result']",OPERATIONAL INCIDENT
103,114,[1439],"Rekognition's face comparison feature was shown by the ACLU to have misidentified members of congress, and particularly members of colors, as other people who have been arrested using a mugshot database built on publicly available arrest photos.",Amazon's Rekognition Falsely Matched Members of Congress to Mugshots,"['rekognition', 'face', 'comparison', 'feature', 'wa_shown', 'aclu', 'misidentified', 'member', 'congress', 'particularly', 'member', 'color', 'people', 'arrested', 'using', 'mugshot', 'database', 'built', 'publicly_available', 'arrest', 'photo']",OPERATIONAL INCIDENT
104,107,"[1410,1928]","Various Chinese firms were revealed by patent applications to have developed facial recognition capable of detecting people by race, which critics feared would enable persecution and discrimination of Uyghur Muslims.","Chinese Tech Firms Allegedly Developed Facial Recognition to Identify People by Race, Targeting Uyghur Muslims","['various', 'chinese', 'firm', 'revealed', 'patent', 'application', 'developed', 'facial_recognition', 'capable', 'detecting', 'people', 'race', 'critic', 'feared', 'would', 'enable', 'persecution', 'discrimination', 'uyghur', 'muslim']",SOCIAL HARM
105,119,"[1444,1800,1801,1802]","Xsolla CEO fired more than a hundred employees from his company in Perm, Russia, based on big data analysis of their remote digitized-work activity, which critics said was violating employee's privacy, outdated, and extremely ineffective.",Xsolla Employees Fired by CEO Allegedly via Big Data Analytics of Work Activities,"['xsolla', 'ceo', 'fired', 'hundred', 'employee', 'company', 'perm', 'russia', 'based', 'big', 'data', 'analysis', 'remote', 'digitized', 'work', 'activity', 'critic_said', 'wa', 'violating', 'employee', 'privacy', 'outdated', 'extremely', 'ineffective']",PRIVACY VIOLATION
106,105,[1408],"A Tesla Model 3 on Autopilot mode crashed into a pickup on a California freeway, where data and video from the company showed neither Autopilot nor the driver slowing the vehicle until seconds before the crash.","Tesla Model 3 on Autopilot Crashed into a Ford Explorer Pickup, Killing a Fifteen-Year-Old in California","['tesla_model', '3', 'autopilot_mode', 'crashed', 'pickup', 'california', 'freeway', 'data', 'video', 'company', 'showed', 'neither', 'autopilot', 'driver', 'slowing', 'vehicle', 'second', 'crash']",SECURITY AND SAFETY
107,99,[1402],Several major universities are using a tool that uses race as one factor to predict student success.,Major Universities Are Using Race as a “High Impact Predictor” of Student Success,"['several', 'major', 'university', 'using', 'tool', 'us', 'race', 'one', 'factor', 'predict', 'student', 'success']",SOCIAL HARM
108,121,"[2106,2105,2104,1447]","In Libya, a Turkish-made Kargu-2 aerial drone powered by a computer vision model was allegedly used remotely by forces backed by the Tripoli-based government to track down and attack enemies as they were running from rocket attacks.",Autonomous Kargu-2 Drone Allegedly Remotely Used to Hunt down Libyan Soldiers,"['libya', 'turkish', 'made', 'kargu', '2', 'aerial', 'drone', 'powered', 'computer', 'vision', 'model', 'wa', 'allegedly', 'used', 'remotely', 'force', 'backed', 'tripoli', 'based', 'government', 'track', 'attack', 'enemy', 'running', 'rocket', 'attack']",OPERATIONAL INCIDENT
109,109,[1412],"PimEyes offered its subscription-based AI service to anyone in the public to search for matching facial images across the internet, which critics said lacked public oversight and government rules to prevent itself from misuse such as stalking women.",PimEyes's Facial Recognition AI Allegedly Lacked Safeguards to Prevent Itself from Being Abused,"['pimeyes', 'offered', 'subscription', 'based', 'ai', 'service', 'anyone', 'public', 'search', 'matching', 'facial', 'image', 'across', 'internet', 'critic_said', 'lacked', 'public', 'oversight', 'government', 'rule', 'prevent', 'misuse', 'stalking', 'woman']",SOCIAL HARM
110,101,"[1404,1575,1863,2570,2805,2845]","A childcare benefits system in the Netherlands falsely accused thousands of families of fraud, in part due to an algorithm that treated having a second nationality as a risk factor.",Dutch Families Wrongfully Accused of Tax Fraud Due to Discriminatory Algorithm,"['childcare', 'benefit', 'system', 'netherlands', 'falsely', 'accused', 'thousand', 'family', 'fraud', 'part', 'due', 'algorithm', 'treated', 'second', 'nationality', 'risk', 'factor']",OPERATIONAL INCIDENT
111,103,"[1406,1527,1528,2145,2241]","Twitter's photo cropping algorithm was revealed by researchers to favor white and women faces in photos containing multiple faces, prompting the company to stop its use on mobile platform.",Twitter’s Image Cropping Tool Allegedly Showed Gender and Racial Bias,"['twitter', 'photo', 'cropping', 'algorithm', 'wa', 'revealed_researcher', 'favor', 'white', 'woman', 'face', 'photo', 'containing', 'multiple', 'face', 'prompting', 'company', 'stop', 'use', 'mobile', 'platform']",SOCIAL HARM
112,113,[1438],"Facebook's AI mislabeled video featuring Black men as a video about ""primates,"" resulting in an offensive prompt message for users who watched the video.","Facebook's AI Put ""Primates"" Label on Video Featuring Black Men","['facebook', 'ai', 'mislabeled', 'video_featuring', 'black', 'men', 'video', 'primate', 'resulting', 'offensive', 'prompt', 'message', 'user', 'watched', 'video']",SOCIAL HARM
113,122,[1448],"Facebook’s initial version of the its Tag Suggestions feature where users were offered suggestions about the identity of people's faces in photos allegedly stored biometric data without consent, violating the Illinois Biometric Information Privacy Act.","Facebook’s ""Tag Suggestions"" Allegedly Stored Biometric Data without User Consent","['facebook', 'initial', 'version', 'tag', 'suggestion', 'feature', 'user', 'offered', 'suggestion', 'identity', 'people', 'face', 'photo', 'allegedly', 'stored', 'biometric_data', 'without_consent', 'violating', 'illinois_biometric', 'information_privacy', 'act']",PRIVACY VIOLATION
114,102,"[1405,1523]","A study found that voice recognition tools from Apple, Amazon, Google, IBM, and Microsoft disproportionately made errors when transcribing black speakers.","Personal voice assistants struggle with black voices, new study shows","['study', 'found', 'voice', 'recognition', 'tool', 'apple', 'amazon', 'google', 'ibm', 'microsoft', 'disproportionately', 'made', 'error', 'transcribing', 'black', 'speaker']",SOCIAL HARM
115,112,"[1434,1436,1432,1433,1810,2495,2496,1435,1821,2250,2623,2831]","ShotSpotter algorithmic systems locating gunshots were reported by police departments for containing high false positive rates and wasting police resources, prompting discontinuation.",Police Departments Reported ShotSpotter as Unreliable and Wasteful,"['shotspotter', 'algorithmic', 'system', 'locating', 'gunshot', 'reported', 'police_department', 'containing', 'high', 'false_positive', 'rate', 'wasting', 'police', 'resource', 'prompting', 'discontinuation']",SECURITY AND SAFETY
116,100,[1403],A French welfare office using software to automatically evaluate cases incorrectly notified a woman receiving benefits that she owed €542.,How French welfare services are creating ‘robo-debt’,"['french', 'welfare', 'office', 'using', 'software', 'automatically', 'evaluate', 'case', 'incorrectly', 'notified', 'woman', 'receiving', 'benefit', 'owed', '542']",SOCIAL HARM
117,116,"[1441,1803]","Amazon's automated performance evaluation system involving AI-powered cameras incorrectly punished delivery drivers for non-existent mistakes, impacting their chances for bonuses and rewards.",Amazon's AI Cameras Incorrectly Penalized Delivery Drivers for Mistakes They Did Not Make,"['amazon', 'automated', 'performance', 'evaluation', 'system_involving', 'ai_powered', 'camera', 'incorrectly', 'punished', 'delivery_driver', 'non_existent', 'mistake', 'impacting', 'chance', 'bonus', 'reward']",OPERATIONAL INCIDENT
118,118,"[1443,2009,2010]","Users and researchers revealed generative AI GPT-3 associating Muslims to violence in prompts, resulting in disturbingly racist and explicit outputs such as casting Muslim actor as a terrorist.",OpenAI's GPT-3 Associated Muslims with Violence,"['user', 'researcher', 'revealed', 'generative_ai', 'gpt_3', 'associating', 'muslim', 'violence', 'prompt', 'resulting', 'disturbingly', 'racist', 'explicit', 'output', 'casting', 'muslim', 'actor', 'terrorist']",SOCIAL HARM
119,120,[1445],"Philosopher AI, a GPT-3-powered controversial text generator, was allegedly used by an anonymous actor on AskReddit subreddit, whose posts featured a mixture of harmless stories, conspiracy theories, and sensitive topic discussions.",Philosophy AI Allegedly Used To Generate Mixture of Innocent and Harmful Reddit Posts,"['philosopher', 'ai', 'gpt_3', 'powered', 'controversial', 'text', 'generator', 'wa', 'allegedly', 'used', 'anonymous', 'actor', 'askreddit', 'subreddit', 'whose', 'post', 'featured', 'mixture', 'harmless', 'story', 'conspiracy_theory', 'sensitive', 'topic', 'discussion']",SOCIAL HARM
120,117,"[1442,2019,2020,2021]","TikTok's ""Suggested Accounts"" recommendations allegedly reinforced racial bias despite not basing recommendations on race or creators' profile photo.","TikTok's ""Suggested Accounts"" Algorithm Allegedly Reinforced Racial Bias through Feedback Loops","['tiktok', 'suggested', 'account', 'recommendation', 'allegedly', 'reinforced', 'racial_bias', 'despite', 'basing', 'recommendation', 'race', 'creator', 'profile', 'photo']",SOCIAL HARM
121,129,[1462],"Facebook's automated moderation tools were shown by internal documents performing incomparably to human moderators, and accounting for only a small fraction of hate speech, violence, and incitement content removal.","Facebook's Automated Tools Failed to Adequately Remove Hate Speech, Violence, and Incitement","['facebook_automated', 'moderation_tool', 'shown', 'internal', 'document', 'performing', 'incomparably', 'human', 'moderator', 'accounting', 'small', 'fraction', 'hate_speech', 'violence', 'incitement', 'content', 'removal']",SOCIAL HARM
122,140,[1478],"An exam monitoring service used by the University of Toronto was alleged by its students to have provided discriminatory check-in experiences via its facial recognition's failure to verify passport photo, disproportionately enhancing disadvantaging stress level for BIPOC students.",ProctorU’s Identity Verification and Exam Monitoring Systems Provided Allegedly Discriminatory Experiences for BIPOC Students,"['exam', 'monitoring', 'service', 'used', 'university', 'toronto', 'wa_alleged', 'student', 'provided', 'discriminatory', 'check', 'experience', 'via_facial', 'recognition', 'failure', 'verify', 'passport', 'photo', 'disproportionately', 'enhancing', 'disadvantaging', 'stress', 'level', 'bipoc', 'student']",OPERATIONAL INCIDENT
123,146,"[1494,1495,1502]","A publicly accessible research model that was trained via Reddit threads showed racially biased advice on moral dilemmas, allegedly demonstrating limitations of language-based models trained on moral judgments.","Research Prototype AI, Delphi, Reportedly Gave Racially Biased Answers on Ethics","['publicly', 'accessible', 'research', 'model', 'wa', 'trained', 'via', 'reddit', 'thread', 'showed', 'racially', 'biased', 'advice', 'moral', 'dilemma', 'allegedly', 'demonstrating', 'limitation', 'language', 'based', 'model_trained', 'moral', 'judgment']",OPERATIONAL INCIDENT
124,137,[1474],"An Israeli farmer was imposed a computer generated fine by the tax authority, who allegedly were not able to explain its calculation, and refused to disclose the program and its source code.","Israeli Tax Authority Employed Opaque Algorithm to Impose Fines, Reportedly Refusing to Provide an Explanation for Amount Calculation to a Farmer","['israeli', 'farmer', 'wa', 'imposed', 'computer', 'generated', 'fine', 'tax', 'authority', 'allegedly', 'able', 'explain', 'calculation', 'refused', 'disclose', 'program', 'source', 'code']",SOCIAL HARM
125,144,"[1483,1979,1980,2042,2043,2134]","YouTube's AI-powered hate speech detection system falsely flagged chess content and banned chess creators allegedly due to its misinterpretation of strategy language such as ""black,"" ""white,"" and ""attack"" as harmful and dangerous.",YouTube's AI Mistakenly Banned Chess Channel over Chess Language Misinterpretation,"['youtube', 'ai_powered', 'hate_speech', 'detection_system', 'falsely', 'flagged', 'chess', 'content', 'banned', 'chess', 'creator', 'allegedly_due', 'misinterpretation', 'strategy', 'language', 'black', 'white', 'attack', 'harmful', 'dangerous']",SOCIAL HARM
126,148,[1499],"AI-powered web accessibility vendors allegedly overstated to customers about their products' utility for people with disabilities, falsely claiming to deliver automated compliance solutions.",Web Accessibility Vendors Allegedly Falsely Claimed to Provide Compliance Using AI,"['ai_powered', 'web', 'accessibility', 'vendor', 'allegedly', 'overstated', 'customer', 'product', 'utility', 'people_disability', 'falsely', 'claiming', 'deliver', 'automated', 'compliance', 'solution']",SOCIAL HARM
127,160,"[1520,1521,2381]","Amazon’s voice assistant Alexa suggested “the penny challenge,” which involves dangerously touching a coin to the prongs of a half-exposed plug, when a ten-year-old girl asked for a challenge to do.",Alexa Recommended Dangerous TikTok Challenge to Ten-Year-Old Girl,"['amazon', 'voice', 'assistant', 'alexa', 'suggested', 'penny', 'challenge', 'involves', 'dangerously', 'touching', 'coin', 'prong', 'half', 'exposed', 'plug', 'ten', 'year_old', 'girl', 'asked', 'challenge']",OPERATIONAL INCIDENT
128,152,"[1509,1510]","SoftBank's robot allegedly kept making mechanical errors, taking unplanned breaks, failing to recognize previously-met people, and breaking down during practice runs.","SoftBank's Humanoid Robot, Pepper, Reportedly Frequently Made Errors, Prompting Dismissal","['softbank', 'robot', 'allegedly', 'kept', 'making', 'mechanical', 'error', 'taking', 'unplanned', 'break', 'failing', 'recognize', 'previously', 'met', 'people', 'breaking', 'practice', 'run']",SECURITY AND SAFETY
129,161,"[1530,2138,2139]",Facebook's housing and employment ad delivery process allegedly resulted in skews in exposure for some users along demographic lines such as gender and racial identity.,Facebook's Ad Delivery Reportedly Excluded Audience along Racial and Gender Lines,"['facebook', 'housing', 'employment', 'ad', 'delivery', 'process', 'allegedly', 'resulted', 'skews', 'exposure', 'user', 'along', 'demographic', 'line', 'gender', 'racial', 'identity']",SECURITY AND SAFETY
130,164,[1534],"After the “News Feed” algorithm had been overhauled to boost engagement between friends and family in early 2018, its heavy weighting of re-shared content was alleged found by company researchers to have pushed content creators to reorient their posts towards outrage and sensationalism, causing a proliferation of misinformation, toxicity, and violent content.","Facebook ""News Feed"" Allegedly Boosted Misinformation and Violating Content Following Use of MSI Metric","['news_feed', 'algorithm', 'overhauled', 'boost', 'engagement', 'friend', 'family', 'early', '2018', 'heavy', 'weighting', 'shared', 'content', 'wa_alleged', 'found', 'company', 'researcher', 'pushed', 'content_creator', 'reorient', 'post', 'towards', 'outrage', 'sensationalism', 'causing', 'proliferation', 'misinformation', 'toxicity', 'violent', 'content']",SOCIAL HARM
131,168,"[1540,1541]","Collaborative filtering prone to popularity bias, resulting in overrepresentation of popular items in the recommendation outputs.","Collaborative Filtering Prone to Popularity Bias, Resulting in Overrepresentation of Popular Items in the Recommendation Outputs","['collaborative', 'filtering', 'prone', 'popularity', 'bias', 'resulting', 'overrepresentation', 'popular', 'item', 'recommendation', 'output']",OPERATIONAL INCIDENT
132,133,[1468],TikTok's automated content reporting system was allegedly abused by online trolls to intentionally misreport content created by users of marginalized groups.,Online Trolls Allegedly Abused TikTok’s Automated Content Reporting System to Discriminate against Marginalized Creators,"['tiktok_automated', 'content', 'reporting', 'system', 'wa', 'allegedly', 'abused', 'online', 'troll', 'intentionally', 'misreport', 'content', 'created', 'user', 'marginalized', 'group']",SOCIAL HARM
133,131,"[1465,1771]","The proctoring algorithm used in a California bar exam cited a third of thousands of applicants as cheaters, resulting in allegations where exam takers were instructed to prove otherwise without seeing their incriminating video evidence.",Proctoring Algorithm in Online California Bar Exam Flagged an Unusually High Number of Alleged Cheaters,"['proctoring', 'algorithm', 'used', 'california', 'bar', 'exam', 'cited', 'third', 'thousand', 'applicant', 'cheater', 'resulting', 'allegation', 'exam', 'taker', 'instructed', 'prove', 'otherwise', 'without', 'seeing', 'incriminating', 'video', 'evidence']",OPERATIONAL INCIDENT
134,153,"[1511,1729,1763,2514]","In 2019, a Tesla Model S driver on Autopilot mode reportedly went through a red light and crashed into a Honda Civic, killing two people in Gardena, Los Angeles.","Tesla Driver on Autopilot Ran a Red Light, Crashing into a Car and Killing Two People in Los Angeles","['2019', 'tesla_model', 'driver', 'autopilot_mode', 'reportedly', 'went', 'red', 'light', 'crashed', 'honda', 'civic', 'killing', 'two', 'people', 'gardena', 'los_angeles']",SECURITY AND SAFETY
135,145,"[1485,1504,1529]","Tesla's Autopilot was shown on video by its owner mistaking the moon for a yellow stop light, allegedly causing the vehicle to keep slowing down.",Tesla's Autopilot Misidentified the Moon as Yellow Stop Light,"['tesla_autopilot', 'wa_shown', 'video', 'owner', 'mistaking', 'moon', 'yellow', 'stop', 'light', 'allegedly', 'causing', 'vehicle', 'keep', 'slowing']",SECURITY AND SAFETY
136,141,"[1479,1480]","A police officer in Beverly Hills played copyrighted music on his phone when realizing that his interactions were being recorded on a livestream, allegedly hoping the Instagram's automated copyright detection system to end or mute the stream.",California Police Turned on Music to Allegedly Trigger Instagram’s DCMA to Avoid Being Live-Streamed,"['police_officer', 'beverly', 'hill', 'played', 'copyrighted', 'music', 'phone', 'realizing', 'interaction', 'recorded', 'livestream', 'allegedly', 'hoping', 'instagram', 'automated', 'copyright', 'detection_system', 'end', 'mute', 'stream']",SOCIAL HARM
137,134,"[1469,1951]","A shopping guide robot deployed by the Fuzhou Zhongfang Marlboro Mall was shown on video allegedly walking to the escalator by itself, falling down, and knocking over passengers, which prompted its suspension.","Robot in Chinese Shopping Mall Fell off the Escalator, Knocking down Passengers","['shopping', 'guide', 'robot', 'deployed', 'fuzhou', 'zhongfang', 'marlboro', 'mall', 'wa_shown', 'video', 'allegedly', 'walking', 'escalator', 'falling', 'knocking', 'passenger', 'prompted', 'suspension']",SECURITY AND SAFETY
138,125,"[1451,1452,1460]",Amazon’s robotic fulfillment centers have higher serious injury rates.,Amazon’s Robotic Fulfillment Centers Have Higher Serious Injury Rates,"['amazon', 'robotic', 'fulfillment', 'center', 'higher', 'serious', 'injury', 'rate']",SECURITY AND SAFETY
139,136,[1471],"Brand safety tech firms falsely claimed use of AI, blocking ads using simple keyword lists.","Brand Safety Tech Firms Falsely Claimed Use of AI, Blocking Ads Using Simple Keyword Lists","['brand', 'safety', 'tech', 'firm', 'falsely', 'claimed', 'use', 'ai', 'blocking', 'ad', 'using', 'simple', 'keyword', 'list']",SOCIAL HARM
140,138,"[1475,1505,1555,1556,2442,2434]","Proctorio's remote-testing software were reported by students at the University of Illinois Urbana-Champaign for issues regarding privacy, accessibility, differential performance on darker-skinned students.",Alleged Issues with Proctorio's Remote-Testing AI Prompted Suspension by University,"['proctorio', 'remote', 'testing', 'software', 'reported', 'student', 'university', 'illinois', 'urbana', 'champaign', 'issue', 'regarding', 'privacy', 'accessibility', 'differential', 'performance', 'darker', 'skinned', 'student']",SOCIAL HARM
141,132,[1466],"Videos promoting eating disorders evaded TikTok's automated violation detection system without difficulty via common misspellings of search terms, bypassing its ban of violating hashtags such as ""proana"" and ""anorexia"".",TikTok’s Content Moderation Allegedly Failed to Adequately Take down Videos Promoting Eating Disorders,"['video', 'promoting', 'eating_disorder', 'evaded', 'tiktok_automated', 'violation', 'detection_system', 'without', 'difficulty', 'via', 'common', 'misspelling', 'search', 'term', 'bypassing', 'ban', 'violating', 'hashtags', 'proana', 'anorexia']",PRIVACY VIOLATION
142,135,"[1470,1871]","The University of Texas at Austin's Department of Computer Science's assistive algorithm to assess PhD applicants ""GRADE"" raised concerns among faculty about worsening historical inequalities for marginalized candidates, prompting its suspension.",UT Austin GRADE Algorithm Allegedly Reinforced Historical Inequalities,"['university', 'texas', 'austin', 'department', 'computer', 'science', 'assistive', 'algorithm_ass', 'phd', 'applicant', 'grade', 'raised_concern', 'among', 'faculty', 'worsening', 'historical', 'inequality', 'marginalized', 'candidate', 'prompting', 'suspension']",SOCIAL HARM
143,155,"[1513,1514]",Lake Tahoe travelers were allegedly guided by Google Maps into hazardous shortcuts in the mountains during a snowstorm.,Google Maps Allegedly Directed Sierra Nevada Travelers to Dangerous Roads amid Winter Storm,"['lake', 'tahoe', 'traveler', 'allegedly', 'guided', 'google', 'map', 'hazardous', 'shortcut', 'mountain', 'snowstorm']",SECURITY AND SAFETY
144,162,[1531]," International testing organization ETS admits voice recognition as evidence of cheating for thousands of previous TOEIC test-takers that reportedly included wrongfully accused people, causing them to be deported without an appeal process or seeing their incriminating evidence.","ETS Used Allegedly Flawed Voice Recognition Evidence to Accuse and Assess Scale of Cheating, Causing Thousands to be Deported from the UK","['international', 'testing', 'organization', 'ets', 'admits', 'voice', 'recognition', 'evidence', 'cheating', 'thousand', 'previous', 'toeic', 'test', 'taker', 'reportedly', 'included', 'wrongfully', 'accused', 'people', 'causing', 'deported', 'without', 'appeal', 'process', 'seeing', 'incriminating', 'evidence']",OPERATIONAL INCIDENT
145,171,[1549],A Bath resident was wrongly fined by the local officials because an automated license plate recognition camera misread the text on her shirt as a license plate number.,"Traffic Camera Misread Text on Pedestrian's Shirt as License Plate, Causing UK Officials to Issue Fine to an Unrelated Person","['bath', 'resident', 'wa', 'wrongly', 'fined', 'local', 'official', 'automated_license', 'plate', 'recognition_camera', 'misread', 'text', 'shirt', 'license_plate', 'number']",OPERATIONAL INCIDENT
146,151,"[1507,1508,1703,1704,1705,1706,1707,1708,1709,1710]","A Pony.ai vehicle operating in autonomous mode crashed into a center divider and a traffic sign in San Francisco, prompting a regulator to suspend the driverless testing permit for the startup.",California Regulator Suspended Pony.ai's Driverless Testing Permit Following a Non-Fatal Collision,"['pony', 'ai', 'vehicle', 'operating', 'autonomous_mode', 'crashed', 'center', 'divider', 'traffic', 'sign', 'san_francisco', 'prompting', 'regulator', 'suspend', 'driverless', 'testing', 'permit', 'startup']",SECURITY AND SAFETY
147,123,"[1449,2651,2705,3013,3012]","Epic System's sepsis prediction algorithms was shown by investigators at the University of Michigan Hospital to have high rates of false positives and false negatives, allegedly delivering inaccurate and irrelevant information on patients, contrasting sharply with their published claims.",Epic Systems’s Sepsis Prediction Algorithms Revealed to Have High Error Rates on Seriously Ill Patients,"['epic', 'system', 'sepsis', 'prediction', 'algorithm', 'wa_shown', 'investigator', 'university', 'michigan', 'hospital', 'high_rate', 'false_positive', 'false', 'negative', 'allegedly', 'delivering', 'inaccurate', 'irrelevant', 'information', 'patient', 'contrasting', 'sharply', 'published', 'claim']",OPERATIONAL INCIDENT
148,156,"[1515,2197]","Despite complaints notifying Amazon about the sale of various products that had been used to aid suicide attempts, its recommendation system reportedly continued selling them and suggesting their frequently bought-together items.",Amazon Reportedly Sold Products and Recommended Frequently Bought Together Items That Aid Suicide Attempts,"['despite', 'complaint', 'notifying', 'amazon', 'sale', 'various', 'product', 'used', 'aid', 'suicide', 'attempt', 'recommendation', 'system', 'reportedly', 'continued', 'selling', 'suggesting', 'frequently', 'bought', 'together', 'item']",SOCIAL HARM
149,143,[1482],"Facebook's and Twitter were not able to sufficiently moderate content of small language groups such as the Balkan languages using AI, allegedly due to the lack of investment in human moderation and difficulty in AI-solution design for the languages.",Facebook’s and Twitter's Automated Content Moderation Reportedly Failed to Effectively Enforce Violation Rules for Small Language Groups,"['facebook', 'twitter', 'able', 'sufficiently', 'moderate', 'content', 'small', 'language', 'group', 'balkan', 'language', 'using', 'ai', 'allegedly_due', 'lack', 'investment', 'human', 'moderation', 'difficulty', 'ai', 'solution', 'design', 'language']",SOCIAL HARM
150,157,[1516],"A lawsuit cited Amazon as liable in a crash involving its delivery driver, alleging that Amazon’s AI-powered driver monitoring system pushed drivers to prioritize speed over safety.","Amazon's Monitoring System Allegedly Pushed Delivery Drivers to Prioritize Speed over Safety, Leading to Crash","['lawsuit', 'cited', 'amazon', 'liable', 'crash', 'involving', 'delivery_driver', 'alleging', 'amazon', 'ai_powered', 'driver', 'monitoring', 'system', 'pushed', 'driver', 'prioritize', 'speed', 'safety']",SECURITY AND SAFETY
151,170,"[1546,1547,1548]","Target recommended maternity-related items to a family in Atlanta via ads, allegedly predicting their teenage daughter’s pregnancy before her father did, although critics have called into question the predictability of the algorithm and the authenticity of its claims.","Target Suggested Maternity-Related Advertisements to a Teenage Girl's Home, Allegedly Correctly Predicting Her Pregnancy via Algorithm","['target', 'recommended', 'maternity', 'related', 'item', 'family', 'atlanta', 'via', 'ad', 'allegedly', 'predicting', 'teenage', 'daughter', 'pregnancy', 'father', 'although', 'critic', 'called', 'question', 'predictability', 'algorithm', 'authenticity', 'claim']",OPERATIONAL INCIDENT
152,139,"[1476,1477]","Evidence of the ""filter-bubble effect"" were found by vaccine-misinformation researchers in Amazon's recommendations, where its algorithms presented users who performed actions on misinformative products with more misinfomative products.",Amazon’s Search and Recommendation Algorithms Found by Auditors to Have Boosted Products That Contained Vaccine Misinformation,"['evidence', 'filter', 'bubble', 'effect', 'found', 'vaccine', 'misinformation', 'researcher', 'amazon', 'recommendation_algorithm', 'presented', 'user', 'performed', 'action', 'misinformative', 'product', 'misinfomative', 'product']",OPERATIONAL INCIDENT
153,142,[1481],"Facebook platforms' automated ad moderation system falsely classified adaptive fashion products as medical and health care products and services, resulting in regular bans and appeals faced by their retailers.",Facebook’s Advertisement Moderation System Routinely Misidentified Adaptive Fashion Products as Medical Equipment and Blocked Their Sellers,"['facebook', 'platform', 'automated', 'ad', 'moderation_system', 'falsely', 'classified', 'adaptive', 'fashion', 'product', 'medical', 'health', 'care', 'product', 'service', 'resulting', 'regular', 'ban', 'appeal', 'faced', 'retailer']",SOCIAL HARM
154,150,"[1506,3157,3158]","Some women using the contraceptive app, Natural Cycles, reported unwanted pregnancies, revealing its algorithm's difficulties in mapping menstrual cycles.","Swedish Contraceptive App, Natural Cycles, Allegedly Failed to Correctly Map Menstrual Cycle","['woman', 'using', 'contraceptive', 'app', 'natural', 'cycle', 'reported', 'unwanted', 'pregnancy', 'revealing', 'algorithm', 'difficulty', 'mapping', 'menstrual', 'cycle']",OPERATIONAL INCIDENT
155,169,"[1544,1545,2986,2987,2988]"," Facebook allegedly did not adequately remove anti-Rohingya hate speech, some of which was extremely violent and dehumanizing, on its platform, contributing to the violence faced by Rohingya communities in Myanmar.",Facebook Allegedly Failed to Police Anti-Rohingya Hate Speech Content That Contributed to Violence in Myanmar,"['facebook', 'allegedly', 'adequately', 'remove', 'anti', 'rohingya', 'hate_speech', 'wa', 'extremely', 'violent', 'dehumanizing', 'platform', 'contributing', 'violence', 'faced', 'rohingya', 'community', 'myanmar']",SOCIAL HARM
156,147,"[1496,1497]","In early 2020, fraudsters reportedly allegedly deepfaked the voice of a company's director, demanding a bank manager in Hong Kong to authorize a $35M transfer.",Hong Kong Bank Manager Swindled by Fraudsters Using Deepfaked Voice of Company Director,"['early', '2020', 'fraudsters', 'reportedly', 'allegedly', 'deepfaked', 'voice', 'company', 'director', 'demanding', 'bank', 'manager', 'hong', 'kong', 'authorize', '35m', 'transfer']",SOCIAL HARM
157,126,"[1453,1454,1455,1532]","A collision involving three robots at an Ocado's warehouse in Erith, UK, resulting in a fire but no reports of injuries.","Three Robots Collided, Sparking Fire in a Grocer's Warehouse in UK ","['collision', 'involving', 'three', 'robot', 'ocado', 'warehouse', 'erith', 'uk', 'resulting', 'fire', 'report', 'injury']",SECURITY AND SAFETY
158,128,"[1459,1818]"," A Tesla Sedan operating on Autopilot mode was not able to center itself on the road and drove over a yellow dividing curb in Redmond, Washington, causing minor damage to the vehicle’s rear suspension.","Tesla Sedan on Autopilot Reportedly Drove Over Dividing Curb in Washington, Resulting in Minor Vehicle Damage","['tesla_sedan', 'operating_autopilot', 'mode', 'wa', 'able', 'center', 'road', 'drove', 'yellow', 'dividing', 'curb', 'redmond', 'washington', 'causing_minor', 'damage', 'vehicle', 'rear', 'suspension']",SECURITY AND SAFETY
159,154,[1512],"Department of Justice’s inmate-recidivism risk assessment tool was reported to have produced racially uneven results, misclassifying risk levels for inmates of color.",Justice Department’s Recidivism Risk Algorithm PATTERN Allegedly Caused Persistent Disparities Along Racial Lines,"['department', 'justice', 'inmate', 'recidivism_risk', 'assessment', 'tool', 'wa_reported', 'produced', 'racially', 'uneven', 'result', 'misclassifying', 'risk', 'level', 'inmate', 'color']",SOCIAL HARM
160,165,"[1536,2781]","Image upscaling tool PULSE powered by NVIDIA's StyleGAN reportedly generated faces with Caucasian features more often, although AI academics, engineers, and researchers were not in agreement about where the source of bias was.",Image Upscaling Algorithm PULSE Allegedly Produced Facial Images with Caucasian Features More Often,"['image', 'upscaling', 'tool', 'pulse', 'powered', 'nvidia', 'stylegan', 'reportedly', 'generated', 'face', 'caucasian', 'feature', 'often', 'although', 'ai', 'academic', 'engineer', 'researcher', 'agreement', 'source', 'bias', 'wa']",SOCIAL HARM
161,158,[1517],"A Black student's face was not recognized by the remote-proctoring software during check-in of a lab quiz, causing her to excessively change her environments for it to work as intended.",Facial Recognition in Remote Learning Software Reportedly Failed to Recognize a Black Student’s Face,"['black', 'student', 'face', 'wa', 'recognized', 'remote_proctoring', 'software', 'check', 'lab', 'quiz', 'causing', 'excessively', 'change', 'environment', 'work', 'intended']",SOCIAL HARM
162,149,"[1500,1501,1890,2925]","Zillow's AI-powered predictive pricing tool Zestimate was allegedly not able to accurately forecast housing prices three to six months in advance due to rapid market changes, prompting division shutdown and layoff of a few thousand employees.",Zillow Shut Down Zillow Offers Division Allegedly Due to Predictive Pricing Tool's Insufficient Accuracy,"['zillow', 'ai_powered', 'predictive', 'pricing', 'tool', 'zestimate', 'wa', 'allegedly', 'able', 'accurately', 'forecast', 'housing', 'price', 'three', 'six_month', 'advance', 'due', 'rapid', 'market', 'change', 'prompting', 'division', 'shutdown', 'layoff', 'thousand', 'employee']",SOCIAL HARM
163,124,"[1450,1522,2262,2652,2651,2704,2856]","Optum's algorithm deployed by a large academic hospital was revealed by researchers to have under-predicted the health needs of black patients, effectively de-prioritizing them in extra care programs relative to white patients with the same health burden.",Algorithmic Health Risk Scores Underestimated Black Patients’ Needs,"['optum', 'algorithm', 'deployed', 'large', 'academic', 'hospital', 'wa', 'revealed_researcher', 'predicted', 'health', 'need', 'black_patient', 'effectively', 'de', 'prioritizing', 'extra', 'care', 'program', 'relative', 'white', 'patient', 'health', 'burden']",SOCIAL HARM
164,159,[2471],"Tencent Keen Security Lab conducted security research into Tesla’s Autopilot system and identified crafted adversarial samples and remote controlling via wireless gamepad as vulnerabilities to its system, although the company called into question their real-world practicality. This incident has been downgraded to an issue as it does not meet current ingestion criteria.",Tesla Autopilot’s Lane Recognition Allegedly Vulnerable to Adversarial Attacks,"['tencent', 'keen', 'security', 'lab', 'conducted', 'security', 'research', 'tesla_autopilot', 'system', 'identified', 'crafted', 'adversarial', 'sample', 'remote', 'controlling', 'via', 'wireless', 'gamepad', 'vulnerability', 'system', 'although', 'company', 'called', 'question', 'real', 'world', 'practicality', 'incident_ha', 'downgraded_issue', 'doe_meet', 'current_ingestion', 'criterion']",OPERATIONAL INCIDENT
165,167,[1539],"Researchers at Stanford Graduate School of Business developed a model that determined, on a binary scale, whether someone was homosexual using only his facial image, which advocacy groups such as GLAAD and the Human Rights Campaign denounced as flawed science and threatening to LGBTQ folks.",Researchers' Homosexual-Men Detection Model Denounced as a Threat to LGBTQ People’s Safety and Privacy,"['researcher', 'stanford', 'graduate', 'school', 'business', 'developed', 'model', 'determined', 'binary', 'scale', 'whether', 'someone', 'wa', 'homosexual', 'using', 'facial', 'image', 'advocacy_group', 'glaad', 'human', 'right', 'campaign', 'denounced', 'flawed', 'science', 'threatening', 'lgbtq', 'folk']",OPERATIONAL INCIDENT
166,127,"[1456,1457,1458,1461,1486,1487,1488,1489,1490,1491,1492,1493]","A news story published on MSN.com featured a photo of the wrong mixed-race person that was allegedly selected by an algorithm, following Microsoft’s layoff and replacement of journalists and editorial workers at its organizations with AI systems.",Microsoft’s Algorithm Allegedly Selected Photo of the Wrong Mixed-Race Person Featured in a News Story,"['news', 'story', 'published', 'msn', 'com', 'featured', 'photo', 'wrong', 'mixed', 'race', 'person', 'wa', 'allegedly', 'selected', 'algorithm', 'following', 'microsoft', 'layoff', 'replacement', 'journalist', 'editorial', 'worker', 'organization', 'ai', 'system']",OPERATIONAL INCIDENT
167,163,"[1533,1652]","Facebook’s hate-speech detection algorithms was found by company researchers to have under-reported less common but more harmful content that was more often experienced by minority groups such as Black, Muslim, LGBTQ, and Jewish users.",Facebook’s Hate Speech Detection Algorithms Allegedly Disproportionately Failed to Remove Racist Content towards Minority Groups,"['facebook', 'hate_speech', 'detection', 'algorithm', 'wa', 'found', 'company', 'researcher', 'reported', 'le', 'common', 'harmful_content', 'wa', 'often', 'experienced', 'minority', 'group', 'black', 'muslim', 'lgbtq', 'jewish', 'user']",SOCIAL HARM
168,166,"[1538,1563]","A social networking platform, Giggle, allegedly collected, shared to third-parties, and used sensitive information and biometric data to verify whether a person is a woman via facial recognition, which critics claimed to be discriminatory against women of color and harmful towards trans women.","Networking Platform Giggle Employs AI to Determine Users’ Gender, Allegedly Excluding Transgender Women","['social', 'networking', 'platform', 'giggle', 'allegedly', 'collected', 'shared', 'third', 'party', 'used', 'sensitive_information', 'biometric_data', 'verify', 'whether', 'person', 'woman', 'via_facial', 'recognition', 'critic', 'claimed', 'discriminatory', 'woman', 'color', 'harmful', 'towards', 'trans', 'woman']",SOCIAL HARM
169,176,[1557]," A Starship food delivery robot deployed by Oregon State University reportedly failed to cross the railroad, becoming stranded, and ending up being struck by an oncoming freight train.","Starship’s Autonomous Food Delivery Robot Allegedly Stranded at Railroad Crossing in Oregon, Run over by Freight Train","['starship', 'food', 'delivery_robot', 'deployed', 'oregon', 'state', 'university', 'reportedly', 'failed', 'cross', 'railroad', 'becoming', 'stranded', 'ending', 'struck', 'oncoming', 'freight', 'train']",SECURITY AND SAFETY
170,182,"[1573,1574]","In San Francisco, an autonomous Cruise Chevrolet Bolt collided with another Cruise vehicle driven by a Cruise human employee, causing minor scuffs to the cars but no human injuries.",Two Cruise Autonomous Vehicles Collided with Each Other in California ,"['san_francisco', 'autonomous', 'cruise', 'chevrolet', 'bolt', 'collided', 'another', 'cruise', 'vehicle', 'driven', 'cruise', 'human', 'employee', 'causing_minor', 'scuff', 'car', 'human', 'injury']",SECURITY AND SAFETY
171,173,[1551],"AI tools failed to sufficiently predict COVID patients, some potentially harmful.","AI Tools Failed to Sufficiently Predict COVID Patients, Some Potentially Harmful","['ai', 'tool', 'failed', 'sufficiently', 'predict', 'covid', 'patient', 'potentially', 'harmful']",SECURITY AND SAFETY
172,203,"[1659,1660,1661]","Uber launched a new but opaque algorithm to determine drivers' pay in the US which allegedly caused drivers to experience lower fares, confusing fare drops, and a decrease in rides.",Uber Launched Opaque Algorithm That Changes Drivers' Payments in the US,"['uber', 'launched', 'new', 'opaque', 'algorithm', 'determine', 'driver', 'pay', 'u', 'allegedly_caused', 'driver', 'experience', 'lower', 'fare', 'confusing', 'fare', 'drop', 'decrease', 'ride']",SECURITY AND SAFETY
173,184,"[1581,1584,1899]"," A facial recognition program rolled out by São Paulo Metro Stations was suspended following a court ruling in response to a lawsuit by civil society organizations, who cited fear of it being integrated with other electronic surveillance entities without consent, and lack of transparency about the biometric data collection process of metro users.",Facial Recognition Program in São Paulo Metro Stations Suspended for Illegal and Disproportionate Violation of Citizens’ Right to Privacy,"['facial_recognition', 'program', 'rolled', 'são', 'paulo', 'metro', 'station', 'wa', 'suspended', 'following', 'court', 'ruling', 'response', 'lawsuit', 'civil', 'society', 'organization', 'cited', 'fear', 'integrated', 'electronic', 'surveillance', 'entity', 'without_consent', 'lack', 'transparency', 'biometric_data', 'collection', 'process', 'metro', 'user']",PRIVACY VIOLATION
174,195,"[1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1843]","The Intelligence-Led Policing model rolled out by the Pasco County Sheriff’s Office was allegedly developed based on flawed science and biased data that also contained sensitive information and irrelevant attributes about students, which critics said to be discriminatory.",Predictive Policing Program by Florida Sheriff’s Office Allegedly Violated Residents’ Rights and Targeted Children of Vulnerable Groups,"['intelligence', 'led', 'policing', 'model', 'rolled', 'pasco', 'county', 'sheriff', 'office', 'wa', 'allegedly', 'developed', 'based', 'flawed', 'science', 'biased', 'data', 'also', 'contained', 'sensitive_information', 'irrelevant', 'attribute', 'student', 'critic_said', 'discriminatory']",OPERATIONAL INCIDENT
175,213,"[1715,1716,1717,1718,1719]","The performance of Facebook’s political ad detection was revealed by researchers to be imprecise, uneven across countries in errors, and inadequate for preventing systematic violations of political advertising policies.",Facebook’s Political Ad Detection Reportedly Showed High and Geographically Uneven Error Rates,"['performance', 'facebook', 'political', 'ad', 'detection', 'wa', 'revealed_researcher', 'imprecise', 'uneven', 'across', 'country', 'error', 'inadequate', 'preventing', 'systematic', 'violation', 'political', 'advertising', 'policy']",OPERATIONAL INCIDENT
176,174,"[1552,1585,1595,1599]","More than a thousand inauthentic LinkedIn profiles using allegedly GAN-generated photos were notified by researchers at Stanford to LinkedIn’s staff, and many of which were removed for violating rules against creating fake profiles and falsifying information.",Fake LinkedIn Profiles Created Using GAN Photos,"['thousand', 'inauthentic', 'linkedin', 'profile', 'using', 'allegedly', 'gan_generated', 'photo', 'notified', 'researcher', 'stanford', 'linkedin', 'staff', 'many', 'removed', 'violating', 'rule', 'creating', 'fake', 'profile', 'falsifying', 'information']",SOCIAL HARM
177,198,"[1642,1643,1644,1645,1646]", A quickly-debunked deepfaked video of the Ukrainian President Volodymyr Zelenskyy was posted on various Ukrainian websites and social media platforms encouraging Ukrainians to surrender to Russian forces during the Russia-Ukraine war.,Deepfake Video of Ukrainian President Yielding to Russia Posted on Ukrainian Websites and Social Media,"['quickly', 'debunked', 'deepfaked', 'video', 'ukrainian', 'president', 'volodymyr', 'zelenskyy', 'wa', 'posted', 'various', 'ukrainian', 'website', 'social_medium', 'platform', 'encouraging', 'ukrainian', 'surrender', 'russian', 'force', 'russia_ukraine', 'war']",SOCIAL HARM
178,175,"[1553,1554,1606,1607,1608]","An autonomous Chevy Bolt operated by Cruise was pulled over in San Francisco, and as the police attempted to engage with the car, it reportedly bolted off, pulled over again, and put on its hazards lights on at a point farther down the road.",Cruise Autonomous Taxi Allegedly Bolted off from Police After Being Pulled over in San Francisco,"['autonomous', 'chevy', 'bolt', 'operated', 'cruise', 'wa', 'pulled', 'san_francisco', 'police', 'attempted', 'engage', 'car', 'reportedly', 'bolted', 'pulled', 'put', 'hazard', 'light', 'point', 'farther', 'road']",SECURITY AND SAFETY
179,178,"[1560,1565,1566,1567,1568,1569,1570,1594]"," A Tesla Model Y was shown on video slowly crashing into a Vision Jet in Spokane, Washington, allegedly due to its owner activating the “Smart Summon” feature.","Tesla Owner Activated ""Smart Summon"" Feature, Causing a Collision with an Aircraft in a Washington Airport","['tesla_model', 'wa_shown', 'video', 'slowly', 'crashing', 'vision', 'jet', 'spokane', 'washington', 'allegedly_due', 'owner', 'activating', 'smart', 'summon', 'feature']",SECURITY AND SAFETY
180,180,"[1564,1582,2236]","The AI system used by the Malaysian judiciary which explicitly considered age, employment, and socio-economic data provided sentencing to a drug possession case that was alleged by lawyer to be disproportionately high for the crime committed.",Algorithm Used by the Malaysian Judiciary Reportedly Recommended Unusually High Sentencing to a Drug Possession Case,"['ai', 'system', 'used', 'malaysian', 'judiciary', 'explicitly_considered', 'age', 'employment', 'socio', 'economic', 'data', 'provided', 'sentencing', 'drug', 'possession', 'case', 'wa_alleged', 'lawyer', 'disproportionately', 'high', 'crime', 'committed']",SOCIAL HARM
181,183,"[1576,1577,1578,1579,1580,2066]"," Airbnb allegedly considered publicly available data on users to gauge their trustworthiness via algorithmic assessment of personality and behavioral traits, resulting in unexplained bans and discriminatory bans against sex workers.","Airbnb's Trustworthiness Algorithm Allegedly Banned Users without Explanation, and Discriminated against Sex Workers","['airbnb', 'allegedly', 'considered', 'publicly_available', 'data', 'user', 'gauge', 'trustworthiness', 'via', 'algorithmic', 'assessment', 'personality', 'behavioral', 'trait', 'resulting', 'unexplained', 'ban', 'discriminatory', 'ban', 'sex_worker']",OPERATIONAL INCIDENT
182,220,"[1731,1732,1969,2061]","Facebook’s AI mistakenly blocked advertisements by small and struggling businesses, after the company allegedly leaned more on algorithms to monitor ads on the platform with little review from human moderators.",Facebook Mistakenly Blocked Small Business Ads,"['facebook', 'ai', 'mistakenly', 'blocked', 'advertisement', 'small', 'struggling', 'business', 'company', 'allegedly', 'leaned', 'algorithm', 'monitor', 'ad', 'platform', 'little', 'review', 'human', 'moderator']",OPERATIONAL INCIDENT
183,194,[1621],"In early 2018, an Australian telecommunications company’s incident management AI excessively deployed technicians into the field, and was allegedly unable to be stopped by the automation team.","Australian Telco’s Incident Management Bot Excessively Sent Technicians in the Field by Mistake, Allegedly Costing Millions","['early', '2018', 'australian', 'telecommunication', 'company', 'incident', 'management', 'ai', 'excessively', 'deployed', 'technician', 'field', 'wa', 'allegedly', 'unable', 'stopped', 'automation', 'team']",OPERATIONAL INCIDENT
184,200,[1653],"Fraudsters allegedly used AI voice technology to impersonate the boss of a UK-based firm's CEO, demanding a transfer of €220,000 over the phone.",Fraudsters Used AI to Mimic Voice of a UK-Based Firm's CEO's Boss,"['fraudsters', 'allegedly', 'used', 'ai', 'voice', 'technology', 'impersonate', 'bos', 'uk', 'based', 'firm', 'ceo', 'demanding', 'transfer', '220', '000', 'phone']",SOCIAL HARM
185,206,"[1675,1676,1677,1678]","Tinder’s personalized pricing was found by Consumers International to consider age as a major determinant of pricing, and could be considered a direct discrimination based on age, according to anti-discrimination law experts.",Tinder's Personalized Pricing Algorithm Found to Offer Higher Prices for Older Users,"['tinder', 'personalized', 'pricing', 'wa', 'found', 'consumer', 'international', 'consider', 'age', 'major', 'determinant', 'pricing', 'could', 'considered', 'direct', 'discrimination', 'based', 'age', 'according', 'anti', 'discrimination', 'law', 'expert']",SOCIAL HARM
186,186,"[1590,1591,1592,1593,1788,1933,1934]"," In Spain, the algorithm that assesses recidivism risk in gender violence, VioGén, have critically underestimated the level of risk in a series of cases that ended in homicide of women and children since its first deployment.","Algorithm Assessing Risk Faced by Victims of Gender Violence Misclassified Low-Risk Cases, Allegedly Leading to Homicide of Women and Children in Spain","['spain', 'algorithm_ass', 'recidivism_risk', 'gender', 'violence', 'viogén', 'critically', 'underestimated', 'level', 'risk', 'series', 'case', 'ended', 'homicide', 'woman', 'child', 'since', 'first', 'deployment']",SOCIAL HARM
187,202,"[1655,1656,1657,1658,1721]",A South Korean political candidate created a deepfake avatar which political opponents alleged to be fraudulent and a threat to democracy.,Korean Politician Employed Deepfake as Campaign Representative,"['south', 'korean', 'political', 'candidate', 'created', 'deepfake', 'avatar', 'political', 'opponent', 'alleged', 'fraudulent', 'threat', 'democracy']",SOCIAL HARM
188,216,"[1724,1924,1925,1926,1927]",The Chinese platform WeChat provided an inappropriate and racist English translation for the Chinese term for “black foreigner” in its messaging app.,WeChat’s Machine Translation Gave a Racist English Translation for the Chinese Term for “Black Foreigner”,"['chinese', 'platform', 'wechat', 'provided', 'inappropriate', 'racist', 'english_translation', 'chinese', 'term', 'black', 'foreigner', 'messaging', 'app']",SOCIAL HARM
189,221,"[1733,1734]","In Taiwan, a Tesla Model 3 on Autopilot mode whose driver did not pay attention to the road collided with a road repair truck; a road engineer immediately placed crash warnings in front of the Tesla, but soon after got hit and was killed by a BMW when its driver failed to see the sign and crashed into the accident.",A Road Engineer Killed Following a Collision Involving a Tesla on Autopilot,"['taiwan', 'tesla_model', '3', 'autopilot_mode', 'whose', 'driver', 'pay', 'attention', 'road', 'collided', 'road', 'repair', 'truck', 'road', 'engineer', 'immediately', 'placed', 'crash', 'warning', 'front', 'tesla', 'soon', 'got', 'hit', 'wa', 'killed', 'bmw', 'driver', 'failed', 'see', 'sign', 'crashed', 'accident']",SECURITY AND SAFETY
190,179,"[1561,1562,1874]","Developers of OpenAI's DALL-E 2 cited risks of the model, varying from misuse as disinformation and explicit content generation, to gender and racial bias.",DALL-E 2 Reported for Gender and Racially Biased Outputs,"['developer', 'openai', 'dall_e', '2', 'cited', 'risk', 'model', 'varying', 'misuse', 'disinformation', 'explicit', 'content', 'generation', 'gender', 'racial_bias']",SOCIAL HARM
191,172,[1550],"NarxCare's algorithm assessing a patient’s overdose risk allegedly did not undergo peer-reviewed validation studies, and considered sensitive data with high risk of biases towards women and Black patients such as experience of sexual abuse and criminality.",NarxCare’s Risk Score Model Allegedly Lacked Validation and Trained on Data with High Risk of Bias,"['narxcare', 'algorithm', 'assessing', 'patient', 'overdose', 'risk', 'allegedly', 'undergo', 'peer', 'reviewed', 'validation', 'study', 'considered', 'sensitive', 'data', 'high', 'risk', 'bias', 'towards', 'woman', 'black_patient', 'experience', 'sexual_abuse', 'criminality']",SOCIAL HARM
192,181,"[1571,1572]","A BMW Sedan reportedly made an illegal left turn, causing a minor collision but no injuries with a Cruise autonomous vehicle (AV) operating in autonomous mode.","BMW Sedan Made a Prohibited Left Turn, Colliding with a Cruise Autonomous Vehicle","['bmw', 'sedan', 'reportedly', 'made', 'illegal', 'left_turn', 'causing_minor', 'collision', 'injury', 'cruise_autonomous', 'vehicle', 'av', 'operating', 'autonomous_mode']",SECURITY AND SAFETY
193,190,"[1610,1611,1612,1613]"," ByteDance allegedly scraped short-form videos, usernames, profile pictures, and descriptions of accounts on Instagram, Snapchat, and other sources, and uploaded them without consent on Flipagram, TikTok’s predecessor, in order to improve its “For You” algorithm's performance on American users.","ByteDance Allegedly Trained ""For You"" Algorithm Using Content Scraped without Consent from Other Social Platforms","['bytedance', 'allegedly', 'scraped', 'short', 'form', 'video', 'usernames', 'profile', 'picture', 'description', 'account', 'instagram', 'snapchat', 'source', 'uploaded', 'without_consent', 'flipagram', 'tiktok', 'predecessor', 'order', 'improve', 'algorithm', 'performance', 'american', 'user']",OPERATIONAL INCIDENT
194,177,"[1558,1583,1600,1601,1602]","Google’s “inclusive language” feature prompting writers to consider alternatives to non-inclusive words reportedly also recommend alternatives for words such as “landlord” and “motherboard,” which critics said was a form of obtrusive, unnecessary, and bias-reinforcing speech-policing.",Google’s Assistive Writing Feature Provided Allegedly Unnecessary and Clumsy Suggestions,"['google', 'inclusive', 'language', 'feature', 'prompting', 'writer', 'consider', 'alternative', 'non', 'inclusive', 'word', 'reportedly', 'also', 'recommend', 'alternative', 'word', 'landlord', 'motherboard', 'critic_said', 'wa', 'form', 'obtrusive', 'unnecessary', 'bias', 'reinforcing', 'speech', 'policing']",SOCIAL HARM
195,188,"[1603,1604,1782,1605]","In 2018, during the abortion-decriminalization debate in Argentina, the Salta city government deployed a teenage-pregnancy predictive algorithm built by Microsoft that allegedly lacked a defined purpose, explicitly considered sensitive information such as disability and whether their home had access to hot water.",Argentinian City Government Deployed Teenage-Pregnancy Predictive Algorithm Using Invasive Demographic Data,"['2018', 'abortion', 'decriminalization', 'debate', 'argentina', 'salta', 'city', 'government', 'deployed', 'teenage', 'pregnancy', 'predictive', 'algorithm', 'built', 'microsoft', 'allegedly', 'lacked', 'defined', 'purpose', 'explicitly_considered', 'sensitive_information', 'disability', 'whether', 'home', 'access', 'hot', 'water']",OPERATIONAL INCIDENT
196,191,"[1614,1615]","The Korean Fair Trade Commission (FTC) imposed a 26.7B KRW on Naver for manipulating shopping and video search algorithms, favoring its own online shopping business to boost its market share. ",Korean Internet Portal Giant Naver Manipulated Shopping and Video Search Algorithms to Favor In-House Services,"['korean', 'fair', 'trade', 'commission', 'ftc', 'imposed', '26', '7b', 'krw', 'naver', 'manipulating', 'shopping', 'video', 'search', 'algorithm', 'favoring', 'online', 'shopping', 'business', 'boost', 'market', 'share']",OPERATIONAL INCIDENT
197,201,"[1654,2435]",A deepfake video showing the Belgium’s prime minister speaking of an urgent need to tackle the climate crises was released by a climate action group.,Climate Action Group Posted Deepfake of Belgian Prime Minister Urging Climate Crisis Action,"['deepfake', 'video', 'showing', 'belgium', 'prime', 'minister', 'speaking', 'urgent', 'need', 'tackle', 'climate', 'crisis', 'wa', 'released', 'climate', 'action', 'group']",SOCIAL HARM
198,204,"[1662,1663,1664,1665]","The firing of an employee at Zhihu, a large Q&A platform in China, was allegedly caused by the use of a behavioral perception algorithm which claimed to predict a worker’s resignation risk using their online footprints, such as browsing history and internal communication.",A Chinese Tech Worker at Zhihu Fired Allegedly via a Resignation Risk Prediction Algorithm,"['firing', 'employee', 'zhihu', 'large', 'q', 'platform', 'china', 'wa', 'allegedly_caused', 'use', 'behavioral', 'perception', 'algorithm', 'claimed', 'predict', 'worker', 'resignation', 'risk', 'using', 'online', 'footprint', 'browsing', 'history', 'internal', 'communication']",OPERATIONAL INCIDENT
199,209,"[1688,1689,1690,1691,1692]",The “rolling stop” functionality within the “Aggressive” Full Self Driving (FSD) profile that was released via a Tesla firmware update was recalled and disabled.,Tesla Disabled “Rolling Stop” Functionality Associated with the “Aggressive” Driving Mode,"['rolling', 'stop', 'functionality', 'within', 'aggressive', 'full_self', 'driving_fsd', 'profile', 'wa', 'released', 'via', 'tesla', 'firmware', 'update', 'wa', 'recalled', 'disabled']",SECURITY AND SAFETY
200,219,[1730],AI cameras installed by Ezemvelo KZN Wildlife failed to detect poachers when four dehorned rhino carcasses were found.,Poachers Evaded AI Cameras and Killed Four Rhinos,"['ai', 'camera', 'installed', 'ezemvelo', 'kzn', 'wildlife', 'failed', 'detect', 'poacher', 'four', 'dehorned', 'rhino', 'carcass', 'found']",OPERATIONAL INCIDENT
201,189,"[1609,1670,1671,1672,1673,1674]",People with disabilities were allegedly disproportionately targeted by a benefit fraud detection algorithm which the UK’s Department of Work and Pensions was urged to disclose.,Opaque Fraud Detection Algorithm by the UK’s Department of Work and Pensions Allegedly Discriminated against People with Disabilities,"['people_disability', 'allegedly', 'disproportionately', 'targeted', 'benefit', 'fraud', 'detection', 'algorithm', 'uk', 'department', 'work', 'pension', 'wa', 'urged', 'disclose']",OPERATIONAL INCIDENT
202,214,[1722],"SN Technologies allegedly misled Lockport City Schools about the performance of its AEGIS face and weapons detection systems, downplaying error rates for Black faces and weapon misidentification.",SN Technologies Reportedly Lied to a New York State School District about Its Facial and Weapon Detection Systems’ Performance,"['sn', 'technology', 'allegedly', 'misled', 'lockport', 'city', 'school', 'performance', 'aegis', 'face', 'weapon', 'detection_system', 'downplaying', 'error', 'rate', 'black', 'face', 'weapon', 'misidentification']",SOCIAL HARM
203,215,[1723],"Content moderators and employees at Facebook demand better working conditions, as automated content moderation system allegedly failed to achieve sufficient performance and exposed human reviewers to psychologically hazardous content such as graphic violence and child abuse.",Facebook Content Moderators Demand Better Working Conditions Due to Allegedly Inadequate AI Content Moderation,"['content', 'moderator', 'employee', 'facebook', 'demand', 'better', 'working', 'condition', 'automated_content', 'moderation_system', 'allegedly', 'failed', 'achieve', 'sufficient', 'performance', 'exposed', 'human', 'reviewer', 'psychologically', 'hazardous', 'content', 'graphic', 'violence', 'child_abuse']",SOCIAL HARM
204,192,"[1616,1617]",Three make-up artists lost their positions following an algorithmically-assessed video interview by HireVue who reportedly failed to provide adequate explanation of the findings.,Three Make-Up Artists Lost Jobs Following Black-Box Automated Decision by HireVue,"['three', 'make', 'artist', 'lost', 'position', 'following', 'algorithmically', 'assessed', 'video', 'interview', 'hirevue', 'reportedly', 'failed', 'provide', 'adequate', 'explanation', 'finding']",OPERATIONAL INCIDENT
205,217,"[1725,1726]","At the 18th China Hi-Tech Fair, a robot suddenly smashed through a glass booth and injured a visitor, after a staff member reportedly mistakenly pressed a button, causing it to reverse and accelerate.","Robot at a Chinese Tech Fair Smashed a Glass Booth, Injuring a Visitor","['18th', 'china', 'hi', 'tech', 'fair', 'robot', 'suddenly', 'smashed', 'glass', 'booth', 'injured', 'visitor', 'staff', 'member', 'reportedly', 'mistakenly', 'pressed', 'button', 'causing', 'reverse', 'accelerate']",OPERATIONAL INCIDENT
206,208,"[1683,1684,1685,1686,1687,1759,1760,1761]","In late 2021, Tesla owners’ complaints to the National Highway Traffic Safety Administration about sudden unexpected automatic braking rapidly increased, coinciding with when radar was no longer equipped in its Model 3 and Model Y vehicles.","Tesla Phantom Braking Complaints Surged, Allegedly Linked to Tesla Vision Rollout","['late', '2021', 'tesla', 'owner', 'complaint', 'national', 'highway', 'traffic', 'safety', 'administration', 'sudden', 'unexpected', 'automatic', 'braking', 'rapidly', 'increased', 'coinciding', 'radar', 'wa', 'longer', 'equipped', 'model_3', 'model', 'vehicle']",SECURITY AND SAFETY
207,212,"[1711,1712,1713,1714]",The Chinese electric vehicle (EV) firm XPeng Motors was fined by local market regulators for illegally collecting in-store customers’ facial images without their consent for six months.,XPeng Motors Fined For Illegal Collection of Consumers’ Faces Using Facial Recognition Cameras,"['chinese', 'electric', 'vehicle', 'ev', 'firm', 'xpeng', 'motor', 'wa', 'fined', 'local', 'market', 'regulator', 'illegally', 'collecting', 'store', 'customer', 'facial', 'image', 'without_consent', 'six_month']",PRIVACY VIOLATION
208,193,[1620],"Alerts about a Target data breach were ignored by Minneapolis Target’s staff reportedly due to them being included with many other potential false alerts, and due to some of the company’s network infiltration alerting systems being off to reduce such false alerts, causing private data theft for millions of customers.  ","Excessive Automated Monitoring Alerts Ignored by Staff, Resulting in Private Data Theft of Seventy Million Target Customers","['alert', 'target', 'data', 'breach', 'ignored', 'minneapolis', 'target', 'staff', 'reportedly', 'due', 'included', 'many', 'potential', 'false', 'alert', 'due', 'company', 'network', 'infiltration', 'alerting', 'system', 'reduce', 'false', 'alert', 'causing', 'private', 'data', 'theft', 'million', 'customer']",SECURITY AND SAFETY
209,196,"[1633,1634,1635,1636,1637]","When the leader of the Afghan Taliban was found possessing a valid ID card in the Pakistani national biometric identification database system, Pakistan launch a national re-verification campaign that is linked to numerous changes in recognition status and loss of services.",Compromise of National Biometric ID Card System Leads to Reverification and Change of Status,"['leader', 'afghan', 'taliban', 'wa', 'found', 'possessing', 'valid', 'id', 'card', 'pakistani', 'national', 'biometric', 'identification', 'database', 'system', 'pakistan', 'launch', 'national', 'verification', 'campaign', 'linked', 'numerous', 'change', 'recognition', 'status', 'loss', 'service']",OPERATIONAL INCIDENT
210,207,"[1679,1680,1681,1682]",Honolulu Police Department spent federal pandemic relief funds on a robot dog to take body temperatures and patrol a homeless quarantine encampment which local civil rights advocates criticized as dehumanizing.,Hawaii Police Deployed Robot Dog to Patrol a Homeless Encampment,"['honolulu', 'police_department', 'spent', 'federal', 'pandemic', 'relief', 'fund', 'robot', 'dog', 'take', 'body', 'temperature', 'patrol', 'homeless', 'quarantine', 'encampment', 'local', 'civil', 'right', 'advocate', 'criticized', 'dehumanizing']",SECURITY AND SAFETY
211,211,"[1696,1697,1698,1699,1700,1701,1702]","In Paris, about 20 people were injured in an accident involving a Tesla Model 3 taxi cab which was reportedly caused by a sudden unintended acceleration (SUA) episode and braking issues.",A Tesla Taxi Cab Involved in an Accident in Paris with Twenty Injuries,"['paris', '20', 'people', 'injured', 'accident', 'involving', 'tesla_model', '3', 'taxi', 'cab', 'wa', 'reportedly', 'caused', 'sudden', 'unintended', 'acceleration', 'sua', 'episode', 'braking', 'issue']",SECURITY AND SAFETY
212,187,"[1596,1597,1598]","A YouTuber who was a Tesla’s employee conducted an on-road review of Tesla's Full Self Driving (FSD) Beta, showing its navigation in various road environments in San Jose and collision with a bollards during Autopilot, allegedly causing his dismissal from the company.","YouTuber Tested Tesla on Self Driving Mode, Colliding with Street Pylons","['youtuber', 'wa', 'tesla', 'employee', 'conducted', 'road', 'review', 'tesla', 'full_self', 'driving_fsd', 'beta', 'showing', 'navigation', 'various', 'road', 'environment', 'san', 'jose', 'collision', 'bollard', 'autopilot', 'allegedly', 'causing', 'dismissal', 'company']",SECURITY AND SAFETY
213,185,"[1586,1587,1588,1589]", An investigation by NewsGuard into TikTok’s handling of content related to the Russia-Ukraine war showed its “For You” algorithm pushing new users towards false and misleading content about the war within less than an hour of signing up.,"TikTok's ""For You"" Algorithm Directed New Users towards Disinformation about the War in Ukraine","['investigation', 'newsguard', 'tiktok', 'handling', 'content', 'related', 'russia_ukraine', 'war', 'showed', 'algorithm', 'pushing', 'new', 'user', 'towards', 'false', 'misleading', 'content', 'war', 'within', 'le', 'hour', 'signing']",OPERATIONAL INCIDENT
214,205,"[1666,1667,1668,1669]","According to security reports by Meta, fictitious personas with GAN-generated profile pictures were used by people operating in Russia and Ukraine to push a disinformation campaign targeting Ukrainian social media users, and were taken down.",AI-Generated Profiles Used in Disinformation Campaign Targeting Ukrainians,"['according', 'security', 'report', 'meta', 'fictitious', 'persona', 'gan_generated', 'profile', 'picture', 'used', 'people', 'operating', 'russia_ukraine', 'push', 'disinformation', 'campaign', 'targeting', 'ukrainian', 'social_medium', 'user', 'taken']",SOCIAL HARM
215,218,"[1727,1728,1950]","On a highway in Taiwan, a Tesla Sedan, reportedly operating on Autopilot mode, crashed into a large overturned truck, barely missing a pedestrian.",Tesla on Autopilot Crashed into Flipped Truck on Taiwan Highway,"['highway', 'taiwan', 'tesla_sedan', 'reportedly', 'operating_autopilot', 'mode_crashed', 'large', 'overturned', 'truck', 'barely', 'missing', 'pedestrian']",SECURITY AND SAFETY
216,197,"[1638,1639,1640,1641]","Facebook's internal report showed an at-least six-month long alleged software bug that caused moderator-flagged posts and other harmful content to evade down-ranking filters, leading to surges of misinformation on users' News Feed.","Facebook Internally Reported Failure of Ranking Algorithm, Exposing Harmful Content to Viewers over Months","['facebook', 'internal', 'report', 'showed', 'least', 'six_month', 'long', 'alleged', 'software', 'bug', 'caused', 'moderator', 'flagged', 'post', 'harmful_content', 'evade', 'ranking', 'filter', 'leading', 'surge', 'misinformation', 'user', 'news_feed']",OPERATIONAL INCIDENT
217,199,"[1647,1648,1649,1650,1651,2024,2031]","Ever AI, now Paravision AI, allegedly failed to inform customers about the development and use of facial recognition that facilitates the sale of customers’ data to various businesses, a business model that critics said was an egregious violation of privacy.",Ever AI Reportedly Deceived Customers about FRT Use in App,"['ever', 'ai', 'paravision', 'ai', 'allegedly', 'failed', 'inform', 'customer', 'development', 'use_facial', 'recognition', 'facilitates', 'sale', 'customer', 'data', 'various', 'business', 'business', 'model', 'critic_said', 'wa', 'egregious', 'violation', 'privacy']",PRIVACY VIOLATION
218,210,"[1693,1694,1695]","The Indian political social media app Tek Fog allegedly allowed operatives affiliated with the ruling political party to hijack social media trends and manipulate public opinion on other apps such as Twitter and WhatsApp, which opposition parties denounced as a national security threat.",Indian Political App Tek Fog Allegedly Hijacked Trends and Manipulated Public Opinion on Other Social Media Platforms,"['indian', 'political', 'social_medium', 'app', 'tek', 'fog', 'allegedly', 'allowed', 'operative', 'affiliated', 'ruling', 'political', 'party', 'hijack', 'social_medium', 'trend', 'manipulate', 'public', 'opinion', 'apps', 'twitter', 'whatsapp', 'opposition', 'party', 'denounced', 'national', 'security', 'threat']",SOCIAL HARM
219,235,[1756],"Customers’ untrustworthiness and unprofitability were reportedly determined by Ping An, a large insurance company in China, via facial-recognition measurements of micro-expressions and body-mass indices (BMI), which critics argue was likely to make mistakes, discriminate against certain ethnic groups, and undermine its own industry.","Chinese Insurer Ping An Employed Facial Recognition to Determine Customers’ Untrustworthiness, Which Critics Alleged to Likely Make Errors and Discriminate","['customer', 'untrustworthiness', 'unprofitability', 'reportedly', 'determined', 'ping', 'large', 'insurance', 'company', 'china', 'via_facial', 'recognition', 'measurement', 'micro', 'expression', 'body', 'mass', 'index', 'bmi', 'critic', 'argue', 'wa', 'likely', 'make', 'mistake', 'discriminate', 'certain', 'ethnic', 'group', 'undermine', 'industry']",SOCIAL HARM
220,227,"[1744,1973,1974]","The tourists driving through Vermont blamed Waze for directing them into a boat launch in Lake Champlain, prompting the vehicle to slide into the water by the time the drivers realized their location in the dark and foggy weather.","Waze App Allegedly Caused Tourists’ Car to End up in Lake Champlain, Vermont","['tourist', 'driving', 'vermont', 'blamed', 'waze', 'directing', 'boat', 'launch', 'lake', 'champlain', 'prompting', 'vehicle', 'slide', 'water', 'time', 'driver', 'realized', 'location', 'dark', 'foggy', 'weather']",SOCIAL HARM
221,222,[1735],"Tweets created by Thoughts, a tweet generation app that leverages OpenAI’s GPT-3, allegedly exhibited toxicity when given prompts related to minority groups.",Thoughts App Allegedly Created Toxic Tweets,"['tweet', 'created', 'thought', 'tweet', 'generation', 'app', 'leverage', 'openai_gpt', '3', 'allegedly', 'exhibited', 'toxicity', 'given', 'prompt', 'related', 'minority', 'group']",SOCIAL HARM
222,223,[1737],"Facial-recognition locks by Hive Box, an express delivery locker company in China, were easily opened by a group of fourth-graders in a science-club demo using only a printed photo of the intended recipient’s face, leaving contents vulnerable to theft.",Hive Box Facial-Recognition Locks Hacked by Fourth Graders Using Intended Recipient’s Facial Photo,"['facial_recognition', 'lock', 'hive', 'box', 'express', 'delivery', 'locker', 'company', 'china', 'easily', 'opened', 'group', 'fourth', 'grader', 'science', 'club', 'demo', 'using', 'printed', 'photo', 'intended', 'recipient', 'face', 'leaving', 'content', 'vulnerable', 'theft']",SECURITY AND SAFETY
223,229,"[1746,1747]",YouTube’s thumbnail monitoring system was allegedly evaded by content farms such as ones in Cambodia who spike viewership and generate ad revenue using bestiality-themed thumbnails.,Content Using Bestiality Thumbnails Allegedly Evaded YouTube’s Thumbnail Monitoring System,"['youtube', 'thumbnail', 'monitoring', 'system', 'wa', 'allegedly', 'evaded', 'content', 'farm', 'one', 'cambodia', 'spike', 'viewership', 'generate', 'ad', 'revenue', 'using', 'bestiality', 'themed', 'thumbnail']",SOCIAL HARM
224,224,[1738],"In China, fraudsters bypassed facial-recognition security for online financial transactions on WeChat Pay by crafting identity-verification GIFs of victims from their selfies on WeChat Moments, a social media platform.",WeChat Pay's Facial Recognition Security Evaded by Scammers Using Victims’ Social Media Content,"['china', 'fraudsters', 'bypassed', 'facial_recognition', 'security', 'online', 'financial', 'transaction', 'wechat', 'pay', 'crafting', 'identity', 'verification', 'gifs', 'victim', 'selfies', 'wechat', 'moment', 'social_medium', 'platform']",SECURITY AND SAFETY
225,239,[1764],"Gates-Foundation-funded Intensive Partnerships for Effective Teaching Initiative’s algorithmic program to assess teacher performance reportedly failed to achieve its goals for student outcomes, particularly for minority students, and was criticized for potentially causing harm against teachers.",Algorithmic Teacher Evaluation Program Failed Student Outcome Goals and Allegedly Caused Harm Against Teachers,"['gate', 'foundation', 'funded', 'intensive', 'partnership', 'effective', 'teaching', 'initiative', 'algorithmic', 'program', 'ass', 'teacher', 'performance', 'reportedly', 'failed', 'achieve', 'goal', 'student', 'outcome', 'particularly', 'minority', 'student', 'wa', 'criticized', 'potentially', 'causing', 'harm', 'teacher']",SOCIAL HARM
226,225,"[1739,1740]",Internal documents from IBM Watson Health showed negative assessments from customers such as Florida’s Jupiter Hospital and Memorial Sloan Kettering criticizing its Watson for Oncology product for allegedly unsafe and incorrect cancer treatment recommendations.,IBM Watson for Oncology Criticized by Customers for Allegedly Unsafe and Inaccurate Cancer Treatment Recommendations,"['internal', 'document', 'ibm', 'watson', 'health', 'showed', 'negative', 'assessment', 'customer', 'florida', 'jupiter', 'hospital', 'memorial', 'sloan', 'kettering', 'criticizing', 'watson', 'oncology', 'product', 'allegedly', 'unsafe', 'incorrect', 'cancer', 'treatment', 'recommendation']",SECURITY AND SAFETY
227,232,"[1751,1752,1975,2018]","A Tesla Model X operated on Autopilot reportedly failed to recognize the parked motorcycles, pedestrians, and van in its path in Kanagawa, Japan, and ran over a motorcyclist who previously stopped when a member of his motorcyclist group was involved in an accident.","Tesla Model X on Autopilot Missed Parked Vehicles and Pedestrians, Killing Motorcyclist in Japan","['tesla_model', 'x', 'operated', 'autopilot', 'reportedly', 'failed', 'recognize', 'parked', 'motorcycle', 'pedestrian', 'van', 'path', 'kanagawa', 'japan', 'ran', 'motorcyclist', 'previously', 'stopped', 'member', 'motorcyclist', 'group', 'wa_involved', 'accident']",SECURITY AND SAFETY
228,242,[1775],A sensor snag resulted in an automotive parts factory robot falling on a factory worker in India,Manufacturing Robot Failure Caused Factory Worker's Death in India,"['sensor', 'snag', 'resulted', 'automotive', 'part', 'factory', 'robot', 'falling', 'factory', 'worker', 'india']",SECURITY AND SAFETY
229,244,[1783],"An automated plate reader reportedly matched a license plate information, but of a family’s minivan and an alleged motorcycle in Montana that was reportedly stolen earlier in the year, resulting in them and their children being held at gunpoint and detained in handcuffs by multiple Aurora police officers.","Colorado Police’s Automated License Plate Reader (ALPR) Matched a Family’s Minivan’s Plate to That of a Stolen Vehicle Allegedly, Resulting in Detainment at Gunpoint","['automated', 'plate_reader', 'reportedly', 'matched', 'license_plate', 'information', 'family', 'minivan', 'alleged', 'motorcycle', 'montana', 'wa', 'reportedly', 'stolen', 'earlier', 'year', 'resulting', 'child', 'held', 'gunpoint', 'detained', 'handcuff', 'multiple', 'aurora', 'police_officer']",SECURITY AND SAFETY
230,233,[1753],"Tumblr’s automated tools to identify adult content were reported to have incorrectly flagged inoffensive images as explicit, following its announcement to ban all adult content on the platform.",Tumblr Automated Pornography-Detecting Algorithms Erroneously Flagged Inoffensive Images as Explicit,"['tumblr', 'automated', 'tool', 'identify', 'adult', 'content', 'reported', 'incorrectly', 'flagged', 'inoffensive', 'image', 'explicit', 'following', 'announcement', 'ban', 'adult', 'content', 'platform']",OPERATIONAL INCIDENT
231,230,[1748],"In Florida, a Model 3 Tesla on Autopilot mode crashed into a tractor-trailer truck, killing the 50-year-old driver.","Model 3 Tesla on Autopilot Crashed into a Truck in Florida, Killing Driver","['florida', 'model_3', 'tesla_autopilot', 'mode_crashed', 'tractor_trailer', 'truck', 'killing', '50', 'year_old', 'driver']",SECURITY AND SAFETY
232,246,"[1785,1787]","An automated license plate reader (ALPR) camera misread a 7 as a 2 and incorrectly alerted the local police about a stolen Oldsmobile car, which was allegedly not able to be verified by an officer before a traffic stop was effected on a BMW in Kansas City suburb.","Misreading of an Automated License Plate Reader (ALPR) Unverified by Police, Resulting in Traffic Stop in Missouri","['automated_license', 'plate_reader', 'alpr_camera', 'misread', '7', '2', 'incorrectly', 'alerted', 'local_police', 'stolen', 'oldsmobile', 'car', 'wa', 'allegedly', 'able', 'verified', 'officer', 'traffic', 'stop', 'wa', 'effected', 'bmw', 'kansa', 'city', 'suburb']",SECURITY AND SAFETY
233,228,[1745],"Near Los Angeles, Apple Maps allegedly directed a couple on a ski trip in the mountains toward into an unconventional route out of town, where the drivers found themselves lost and stuck on an unpaved road in the snow.",Apple Maps Allegedly Directed Ski Trip Couple Onto Unpaved Road in the Mountains,"['near', 'los_angeles', 'apple', 'map', 'allegedly', 'directed', 'couple', 'ski', 'trip', 'mountain', 'toward', 'unconventional', 'route', 'town', 'driver', 'found', 'lost', 'stuck', 'unpaved', 'road', 'snow']",SECURITY AND SAFETY
234,231,"[1749,1750,208,1945]","A Tesla Model S collided with and killed a road sweeper on a highway near Handan, China, an accident where Tesla previously said it was not able to determine whether Autopilot was operating at the time of the crash.",A Tesla Crashed into and Killed a Road Sweeper on a Highway in China,"['tesla_model', 'collided', 'killed', 'road', 'sweeper', 'highway', 'near', 'handan', 'china', 'accident', 'tesla', 'previously', 'said', 'wa', 'able', 'determine', 'whether', 'autopilot', 'wa', 'operating', 'time', 'crash']",SECURITY AND SAFETY
235,245,[1784],"In San Francisco, an automated license plate reader (ALPR) camera misread a number as belonging to a stolen vehicle having the wrong make, but its photo was not visually confirmed by the police due to poor quality and allegedly despite multiple chances prior to making a traffic stop, causing an innocent person to be pulled over at gunpoint and restrained in handcuffed.",Unverified Misreading by Automated Plate Reader Led to Traffic Stop and Restraint of an Innocent Person at Gunpoint in California,"['san_francisco', 'automated_license', 'plate_reader', 'alpr_camera', 'misread', 'number', 'belonging', 'stolen', 'vehicle', 'wrong', 'make', 'photo', 'wa', 'visually', 'confirmed', 'police', 'due', 'poor_quality', 'allegedly', 'despite', 'multiple', 'chance', 'prior', 'making', 'traffic', 'stop', 'causing', 'innocent', 'person', 'pulled', 'gunpoint', 'restrained', 'handcuffed']",SECURITY AND SAFETY
236,248,"[1789,1790]","In Oakland, a previously stolen rental car that was returned but allegedly not updated in the police database was pinged by an automated license plate reader (ALPR) camera, leading to police’s wrongful detainment of an innocent person reportedly using excessive force and improper conduct.","Automated License Plate Camera Notified Police about a Previously Stolen Rental Car that was Returned, Causing an Innocent Person to be Detained at Gunpoint in California","['oakland', 'previously', 'stolen', 'rental', 'car', 'wa', 'returned', 'allegedly', 'updated', 'police', 'database', 'wa', 'pinged', 'automated_license', 'plate_reader', 'alpr_camera', 'leading', 'police', 'wrongful', 'detainment', 'innocent', 'person', 'reportedly', 'using', 'excessive', 'force', 'improper', 'conduct']",SECURITY AND SAFETY
237,236,[1757],GAN faces were allegedly used by scammers alongside a parked domain and a fake website to impersonate a Boston law firm.,AI-Generated Faces Used by Scammers to Pose as a Law Firm in Boston,"['gan', 'face', 'allegedly', 'used', 'scammer', 'alongside', 'parked', 'domain', 'fake', 'website', 'impersonate', 'boston', 'law', 'firm']",SOCIAL HARM
238,234,"[1754,1755]","Waze app was blamed by Los Gatos town residents for contributing to high wildfire hazard risk via allegedly routing weekend beach-going drivers through their neighborhoods, effectively choking off their single escape route in the event of a medical emergency or wildfire.","Waze Allegedly Frequently Routed Drivers through the Town of Los Gatos, Blocking Its Single Wildfire Escape Route","['waze', 'app', 'wa', 'blamed', 'los', 'gatos', 'town', 'resident', 'contributing', 'high', 'wildfire', 'hazard', 'risk', 'via', 'allegedly', 'routing', 'weekend', 'beach', 'going', 'driver', 'neighborhood', 'effectively', 'choking', 'single', 'escape', 'route', 'event', 'medical', 'emergency', 'wildfire']",SECURITY AND SAFETY
239,238,[1762],"Oregon’s Department of Human Services (DHS) stopped using its Safety at Screening Tool, that is aimed to predict the risk that children wind up in foster care or be investigated in the future, and opted for a new process allegedly to reduce disparities and improve racially equitable decision-making.",Oregon’s Screening Tool for Child Abuse Cases Discontinued Following Concerns of Racial Bias,"['oregon', 'department_human', 'service_dhs', 'stopped', 'using', 'safety', 'screening', 'tool', 'aimed', 'predict', 'risk', 'child', 'wind', 'foster', 'care', 'investigated', 'future', 'opted', 'new', 'process', 'allegedly', 'reduce', 'disparity', 'improve', 'racially', 'equitable', 'decision_making']",OPERATIONAL INCIDENT
240,226,"[1741,1742,1743]","For years, Waze has, in an attempt to cut travel times, allegedly caused more traffic and guided drivers to make unsafe and often un-permitted traffic decisions, which was described by a Los Angeles city council member as a threat to public safety.",Waze Allegedly Clogged Streets and Directed Drivers to Make Unsafe Traffic Decisions,"['year', 'waze', 'ha', 'attempt', 'cut', 'travel', 'time', 'allegedly_caused', 'traffic', 'guided', 'driver', 'make', 'unsafe', 'often', 'un', 'permitted', 'traffic', 'decision', 'wa', 'described', 'los_angeles', 'city', 'council', 'member', 'threat', 'public', 'safety']",SOCIAL HARM
241,241,"[1772,1773,1774,1776,1781]",A chess robot at a tournament in Russia broke the finger of a child who reached onto the board before the robot had completed its move,Chess-Playing Robot Broke Child's Finger in Russia,"['chess', 'robot', 'tournament', 'russia', 'broke', 'finger', 'child', 'reached', 'onto', 'board', 'robot', 'completed', 'move']",SECURITY AND SAFETY
242,240,"[1767,1768,1769,1770,2230]",Users of GitHub Copilot can produce source code subject to license requirements without attributing and licensing the code to the rights holder.,"GitHub Copilot, Copyright Infringement and Open Source Licensing","['user', 'github', 'copilot', 'produce', 'source', 'code', 'subject', 'license', 'requirement', 'without', 'attributing', 'licensing', 'code', 'right', 'holder']",SOCIAL HARM
243,243,"[1777,1778]","Bots by anonymous actors were found by researchers to make up roughly half of Twitter accounts participating in COVID-19 discussions, many of which posted tweets about “reopening America“.",Bots Allegedly Made up Roughly Half of Twitter Accounts in Discussions Surrounding COVID-19 Related Issues,"['bot', 'anonymous', 'actor', 'found', 'researcher', 'make', 'roughly', 'half', 'twitter', 'account', 'participating', 'covid_19', 'discussion', 'many', 'posted', 'tweet', 'reopening', 'america']",SOCIAL HARM
244,270,[1851],"Following Apple’s changes in ranking algorithm in its iTunes App Store, apps by allegedly reputable companies and local startups in China experienced significant drops in ranking order.","Apple Tweaked App Store Ranking Algorithms, Allegedly Resulted in Demotion of Local Apps in China","['following', 'apple', 'change', 'ranking', 'algorithm', 'itunes', 'app', 'store', 'apps', 'allegedly', 'reputable', 'company', 'local', 'startup', 'china', 'experienced', 'significant', 'drop', 'ranking', 'order']",OPERATIONAL INCIDENT
245,271,"[1852,1861,1862]","A Tesla Model 3 operating on Autopilot mode slammed into the back of a Harley-Davidson motorcycle on an interstate in Utah, throwing the rider from the bike and killing him instantly.",Tesla Model 3 Sedan on Autopilot Killed Motorcyclist in a Rear-End Collision in Utah,"['tesla_model', '3', 'operating_autopilot', 'mode', 'slammed', 'back', 'harley', 'davidson', 'motorcycle', 'interstate', 'utah', 'throwing', 'rider', 'bike', 'killing', 'instantly']",SECURITY AND SAFETY
246,268,"[1849,1929]","Automated permanent removal of violating social media content such as terrorism, violent extremism, and hate speech without archival allegedly prevented its potential use to investigate serious crimes and hamper criminal accountability efforts.",Permanent Removal of Social Media Content via Automated Tools Allegedly Prevented Investigative Efforts,"['automated', 'permanent', 'removal', 'violating', 'social_medium', 'content', 'terrorism', 'violent', 'extremism', 'hate_speech', 'without', 'archival', 'allegedly', 'prevented', 'potential', 'use', 'investigate', 'serious', 'crime', 'hamper', 'criminal', 'accountability', 'effort']",SOCIAL HARM
247,251,"[1794,2384,2975]","Amazon tweaked product-search algorithm to boost and guide customers towards more profitable in-house products instead of showing mainly most-relevant and best-selling listings, which its internal engineers and lawyers alleged to violate company’s best-for-customer principle.",Amazon Allegedly Tweaked Search Algorithm to Boost Its Own Products,"['amazon', 'tweaked', 'product', 'search', 'algorithm', 'boost', 'guide', 'customer', 'towards', 'profitable', 'house', 'product', 'instead', 'showing', 'mainly', 'relevant', 'best', 'selling', 'listing', 'internal', 'engineer', 'lawyer', 'alleged', 'violate', 'company', 'best', 'customer', 'principle']",OPERATIONAL INCIDENT
248,273,[1856],FaceApp’s algorithm was reported by a user to have predicted different genders for two mostly identical facial photos with only a slight difference in eyebrow thickness.,FaceApp Predicted Different Genders for Similar User Photos with Slight Variations,"['faceapp', 'algorithm', 'wa_reported', 'user', 'predicted', 'different', 'gender', 'two', 'mostly', 'identical', 'facial', 'photo', 'slight', 'difference', 'eyebrow', 'thickness']",SOCIAL HARM
249,259,"[1822,1842]","A YouTuber built GPT-4chan, a model based on OpenAI’s GPT-J and trained on posts containing racism, misogyny, and antisemitism collected from 4chan’s “politically incorrect” board, which he made publicly available, and deployed as multiple bots posting thousands of messages on the same 4chan board as a prank.","YouTuber Built, Made Publicly Available, and Released Model Trained on Toxic 4chan Posts as Prank","['youtuber', 'built', 'gpt', '4chan', 'model', 'based', 'openai_gpt', 'j', 'trained', 'post', 'containing', 'racism', 'misogyny', 'antisemitism', 'collected', '4chan', 'politically', 'incorrect', 'board', 'made', 'publicly_available', 'deployed', 'multiple', 'bot', 'posting', 'thousand', 'message', '4chan', 'board', 'prank']",OPERATIONAL INCIDENT
250,255,"[1805,1806,1807,1808,1809,1431,1811,1812,1813]","ShotSpotter audios were previously admitted to convict an innocent Black man in a murder case in Chicago, resulted in his nearly-one-year-long arrest before being dismissed by prosecutors as insufficient evidence.",Unreliable ShotSpotter Audio Previously Used to Convict Chicago Man in Murder Case,"['shotspotter', 'audio', 'previously', 'admitted', 'convict', 'innocent', 'black_man', 'murder', 'case', 'chicago', 'resulted', 'nearly', 'one', 'year', 'long', 'arrest', 'dismissed', 'prosecutor', 'insufficient', 'evidence']",SOCIAL HARM
251,266,"[1844,2532,2533,2534,2535,2536,2537,2538]","Replika's AI-powered ""digital companions"" was allegedly abused by their users, who posted on Reddit abusive behaviors and interactions such as using slurs, roleplaying violent acts, and stimulating sexual abuse.","Replika's ""AI Companions"" Reportedly Abused by Its Users","['replika', 'ai_powered', 'digital', 'companion', 'wa', 'allegedly', 'abused', 'user', 'posted', 'reddit', 'abusive', 'behavior', 'interaction', 'using', 'slur', 'roleplaying', 'violent', 'act', 'stimulating', 'sexual_abuse']",SOCIAL HARM
252,253,"[1796,1797,1798,1799]","Cruise’s autonomous vehicles were shown on video stopping in the middle of the road and causing blockages in San Francisco, as they were disabled allegedly due to lost connection to their company’s server.","Cruise's Self-Driving Cars Allegedly Lost Connection to Their Server, Causing Traffic Blockages in San Francisco","['cruise_autonomous', 'vehicle', 'shown_video', 'stopping', 'middle', 'road', 'causing', 'blockage', 'san_francisco', 'disabled', 'allegedly_due', 'lost', 'connection', 'company', 'server']",SECURITY AND SAFETY
253,249,"[1791,1792]",A suite of AI-powered digital surveillance systems involving facial recognition and analysis of biometric data were deployed by the Chinese government in Xinjiang to monitor and discriminate local Uyghur and other Turkic Muslims.,Government Deployed Extreme Surveillance Technologies to Monitor and Target Muslim Minorities in Xinjiang,"['suite', 'ai_powered', 'digital', 'surveillance', 'system_involving', 'facial_recognition', 'analysis', 'biometric_data', 'deployed', 'chinese', 'government', 'xinjiang', 'monitor', 'discriminate', 'local', 'uyghur', 'turkic', 'muslim']",PRIVACY VIOLATION
254,254,"[1804,2069]","A class-action lawsuit alleged Google failing to provide notice, obtain informed written consent, or publish data retention policies about the collection, storage, and analysis of its face-grouping feature in Google Photos, which violated Illinois Biometric Information Privacy Act (BIPA).","Google’s Face Grouping Allegedly Collected and Analyzed Users’ Facial Structure without Consent, Violated BIPA","['class_action', 'lawsuit', 'alleged', 'google', 'failing', 'provide', 'notice', 'obtain', 'informed', 'written', 'consent', 'publish', 'data', 'retention', 'policy', 'collection', 'storage', 'analysis', 'face', 'grouping', 'feature', 'google', 'photo', 'violated', 'illinois_biometric', 'information_privacy', 'act', 'bipa']",PRIVACY VIOLATION
255,256,[1814],"A car stop resulting in a DUI arrest of its driver was allegedly based solely on a ShotSpotter alert, the reliability of which came into question by public defenders, who subpoenaed the company to assess its gunshot alert system.",DUI Arrest Case Allegedly Based Only on ShotSpotter's Alert,"['car', 'stop', 'resulting', 'duo', 'arrest', 'driver', 'wa', 'allegedly', 'based', 'solely', 'shotspotter', 'alert', 'reliability', 'came', 'question', 'public', 'defender', 'subpoenaed', 'company', 'ass', 'gunshot', 'alert', 'system']",SOCIAL HARM
256,250,[1793],"A home value generated by a black-box algorithm was reportedly defended by the Castricum court, which was criticized by a legal specialist for setting a dangerous precedent for accepting black-box algorithms as long as their results appear reasonable.",Dutch City Court Defended Home Value Generated by Black-Box Algorithm,"['home', 'value', 'generated', 'black', 'box', 'algorithm', 'wa', 'reportedly', 'defended', 'castricum', 'court', 'wa', 'criticized', 'legal', 'specialist', 'setting', 'dangerous', 'precedent', 'accepting', 'black', 'box', 'algorithm', 'long', 'result', 'appear', 'reasonable']",OPERATIONAL INCIDENT
257,258,"[1819,1820]","Major Australian retailers reportedly analyzed in-store footage to capture facial features of their customers without consent, which was criticized by consumer groups as creepy and invasive.",Australian Retailers Reportedly Captured Face Prints of Their Customers without Consent,"['major', 'australian', 'retailer', 'reportedly', 'analyzed', 'store', 'footage', 'capture', 'facial', 'feature', 'customer', 'without_consent', 'wa', 'criticized', 'consumer', 'group', 'creepy', 'invasive']",PRIVACY VIOLATION
258,274,"[1857,1859]","Virginia courts’ use of algorithmic predictions of future offending risks were found by researchers failing to reduce incarceration rates, showed racial and age disparities in risk scores and its application, and neither exacerbated or ameliorated historical racial differences in sentencing.",Virginia Courts’ Algorithmic Recidivism Risk Assessment Failed to Lower Incarceration Rates,"['virginia', 'court', 'use', 'algorithmic', 'prediction', 'future', 'offending', 'risk', 'found', 'researcher', 'failing', 'reduce', 'incarceration', 'rate', 'showed', 'racial', 'age', 'disparity', 'risk', 'score', 'application', 'neither', 'exacerbated', 'ameliorated', 'historical', 'racial', 'difference', 'sentencing']",SOCIAL HARM
259,267,"[1845,1846,1847,1848,2101,2141,2142,2143,2144,2226]","Face-matching algorithm by Clearview AI was built using scraped images from social media sites such as Instagram and Facebook without user consent, violating social media site policies, and allegedly privacy regulations.",Clearview AI Algorithm Built on Photos Scraped from Social Media Profiles without Consent,"['face', 'matching', 'algorithm', 'clearview', 'ai', 'wa', 'built', 'using', 'scraped', 'image', 'social_medium', 'site', 'instagram', 'facebook', 'without', 'user', 'consent', 'violating', 'social_medium', 'site', 'policy', 'allegedly', 'privacy', 'regulation']",PRIVACY VIOLATION
260,257,"[1815,1435,1821,2250]","Police departments disproportionately placed ShotSpotter sensors in black and brown neighborhoods, which is denounced by communities for allegedly creating dangerous situations, such as one involving in Adam Toledo's death.",Police Reportedly Deployed ShotSpotter Sensors Disproportionately in Neighborhoods of Color,"['police_department', 'disproportionately', 'placed', 'shotspotter', 'sensor', 'black', 'brown', 'neighborhood', 'denounced', 'community', 'allegedly', 'creating', 'dangerous', 'situation', 'one', 'involving', 'adam', 'toledo', 'death']",SECURITY AND SAFETY
261,264,[1839],"Speedcam Anywhere, an app allowing users to document and report traffic violations via AI-based videographic speed estimation of a vehicle, raised concerns for UK drivers about its capabilities for surveillance and abuse.",AI-Based Vehicle Speed Estimation App Denounced by UK Drivers as Surveillance Technology,"['speedcam', 'anywhere', 'app', 'allowing_user', 'document', 'report', 'traffic', 'violation', 'via', 'ai', 'based', 'videographic', 'speed', 'estimation', 'vehicle', 'raised_concern', 'uk', 'driver', 'capability', 'surveillance', 'abuse']",PRIVACY VIOLATION
262,252,[1795],"Axon Enterprise considered development of remotely operated drones capable of tasering at a target a short distance away as a defense mechanism for mass shootings, despite its internal AI ethics board’s previous objection and condemnation as dangerous and fantastical.",Remotely Operated Taser-Armed Drones Proposed by Taser Manufacturer as Defense for School Shootings in the US,"['axon', 'enterprise', 'considered', 'development', 'remotely', 'operated', 'drone', 'capable', 'tasering', 'target', 'short', 'distance', 'away', 'defense', 'mechanism', 'mass', 'shooting', 'despite', 'internal', 'ai', 'ethic', 'board', 'previous', 'objection', 'condemnation', 'dangerous', 'fantastical']",SECURITY AND SAFETY
263,272,"[1853,1854,1855]","Grab Indonesia was fined by the Indonesian Competition Commission (KPPU) for unfairly favoring drivers who rented cars via the Grab-affiliated company Teknologi Pengangkutan Indonesia (TPI), including offering more rides via their matchmaking algorithm.","Grab Tweaked Matchmaking Algorithm, Providing Preferential Treatment to Drivers Registered with Affiliated Car Rental Service","['grab', 'indonesia', 'wa', 'fined', 'indonesian', 'competition', 'commission', 'kppu', 'unfairly', 'favoring', 'driver', 'rented', 'car', 'via', 'grab', 'affiliated', 'company', 'teknologi', 'pengangkutan', 'indonesia', 'tpi', 'including', 'offering', 'ride', 'via', 'matchmaking', 'algorithm']",SECURITY AND SAFETY
264,260,"[1823,1831]","US Citizenship and Immigration Services (USCIS)’s ATLAS software used in vetting immigration requests was condemned by advocacy groups as a threat to naturalized citizens for its secretive algorithmic decision-making, reliance on poor quality data and unknown sources, and alleged discrimination of immigrants using biometric and sensitive information.",US DHS’s Opaque Vetting Software Allegedly Relied on Poor-Quality Data and Discriminated against Immigrants,"['u', 'citizenship', 'immigration', 'service', 'uscis', 'atlas', 'software', 'used', 'vetting', 'immigration', 'request', 'wa', 'condemned', 'advocacy_group', 'threat', 'naturalized', 'citizen', 'secretive', 'algorithmic', 'decision_making', 'reliance', 'poor_quality', 'data', 'unknown', 'source', 'alleged', 'discrimination', 'immigrant', 'using', 'biometric', 'sensitive_information']",SOCIAL HARM
265,261,"[1824,1825,1826,1827,1828,1829,1830,1832]","Society for the Prevention of Cruelty to Animals (SPCA) deployed a Knightscope robot to autonomously patrol the area outside its office and ward off homeless people, which was criticized by residents as a tool of intimidation and ordered by the city of San Francisco to stop its use on a public right-of-way.","Robot Deployed by Animal Shelter to Patrol Sidewalks outside Its Office, Warding off Homeless People in San Francisco","['society', 'prevention', 'cruelty', 'animal', 'spca', 'deployed', 'knightscope', 'robot', 'autonomously', 'patrol', 'area', 'outside', 'office', 'ward', 'homeless', 'people', 'wa', 'criticized', 'resident', 'tool', 'intimidation', 'ordered', 'city', 'san_francisco', 'stop', 'use', 'public', 'right', 'way']",SOCIAL HARM
266,262,"[1833,1834,1835,1836]",Publicly deployed open-source model DALL-E Mini was acknowledged by its developers and found by its users to have produced images which reinforced racial and gender biases.,DALL-E Mini Reportedly Reinforced or Exacerbated Societal Biases in Its Outputs as Gender and Racial Stereotypes,"['publicly', 'deployed', 'open_source', 'model', 'dall_e', 'mini', 'wa_acknowledged', 'developer', 'found', 'user', 'produced', 'image', 'reinforced', 'racial', 'gender_bias']",SOCIAL HARM
267,263,[1838],"YouTube’s personalization and recommendation algorithms were alleged to have pushed and exposed its young male users to political extremism and misinformation, driving them towards far-right ideologies such as neo-Nazism and white supremacy.",YouTube Recommendations Implicated in Political Radicalization of User,"['youtube', 'personalization', 'recommendation_algorithm', 'alleged', 'pushed', 'exposed', 'young', 'male', 'user', 'political', 'extremism', 'misinformation', 'driving', 'towards', 'far', 'right', 'ideology', 'neo', 'nazism', 'white', 'supremacy']",SOCIAL HARM
268,265,"[1840,1841]","A lawsuit by a former Uber Eats delivery driver alleged the company to have wrongfully dismissed him due to frequent false mismatches of his verification selfies, and discriminated against him via excessive verification checks.",Black Uber Eats Driver Allegedly Subjected to Excessive Photo Checks and Dismissed via FRT Results,"['lawsuit', 'former', 'uber', 'eats', 'delivery_driver', 'alleged', 'company', 'wrongfully', 'dismissed', 'due', 'frequent', 'false', 'mismatch', 'verification', 'selfies', 'discriminated', 'via', 'excessive', 'verification', 'check']",OPERATIONAL INCIDENT
269,278,"[1866,1867,1868]",The publicly launched conversational AI demo BlenderBot 3 developed by Meta was reported by its users and acknowledged by its developers to have “occasionally” made offensive and inconsistent remarks such as invoking Jewish stereotypes.,Meta’s BlenderBot 3 Chatbot Demo Made Offensive Antisemitic Comments,"['publicly', 'launched', 'conversational_ai', 'demo', 'blenderbot', '3', 'developed', 'meta', 'wa_reported', 'user', 'acknowledged', 'developer', 'occasionally', 'made', 'offensive', 'inconsistent', 'remark', 'invoking', 'jewish', 'stereotype']",SOCIAL HARM
270,275,"[1858,1860]",Facebook’s automated content moderation was acknowledged by a company spokesperson to have erroneously censored and banned Australian users from posting an article containing a 1890s photo of Aboriginal men in chains over nudity as historical evidence of slavery in Australia.,Facebook’s Moderation Algorithm Banned Users for Historical Evidence of Slavery,"['facebook_automated', 'content_moderation', 'wa_acknowledged', 'company', 'spokesperson', 'erroneously', 'censored', 'banned', 'australian', 'user', 'posting', 'article', 'containing', '1890s', 'photo', 'aboriginal', 'men', 'chain', 'nudity', 'historical', 'evidence', 'slavery', 'australia']",SOCIAL HARM
271,285,[1888],A book title by Korea’s first minister of culture was mistranslated into an offensive phrase by Google Lens’s camera-based translation feature allegedly due to its training on internet communications and a lack of context.,Google Lens’s Camera-Based Translation Feature Provided an Offensive Mistranslation of a Book Title in Korean,"['book', 'title', 'korea', 'first', 'minister', 'culture', 'wa', 'mistranslated', 'offensive', 'phrase', 'google', 'lens', 'camera', 'based', 'translation', 'feature', 'allegedly_due', 'training', 'internet', 'communication', 'lack', 'context']",SOCIAL HARM
272,330,[2017],Amazon’s “Amazon’s Choice” algorithm recommended poor-quality defective products and were reportedly susceptible to manipulation by inauthentic reviews.,“Amazon’s Choice” Algorithm Failed to Recommend Functional Products and Prone to Review Manipulation,"['amazon', 'amazon', 'choice', 'algorithm', 'recommended', 'poor_quality', 'defective', 'product', 'reportedly', 'susceptible', 'manipulation', 'inauthentic', 'review']",OPERATIONAL INCIDENT
273,299,[1935],"A man allegedly unblurred, using deepfake technology, pixelated pornographic images and videos of pornographic actors, which violated Japan’s obscenity law requiring images of genitalia to be obscured.",Japanese Porn Depixelated by Man using Deepfake,"['man', 'allegedly', 'unblurred', 'using', 'deepfake', 'technology', 'pixelated', 'pornographic', 'image', 'video', 'pornographic', 'actor', 'violated', 'japan', 'obscenity', 'law', 'requiring', 'image', 'genitalia', 'obscured']",PRIVACY VIOLATION
274,323,"[1992,1193,2006,2514]","A Tesla sedan on Autopilot mode collided with a parked Laguna Beach Police Department car, resulting in minor injuries for its driver in Laguna Beach, California.",Tesla on Autopilot Crashed into Parked Police Car in California,"['tesla_sedan', 'autopilot_mode', 'collided', 'parked', 'laguna', 'beach', 'police_department', 'car', 'resulting', 'minor', 'injury_driver', 'laguna', 'beach', 'california']",SECURITY AND SAFETY
275,293,"[1907,1908,1909,1910,1996,1997,2016]","A Cruise autonomous vehicle was involved in a crash at an intersection in San Francisco when making a left turn in front of a Toyota Prius traveling in an opposite direction, which caused occupants in both cars to sustain injuries.",Cruise’s Self-Driving Car Involved in a Multiple-Injury Collision at an San Francisco Intersection,"['cruise_autonomous', 'vehicle', 'wa_involved', 'crash', 'intersection', 'san_francisco', 'making', 'left_turn', 'front', 'toyota', 'prius', 'traveling', 'opposite', 'direction', 'caused', 'occupant', 'car', 'sustain', 'injury']",SECURITY AND SAFETY
276,325,"[2004,2005]",An Instagram user’s image containing violent content was reportedly used as advertisement on Facebook allegedly via automated means.,Offensive Instagram User Content Displayed as Facebook Ad,"['instagram', 'user', 'image', 'containing', 'violent', 'content', 'wa', 'reportedly', 'used', 'advertisement', 'facebook', 'allegedly', 'via', 'automated', 'mean']",SOCIAL HARM
277,328,"[2014,2032]","A pro-China propaganda campaign deployed fake accounts on Facebook, Twitter, and YouTube using GAN-synthesized faces to share and post comments on its content to gain wider circulation.",Fake Accounts Using GAN Faces Deployed by Propaganda Campaign on Social Platforms,"['pro', 'china', 'propaganda', 'campaign', 'deployed', 'fake', 'account', 'facebook', 'twitter', 'youtube', 'using', 'gan', 'synthesized', 'face', 'share', 'post', 'comment', 'content', 'gain', 'wider', 'circulation']",SOCIAL HARM
278,347,"[2060,2098,2099]","A Waymo self-driving taxi car was shown on video stranded on a road in Arizona while carrying a passenger, suddenly drove away from the company's roadside assistance worker, and ended up being stuck farther down the road.","Waymo Self-Driving Taxi Behaved Unexpectedly, Driving away from Support Crew","['waymo', 'self_driving', 'taxi', 'car', 'wa_shown', 'video', 'stranded', 'road', 'arizona', 'carrying', 'passenger', 'suddenly', 'drove', 'away', 'company', 'roadside', 'assistance', 'worker', 'ended', 'stuck', 'farther', 'road']",SECURITY AND SAFETY
279,350,"[2067,2094]",A Serve Robotics delivery robot was shown on video rolling through a crime scene blocked off by police tape.,Delivery Robot Rolled Through Crime Scene,"['serve', 'robotics', 'delivery_robot', 'wa_shown', 'video', 'rolling', 'crime', 'scene', 'blocked', 'police', 'tape']",OPERATIONAL INCIDENT
280,291,"[1901,1902,1903,2242,2590,2604]","California’s Department of Motor Vehicles (DMV) accused Tesla of false advertising in its promotion of Autopilot and Full Self-Driving (FSD) technologies, alleging the company to have made untrue or misleading claims with marketing language about the capabilities of its products.",Tesla Allegedly Misled Customers about Autopilot and FSD Capabilities,"['california', 'department', 'motor', 'vehicle', 'dmv', 'accused', 'tesla', 'false', 'advertising', 'promotion', 'autopilot', 'full_self', 'driving_fsd', 'technology', 'alleging', 'company', 'made', 'untrue', 'misleading', 'claim', 'marketing', 'language', 'capability', 'product']",SECURITY AND SAFETY
281,294,"[1911,1912,1913,1914]","Autopilot was alleged by its Tesla Model 3 driver to have unexpectedly malfunctioned, veering right without warning and crashing into a road divider near Thessaloniki, Greece, which resulted in damages to its wheel and door but no injury to the driver.",Tesla Autopilot Allegedly Malfunctioned in a Non-Fatal Collision in Greece,"['autopilot', 'wa_alleged', 'tesla_model', '3', 'driver', 'unexpectedly', 'malfunctioned', 'veering', 'right', 'without', 'warning', 'crashing', 'road', 'divider', 'near', 'thessaloniki', 'greece', 'resulted', 'damage', 'wheel', 'door', 'injury_driver']",SECURITY AND SAFETY
282,280,"[1872,1873]","Users selecting “no preference” were shown by Coffee Meets Bagels’s matching algorithm more potential matches with the same ethnicity, which was acknowledged and justified by its founder as a means to maximize connection rate without sufficient user information.",Coffee Meets Bagel’s Algorithm Reported by Users Disproportionately Showing Them Matches of Their Own Ethnicities Despite Selecting “No Preference”,"['user', 'selecting', 'preference', 'shown', 'coffee', 'meet', 'bagel', 'matching', 'algorithm', 'potential', 'match', 'ethnicity', 'wa_acknowledged', 'justified', 'founder', 'mean', 'maximize', 'connection', 'rate', 'without', 'sufficient', 'user', 'information']",SOCIAL HARM
283,287,[2471],"The French digital care company, Nabla, in researching GPT-3’s capabilities for medical documentation, diagnosis support, and treatment recommendation, found its inconsistency and lack of scientific and medical expertise unviable and risky in healthcare applications. This incident has been downgraded to an issue as it does not meet current ingestion criteria.",OpenAI’s GPT-3 Reported as Unviable in Medical Tasks by Healthcare Firm,"['french', 'digital', 'care', 'company', 'nabla', 'researching', 'gpt_3', 'capability', 'medical', 'documentation', 'diagnosis', 'support', 'treatment', 'recommendation', 'found', 'inconsistency', 'lack', 'scientific', 'medical', 'expertise', 'unviable', 'risky', 'healthcare', 'application', 'incident_ha', 'downgraded_issue', 'doe_meet', 'current_ingestion', 'criterion']",OPERATIONAL INCIDENT
284,295,"[1915,1916,1917,2102,2103]","New York Police Department (NYPD)’s facial recognition system falsely connected a Black teenager to a series of thefts at Apple stores, which resulted in his wrongful attempted arrest.",Wrongful Attempted Arrest for Apple Store Thefts Due to NYPD’s Facial Misidentification,"['new_york', 'police_department', 'nypd', 'facial_recognition', 'system', 'falsely', 'connected', 'black_teenager', 'series', 'theft', 'apple', 'store', 'resulted', 'wrongful', 'attempted', 'arrest']",SOCIAL HARM
285,320,"[1985,1986,1987,2007]","A Tesla Model S operating on Autopilot mode crashed into the back of a parked fire truck on a freeway in Culver City, California in a non-fatal collision.",Tesla on Autopilot Collided with Parked Fire Truck on California Freeway,"['tesla_model', 'operating_autopilot', 'mode_crashed', 'back', 'parked', 'fire_truck', 'freeway', 'culver', 'city', 'california', 'non', 'fatal', 'collision']",SECURITY AND SAFETY
286,326,"[2008,2012,2013]","Facebook’s “Year in Review” algorithm which compiled content in users’ past year as highlights inadvertently showed painful and unwanted memories to users, including death of family member.",Facebook Automated Year-in-Review Highlights Showed Users Painful Memories,"['facebook', 'year', 'review', 'algorithm', 'compiled', 'content', 'user', 'past', 'year', 'highlight', 'inadvertently', 'showed', 'painful', 'unwanted', 'memory_user', 'including', 'death', 'family', 'member']",SOCIAL HARM
287,335,"[2047,2090,2091,2092,2122,2123,2124,2125]","UK Home Office's algorithm to assess visa application risks explicitly considered nationality, allegedly caused candidates to face more scrutiny and discrimination.",UK Visa Streamline Algorithm Allegedly Discriminated Based on Nationality,"['uk', 'home', 'office', 'algorithm_ass', 'visa', 'application', 'risk', 'explicitly_considered', 'nationality', 'allegedly_caused', 'candidate', 'face', 'scrutiny', 'discrimination']",SOCIAL HARM
288,292,"[1904,1905,1906]",Apple’s autonomous cars were reported to have bumped into curbs and struggled to stay in their lanes after crossing intersections during an on-road test drives near the company’s Silicon Valley headquarters.,Apple’s AVs Reportedly Struggled to Navigate Streets in Silicon Valley Test Drives,"['apple', 'autonomous', 'car', 'reported', 'bumped', 'curb', 'struggled', 'stay', 'lane', 'crossing', 'intersection', 'road', 'test', 'drive', 'near', 'company', 'silicon', 'valley', 'headquarters']",SECURITY AND SAFETY
289,300,"[1936,1937]","TikTok’s “For You” algorithm allegedly boosted or was manipulated by an online personality to artificially boost his content which promotes extreme misogynistic views towards teenagers and men, despite breaking its rules.","TikTok's ""For You"" Algorithm Allegedly Abused by Online Personality to Promote Anti-Women Hate","['tiktok', 'algorithm', 'allegedly', 'boosted', 'wa', 'manipulated', 'online', 'personality', 'artificially', 'boost', 'content', 'promotes', 'extreme', 'misogynistic', 'view', 'towards', 'teenager', 'men', 'despite', 'breaking', 'rule']",SOCIAL HARM
290,318,"[1977,1978]","Facebook’s algorithmic recommendations reportedly continued showing advertisements for gun accessories and military gear, despite Facebook’s halt on weapons accessories ads following the US Capitol attack.",Facebook Recommended Military Gear Ads Despite Pause on Weapons Accessories Ads,"['facebook', 'algorithmic', 'recommendation', 'reportedly', 'continued', 'showing', 'advertisement', 'gun', 'accessory', 'military', 'gear', 'despite', 'facebook', 'halt', 'weapon', 'accessory', 'ad', 'following', 'u', 'capitol', 'attack']",SOCIAL HARM
291,319,"[1981,1982,1983,1984,1993]","A Tesla on Autopilot mode failed to see a parked fire truck and crashed into its rear on an interstate in Indiana, causing the death of an Arizona woman.",Tesla on Autopilot Fatally Crashed into Parked Fire Truck in Indiana,"['tesla_autopilot', 'mode', 'failed', 'see', 'parked', 'fire_truck', 'crashed', 'rear', 'interstate', 'indiana', 'causing', 'death', 'arizona', 'woman']",SECURITY AND SAFETY
292,332,"[2033,2040,2041,2044]","Google Image search reportedly showed disparate results along racial lines, featuring almost exclusively white women for “professional hairstyles” and black women for “unprofessional hairstyles” prompts.",Google Image Showed Racially Biased Results for “Professional” Hairstyles,"['google_image', 'search', 'reportedly', 'showed', 'disparate', 'result', 'along', 'racial', 'line', 'featuring', 'almost', 'exclusively', 'white', 'woman', 'professional', 'hairstyle', 'black', 'woman', 'unprofessional', 'hairstyle', 'prompt']",SOCIAL HARM
293,340,[2053],Honda's Collision Mitigation Braking System (CMBS) allegedly caused accidents to consumers due to frequent instances of false obstacle detection.,Honda's CMBS False Positives Allegedly Caused Accidents to Customers,"['honda', 'collision', 'mitigation', 'braking', 'system', 'cmb', 'allegedly_caused', 'accident', 'consumer', 'due', 'frequent', 'instance', 'false', 'obstacle', 'detection']",SECURITY AND SAFETY
294,341,"[2054,2114,2198,2199,2200]","Nissan's Automatic Emergency Braking (AEB) feature was reported in a series of complaints for false positives and abrupt braking behaviors, endangering car occupants and traffic participants. ","Nissan's ""Automatic Emergency Braking"" False Positives Posed Traffic Risks to Drivers","['nissan', 'automatic', 'emergency', 'braking', 'aeb', 'feature', 'wa_reported', 'series', 'complaint', 'false_positive', 'abrupt', 'braking', 'behavior', 'endangering', 'car', 'occupant', 'traffic', 'participant']",SECURITY AND SAFETY
295,334,"[2046,2077]","Uber developed a secret program ""Greyball"" which prevented known law enforcement officers in areas where its service violated regulations from receiving rides.",Uber Deployed Secret Program To Deny Local Authorities Rides,"['uber', 'developed', 'secret', 'program', 'greyball', 'prevented', 'known', 'law_enforcement', 'officer', 'area', 'service', 'violated', 'regulation', 'receiving', 'ride']",SECURITY AND SAFETY
296,305,"[1942,1943]",YouTube’s recommendation system and its focus on views and watched time were alleged by an advocacy group to have driven people towards climate denial and misinformation videos.,YouTube’s Recommendation Algorithm Allegedly Promoted Climate Misinformation Content,"['youtube_recommendation', 'system', 'focus', 'view', 'watched', 'time', 'alleged', 'advocacy_group', 'driven', 'people', 'towards', 'climate', 'denial', 'misinformation', 'video']",SOCIAL HARM
297,297,"[1921,1922,1923]","A self-driving shuttle deployed by Smart Columbus in Linden neighborhood unexpectedly stopped on the street, which caused a woman to fall onto the floor from her seat.","EasyMile Self-Driving Shuttle Unexpectedly Stopped Mid-Route, Injuring a Passenger","['self_driving', 'shuttle', 'deployed', 'smart', 'columbus', 'linden', 'neighborhood', 'unexpectedly', 'stopped', 'street', 'caused', 'woman', 'fall', 'onto', 'floor', 'seat']",SECURITY AND SAFETY
298,282,"[1879,1881,1972]","Facebook’s content moderation algorithm misidentified and removed a Canadian business’s advertisement containing a photo of onions as products of overtly sexual content, which was later reinstated after review.",Facebook’s Algorithm Mistook an Advertisement of Onions as Sexual Suggestive Content,"['facebook', 'content_moderation', 'algorithm', 'misidentified', 'removed', 'canadian', 'business', 'advertisement', 'containing', 'photo', 'onion', 'product', 'overtly', 'sexual_content', 'wa', 'later', 'reinstated', 'review']",OPERATIONAL INCIDENT
299,276,[1864],"Bucheon government’s use of facial recognition in analyzing CCTV footage, despite gaining wide public support, was scrutinized by privacy advocates and some lawmakers for collecting data without consent, and retaining and misusing data beyond pandemic needs.","Local South Korean Government’s Use of CCTV Footage Analysis via Facial Recognition to Track COVID Cases Raised Concerns about Privacy, Retention, and Potential Misuse","['bucheon', 'government', 'use_facial', 'recognition', 'analyzing', 'cctv', 'footage', 'despite', 'gaining', 'wide', 'public', 'support', 'wa', 'scrutinized', 'privacy', 'advocate', 'lawmaker', 'collecting', 'data_without', 'consent', 'retaining', 'misusing', 'data', 'beyond', 'pandemic', 'need']",PRIVACY VIOLATION
300,290,"[1900,2413,2414]","Toronto’s use of AI predictive modeling (AIPM) which had replaced existing methodology as the only determiner of beach water quality raised concerns about its accuracy, after allegedly conflicting results were found by a local water advocacy group using traditional means.",False Negatives for Water Quality-Associated Beach Closures,"['toronto', 'use', 'ai', 'predictive', 'modeling', 'aipm', 'replaced', 'existing', 'methodology', 'determiner', 'beach', 'water', 'quality', 'raised_concern', 'accuracy', 'allegedly', 'conflicting', 'result', 'found', 'local', 'water', 'advocacy_group', 'using', 'traditional', 'mean']",OPERATIONAL INCIDENT
301,296,"[1918,1919,1920]",Twitter’s “Home” timeline algorithm was revealed by its internal researchers to have amplified tweets and news of rightwing politicians and organizations more than leftwing ones in six out of seven studied countries.,Twitter Recommender System Amplified Right-Leaning Tweets,"['twitter', 'home', 'timeline', 'algorithm', 'wa', 'revealed', 'internal', 'researcher', 'amplified', 'tweet', 'news', 'rightwing', 'politician', 'organization', 'leftwing', 'one', 'six', 'seven', 'studied', 'country']",SOCIAL HARM
302,313,"[1967,3207]","Meta’s conversational AI BlenderBot 3, when prompted “who is a terrorist,“ responded with an incumbent Dutch politician’s name, who was confused about its association.",BlenderBot 3 Cited Dutch Politician as a Terrorist,"['meta', 'conversational_ai', 'blenderbot', '3', 'prompted', 'terrorist', 'responded', 'incumbent', 'dutch', 'politician', 'name', 'wa', 'confused', 'association']",SOCIAL HARM
303,333,"[2045,2135,2136,2137,2146,2148]","A Tesla Model Y on Autopilot collided with a parked Michigan State Police (MSP) car which had its emergency lights on, in Eaton County, Michigan, although no one was injured.",Tesla on Autopilot Crashed Parked Michigan Police Car on Interstate,"['tesla_model', 'autopilot', 'collided', 'parked', 'michigan', 'state', 'police', 'msp', 'car', 'emergency', 'light', 'eaton', 'county', 'michigan', 'although', 'one', 'wa', 'injured']",SECURITY AND SAFETY
304,304,[1941],"A Tesla Model Y in Full Self-Driving (FSD) mode drove into the wrong lane after making a left turn despite its driver allegedly attempting to overtake its driving, resulting in a non-fatal collision with another vehicle in the wrong lane in Brea, California.",Tesla on FSD Reportedly Drove into the Wrong Lane in California,"['tesla_model', 'full_self', 'driving_fsd', 'mode', 'drove', 'wrong', 'lane', 'making', 'left_turn', 'despite', 'driver', 'allegedly', 'attempting', 'overtake', 'driving', 'resulting', 'non', 'fatal', 'collision', 'another', 'vehicle', 'wrong', 'lane', 'brea', 'california']",SECURITY AND SAFETY
305,331,"[2022,2023]","A bug was reported by Instagram’s spokesperson to have prevented an algorithm from populating related hashtags for thousands of hashtags, resulting in an allege preferential treatment for some politically partisan hashtags.",Bug in Instagram’s “Related Hashtags” Algorithm Allegedly Caused Disproportionate Treatment of Political Hashtags,"['bug', 'wa_reported', 'instagram', 'spokesperson', 'prevented', 'algorithm', 'populating', 'related', 'hashtags', 'thousand', 'hashtags', 'resulting', 'allege', 'preferential', 'treatment', 'politically', 'partisan', 'hashtags']",SOCIAL HARM
306,337,"[2049,2071,2072,2112,2115,2116,2117,2118,2237]","A 2019 Tesla Model S was reportedly traveling on Adaptive Cruise Control (ACC) at high speed before crashing into a tree near The Woodlands in Spring, Texas, killing two people.","Tesla Model S on ACC Crashed into Tree in Texas, Killing Two People","['2019', 'tesla_model', 'wa', 'reportedly', 'traveling', 'adaptive', 'cruise_control', 'acc', 'high', 'speed', 'crashing', 'tree', 'near', 'woodland', 'spring', 'texas', 'killing', 'two', 'people']",SECURITY AND SAFETY
307,346,"[2059,2062,2108,2109,2110]",A number of robots employed by a hotel in Japan were reported by guests in a series of complaints for failing to handle tasks such as answering scheduling questions or making passport copies without human intervention.,Robots in Japanese Hotel Annoyed Guests and Failed to Handle Simple Tasks,"['number', 'robot', 'employed', 'hotel', 'japan', 'reported', 'guest', 'series', 'complaint', 'failing', 'handle', 'task', 'answering', 'scheduling', 'question', 'making', 'passport', 'copy', 'without', 'human', 'intervention']",OPERATIONAL INCIDENT
308,283,[1880],Facebook’s content moderation algorithm was acknowledged by the company to have flagged excerpts of the Declaration of Independence posted by a small newspaper in Texas as hate speech by mistake.,Facebook’s Automated Content Moderation Tool Flagged a Post Containing Parts of the Declaration of Independence as Hate Speech by Mistake,"['facebook', 'content_moderation', 'algorithm', 'wa_acknowledged', 'company', 'flagged', 'excerpt', 'declaration', 'independence', 'posted', 'small', 'newspaper', 'texas', 'hate_speech', 'mistake']",OPERATIONAL INCIDENT
309,286,"[1889,2052,2381]","TikTok’s recommendation algorithm was alleged in a lawsuit to have intentionally and repeatedly pushed videos of the “blackout” challenge onto children’s feeds, incentivizing their participation which ultimately resulted in the death of two young girls.","TikTok’s ""For You"" Allegedly Pushed Fatal “Blackout” Challenge Videos to Two Young Girls","['tiktok', 'recommendation_algorithm', 'wa_alleged', 'lawsuit', 'intentionally', 'repeatedly', 'pushed', 'video', 'blackout', 'challenge', 'onto', 'child', 'feed', 'incentivizing', 'participation', 'ultimately', 'resulted', 'death', 'two', 'young', 'girl']",SECURITY AND SAFETY
310,307,[1947],The Face ID feature on iPhone allowing users to unlock their phones via facial recognition was reported by users for not recognizing their faces in the morning.,iPhone Face ID Failed to Recognize Users’ Morning Faces,"['face', 'id', 'feature', 'iphone', 'allowing_user', 'unlock', 'phone', 'via_facial', 'recognition', 'wa_reported', 'user', 'recognizing', 'face', 'morning']",OPERATIONAL INCIDENT
311,309,"[1954,1956,1960,2030]",The facial recognition trial by London’s Metropolitan Police Service at the Notting Hill Carnival reportedly performed poorly with a high rate of false positives.,Facial Recognition Trial Performed Poorly at Notting Hill Carnival,"['facial_recognition', 'trial', 'london', 'metropolitan', 'police', 'service', 'notting', 'hill', 'carnival', 'reportedly', 'performed', 'poorly', 'high_rate', 'false_positive']",OPERATIONAL INCIDENT
312,327,[2011],Facebook’s “On This Day” algorithm which highlighted past posts on a user’s private page or News Feed confronted unwanted and painful personal memories to its users.,Facebook’s On-This-Day Feature Mistakenly Showed Painful Memories to Users,"['facebook', 'day', 'algorithm', 'highlighted', 'past', 'post', 'user', 'private', 'page', 'news_feed', 'confronted', 'unwanted', 'painful', 'personal', 'memory_user']",SOCIAL HARM
313,344,[2057],"Two AI interview softwares provided positive but invalid results such as ""competent"" English proficiency and high match percentage for interview responses given in German by reporters.",Hiring Algorithms Provided Invalid Positive Results for Interview Responses in German,"['two', 'ai', 'interview', 'software', 'provided', 'positive', 'invalid', 'result', 'competent', 'english', 'proficiency', 'high', 'match', 'percentage', 'interview', 'response', 'given', 'german', 'reporter']",OPERATIONAL INCIDENT
314,348,"[2064,2075,2096]",YouTube's recommendation algorithm allegedly pushed 2020's US Presidential Election fraud content to users most skeptical of the election's legitimacy disproportionately compared to least skeptical users.,YouTube Recommendation Reportedly Pushed Election Fraud Content to Skeptics Disproportionately,"['youtube_recommendation', 'algorithm', 'allegedly', 'pushed', '2020', 'u', 'presidential_election', 'fraud', 'content', 'user', 'skeptical', 'election', 'legitimacy', 'disproportionately', 'compared', 'least', 'skeptical', 'user']",SOCIAL HARM
315,349,"[2065,2095]","Evolv's AI-based weapons detection system reportedly produced excessive false positives, mistaking everyday school items for weapons and pulling schools' security personnel for manual checking.",Evolv's Gun Detection False Positives Created Problems for Schools,"['evolv', 'ai', 'based', 'weapon', 'detection_system', 'reportedly', 'produced', 'excessive', 'false_positive', 'mistaking', 'everyday', 'school', 'item', 'weapon', 'pulling', 'school', 'security', 'personnel', 'manual', 'checking']",OPERATIONAL INCIDENT
316,277,[1865],"An AI-synthetic audio sold as an NFT on Voiceverse’s platform was acknowledged by the company for having been created by 15.ai, a free web app specializing in text-to-speech and AI-voice generation, and reused without proper attribution.",Voices Created Using Publicly Available App Stolen and Resold as NFT without Attribution,"['ai', 'synthetic', 'audio', 'sold', 'nft', 'voiceverse', 'platform', 'wa_acknowledged', 'company', 'created', '15', 'ai', 'free', 'web', 'app', 'specializing', 'text', 'speech', 'ai', 'voice', 'generation', 'reused', 'without', 'proper', 'attribution']",SOCIAL HARM
317,311,"[1961,1962]","YouTube’s automated content moderation tool erroneously removed The Women of Sex Tech conference’s live-streamed event and banned the conference from the platform, despite not violating the platform’s sexual content policies.",YouTube Auto-Moderation Mistakenly Banned Women of Sex Tech Conference,"['youtube', 'automated_content', 'moderation_tool', 'erroneously', 'removed', 'woman', 'sex', 'tech', 'conference', 'live', 'streamed', 'event', 'banned', 'conference', 'platform', 'despite', 'violating', 'platform', 'sexual_content', 'policy']",SOCIAL HARM
318,317,[1976],"Facebook was reported by users for blocking posts of legitimate news about the coronavirus pandemic, allegedly due to a bug in an anti-spam system.",Bug in Facebook’s Anti-Spam Filter Allegedly Blocked Legitimate Posts about COVID-19,"['facebook', 'wa_reported', 'user', 'blocking', 'post', 'legitimate', 'news', 'coronavirus', 'pandemic', 'allegedly_due', 'bug', 'anti', 'spam', 'system']",OPERATIONAL INCIDENT
319,324,"[1998,1999,2000,2001,2002,2003]","A large network of pages, groups, and fake accounts having GAN-generated face photos associated with The BL, a US-based media outlet, reportedly bypassed Facebook moderation systems to push ""pro-Trump"" narratives on its platform and Instagram.",GAN Faces Deployed by The BL's Fake Account Network to Push Pro-Trump Content on Meta Platforms,"['large', 'network', 'page', 'group', 'fake', 'account', 'gan_generated', 'face', 'photo', 'associated', 'bl', 'u', 'based', 'medium', 'outlet', 'reportedly', 'bypassed', 'facebook', 'moderation_system', 'push', 'pro', 'trump', 'narrative', 'platform', 'instagram']",SOCIAL HARM
320,303,"[1940,1944]","Google’s automated detection of abusive images of children incorrectly flagged a parent’s photo intended for a healthcare provider, resulting in a false police report of child abuse, and loss of access to his online accounts and information.",Google’s Automated Child Abuse Detection Wrongfully Flagged a Parent’s Naked Photo of His Child,"['google', 'automated', 'detection', 'abusive', 'image', 'child', 'incorrectly', 'flagged', 'parent', 'photo', 'intended', 'healthcare', 'provider', 'resulting', 'false', 'police', 'report', 'child_abuse', 'loss', 'access', 'online', 'account', 'information']",SOCIAL HARM
321,339,"[2051,2063,2491,2511,2516,2539,2540,2575,2576,2593,2601,2634,2643,2755]","Students were reportedly using open-source text generative models such as GPT-3 and ChatGPT to complete school assignments and exams such as writing reports, essays.",Open-Source Generative Models Abused by Students to Cheat on Assignments and Exams,"['student', 'reportedly', 'using', 'open_source', 'text', 'generative', 'model', 'gpt_3', 'chatgpt', 'complete', 'school', 'assignment', 'exam', 'writing', 'report', 'essay']",SOCIAL HARM
322,343,"[2056,2113]","Facebook's, Instagram's, and Twitter's automated content moderation failed to proactively remove racist remarks and posts directing at Black football players after finals loss, allegedly largely relying on user reports of harassment.","Facebook, Instagram, and Twitter Failed to Proactively Remove Targeted Racist Remarks via Automated Systems","['facebook', 'instagram', 'twitter', 'automated_content', 'moderation', 'failed', 'proactively', 'remove', 'racist', 'remark', 'post', 'directing', 'black', 'football', 'player', 'final', 'loss', 'allegedly', 'largely', 'relying', 'user', 'report', 'harassment']",SOCIAL HARM
323,302,[1939],Dartmouth's Geisel School of Medicine allegedly falsely accused students of cheating during remote exams using an internally built system which tracked student activity patterns without their knowledge on its learning management platform.,Students Allegedly Wrongfully Accused of Cheating via Medical School's Internal Software,"['dartmouth', 'geisel', 'school', 'medicine', 'allegedly', 'falsely', 'accused', 'student', 'cheating', 'remote', 'exam', 'using', 'internally', 'built', 'system', 'tracked', 'student', 'activity', 'pattern', 'without', 'knowledge', 'learning', 'management', 'platform']",PRIVACY VIOLATION
324,308,"[1952,1953]","Boston Dynamics’s autonomous robot Atlas allegedly caught its foot on a stage light, resulting in a fall off the stage at the Congress of Future Science and Technology Leaders conference.",Atlas Robot Fell off Stage at Conference,"['boston', 'dynamic', 'autonomous', 'robot', 'atlas', 'allegedly', 'caught', 'foot', 'stage', 'light', 'resulting', 'fall', 'stage', 'congress', 'future', 'science', 'technology', 'leader', 'conference']",SECURITY AND SAFETY
325,310,"[1955,1957,1958,1959,2126,2127,2128,2269]",South Wales Police (SWP)’s automated facial recognition (AFR) at the Champion's League Final football game in Cardiff wrongly identified innocent people as potential matches at an extremely high false positive rate of more than 90%.,High False Positive Rate by SWP's Facial Recognition Use at Champion's League Final,"['south', 'wale', 'police', 'swp', 'automated', 'facial_recognition', 'afr', 'champion', 'league', 'final', 'football', 'game', 'cardiff', 'wrongly', 'identified', 'innocent', 'people', 'potential', 'match', 'extremely', 'high', 'false_positive', 'rate', '90']",OPERATIONAL INCIDENT
326,315,[1970],The facial recognition software FindFace allowing its users to match photos to people’s social media pages on Vkontakte was reportedly abused to de-anonymize and harass Russian women who appeared in pornography and alleged sex workers.,Facial Recognition Service Abused to Target Russian Porn Actresses,"['facial_recognition', 'software', 'findface', 'allowing_user', 'match', 'photo', 'people', 'social_medium', 'page', 'vkontakte', 'wa', 'reportedly_abused', 'de', 'anonymize', 'harass', 'russian', 'woman', 'appeared', 'pornography', 'alleged', 'sex_worker']",SOCIAL HARM
327,321,"[188,190,194,195,199,209,212,1988,1989,1990,1995,200]","A Tesla Model X P100D operating on Autopilot's Traffic-Aware Cruise Control (TACC) and Autosteer system allegedly accelerated above the speed limit of a highway in Mountain View, California, and steered itself directly into a barrier, resulting in its driver’s death.","Tesla Model X on Autopilot Crashed into California Highway Barrier, Killing Driver","['tesla_model', 'x', 'p100d', 'operating_autopilot', 'traffic', 'aware', 'cruise_control', 'tacc', 'autosteer', 'system', 'allegedly', 'accelerated', 'speed', 'limit', 'highway', 'mountain', 'view', 'california', 'steered', 'directly', 'barrier', 'resulting', 'driver', 'death']",SECURITY AND SAFETY
328,329,[2015],Amazon was reported to have shown chemical combinations for producing explosives and incendiary devices as “frequently bought together” items via automated recommendation.,Amazon Recommended Explosive-Producing Ingredients as “Frequently Bought Together” Items for Chemicals,"['amazon', 'wa_reported', 'shown', 'chemical', 'combination', 'producing', 'explosive', 'incendiary', 'device', 'frequently', 'bought', 'together', 'item', 'via', 'automated', 'recommendation']",SECURITY AND SAFETY
329,284,"[1882,1883,1884,1885,1886,1887]","Facebook’s removal of posts featuring renowned artworks by many historical artists and their promotional content due to nudity via both automated and human-moderated means were condemned by critics, such as museums and tourism boards, as cultural censorship and prevention of artwork promotion.",Facebook’s Automated Removal of Content Featuring Nudity-Containing Artworks Denounced as Censorship,"['facebook', 'removal', 'post', 'featuring', 'renowned', 'artwork', 'many', 'historical', 'artist', 'promotional', 'content', 'due', 'nudity', 'via', 'automated', 'human', 'moderated', 'mean', 'condemned', 'critic', 'museum', 'tourism', 'board', 'cultural', 'censorship', 'prevention', 'artwork', 'promotion']",SOCIAL HARM
330,298,[2471],"TheFaceTag app, a social networking app developed and deployed within-campus by a student at Harvard raised concerns surrounding its facial recognition, cybersecurity, privacy, and misuse. This incident has been downgraded to an issue as it does not meet current ingestion criteria.",Student-Developed Facial Recognition App Raised Ethical Concerns,"['thefacetag', 'app', 'social', 'networking', 'app', 'developed', 'deployed', 'within', 'campus', 'student', 'harvard', 'raised_concern', 'surrounding', 'facial_recognition', 'cybersecurity', 'privacy', 'misuse', 'incident_ha', 'downgraded_issue', 'doe_meet', 'current_ingestion', 'criterion']",SOCIAL HARM
331,279,"[1869,1870,2381]",TikTok’s young users were allegedly exposed to community-guideline-violating pro-eating disorder content on their algorithmically curated “For You” page that serves videos from any user on its platform.,TikTok’s “For You” Algorithm Exposed Young Users to Pro-Eating Disorder Content,"['tiktok', 'young', 'user', 'allegedly', 'exposed', 'community', 'guideline', 'violating', 'pro', 'eating_disorder', 'content', 'algorithmically', 'curated', 'page', 'serf', 'video', 'user', 'platform']",SOCIAL HARM
332,281,"[1875,1876,1877]","Terms-of-service-violating videos related to suicide and self-harm reportedly bypassed YouTube’s content moderation algorithms, allegedly resulting in exposure of graphic content to young users via recommended videos.",YouTube's Algorithms Failed to Remove Violating Content Related to Suicide and Self-Harm,"['term', 'service', 'violating', 'video', 'related', 'suicide', 'self', 'harm', 'reportedly', 'bypassed', 'youtube', 'content_moderation', 'algorithm', 'allegedly', 'resulting', 'exposure', 'graphic', 'content', 'young', 'user', 'via', 'recommended', 'video']",SOCIAL HARM
333,312,"[1963,1964,1965,1966]","A startup’s use of AI voice technology to alter or remove accents for call center agents was scrutinized by critics as reaffirming bias, despite the company’s claim.",Startup's Accent Translation AI Denounced as Reinforcing Racial Bias,"['startup', 'use', 'ai', 'voice', 'technology', 'alter', 'remove', 'accent', 'call', 'center', 'agent', 'wa', 'scrutinized', 'critic', 'reaffirming', 'bias', 'despite', 'company', 'claim']",SOCIAL HARM
334,316,[1971],"Facebook’s advertisement-approval algorithm was reported by a security analyst to have neglected simple checks for domain URLs, leaving its users at risk of fraudulent ads.",Facebook Ad-Approval Algorithm Allegedly Missed Fraudulent Ads via Simple URL Checks,"['facebook', 'advertisement', 'approval', 'algorithm', 'wa_reported', 'security', 'analyst', 'neglected', 'simple', 'check', 'domain', 'url', 'leaving', 'user', 'risk', 'fraudulent', 'ad']",SOCIAL HARM
335,288,"[1895,1896,2025,2026]","Woodbridge Police Department falsely arrested an innocent Black man following a misidentification by their facial recognition software, who was jailed for more than a week and paid thousands of dollar for his defense.",New Jersey Police Wrongful Arrested Innocent Black Man via FRT,"['woodbridge', 'police_department', 'falsely', 'arrested', 'innocent', 'black_man', 'following', 'misidentification', 'facial_recognition', 'software', 'wa', 'jailed', 'week', 'paid', 'thousand', 'dollar', 'defense']",SOCIAL HARM
336,289,"[1897,1898]","A Starship food delivery robot crashed into the front bumper of a vehicle waiting at a stoplight intersection in Frisco, Texas, the video of which the company reportedly refused to release.","Starship Delivery Robot Scuffed Bumper of a Resident’s Car in Texas, Allegedly Refusing to Release Footage of the Accident","['starship', 'food', 'delivery_robot', 'crashed', 'front', 'bumper', 'vehicle', 'waiting', 'stoplight', 'intersection', 'frisco', 'texas', 'video', 'company', 'reportedly', 'refused', 'release']",SECURITY AND SAFETY
337,306,"[1946,1948,1949]","A Tesla Model S operating on the Traffic-Aware Cruise Control (TACC) feature of Autopilot was shown on video by its driver crashing into a parked van on a European highway in heavy traffic, which damaged the front of the car.",Tesla on Autopilot TACC Crashed into Van on European Highway,"['tesla_model', 'operating', 'traffic', 'aware', 'cruise_control', 'tacc', 'feature', 'autopilot', 'wa_shown', 'video', 'driver', 'crashing', 'parked', 'van', 'european', 'highway', 'heavy', 'traffic', 'damaged', 'front', 'car']",SECURITY AND SAFETY
338,345,[2058],"Auto-insurance companies' photo-based estimation of repair price was alleged by repair shop owners and industry groups as providing inaccurate estimates, causing damaged cars to stay in the shop longer.",Auto-Insurance Photo-Based Estimation Allegedly Gave Inaccurate Repair Prices Frequently,"['auto', 'insurance', 'company', 'photo', 'based', 'estimation', 'repair', 'price', 'wa_alleged', 'repair', 'shop', 'owner', 'industry', 'group', 'providing', 'inaccurate', 'estimate', 'causing', 'damaged', 'car', 'stay', 'shop', 'longer']",OPERATIONAL INCIDENT
339,301,[1938],Broward College’s use of remote proctoring system and reliance on its flagging algorithm allegedly led to a wrongful accusation of academic dishonesty in a biology exam of a Florida teenager.,Teenager at Broward College Allegedly Wrongfully Accused of Cheating via Remote Proctoring,"['broward', 'college', 'use', 'remote_proctoring', 'system', 'reliance', 'flagging', 'algorithm', 'allegedly', 'led', 'wrongful', 'accusation', 'academic', 'dishonesty', 'biology', 'exam', 'florida', 'teenager']",OPERATIONAL INCIDENT
340,314,[1968],"Stable Diffusion, an open-source image generation model by Stability AI, was reportedly leaked on 4chan prior to its release date, and was used by its users to generate pornographic deepfakes of celebrities.",Stable Diffusion Abused by 4chan Users to Deepfake Celebrity Porn,"['stable_diffusion', 'open_source', 'image', 'generation', 'model', 'stability', 'ai', 'wa', 'reportedly', 'leaked', '4chan', 'prior', 'release', 'date', 'wa', 'used', 'user', 'generate', 'pornographic', 'deepfakes', 'celebrity']",SOCIAL HARM
341,322,"[1991,1994]","A Tesla Model 3 on Autopilot slammed into a parked car of patrol police officers who stopped to assist a stranded motorist on the interstate in Norwalk, Connecticut.",Tesla Model 3 Crashed into Police Patrol Car on Connecticut Highway,"['tesla_model', '3', 'autopilot', 'slammed', 'parked', 'car', 'patrol', 'police_officer', 'stopped', 'assist', 'stranded', 'motorist', 'interstate', 'norwalk', 'connecticut']",SECURITY AND SAFETY
342,336,"[2048,2119,2120,2121]","UK Home Office's opaque algorithm to detect sham marriages flagged some nationalities for investigation more than others, raising fears surrounding discrimination based on nationality and age.",UK Home Office's Sham Marriage Detection Algorithm Reportedly Flagged Certain Nationalities Disproportionately,"['uk', 'home', 'office', 'opaque', 'algorithm', 'detect', 'sham', 'marriage', 'flagged', 'nationality', 'investigation', 'others', 'raising', 'fear', 'surrounding', 'discrimination', 'based', 'nationality', 'age']",SOCIAL HARM
343,351,[2068],"A Twitter user reportedly modified using generative AI a short clip of Disney's 2022 version of ""The Little Mermaid,"" replacing a Black actress with a white digital character.","""The Little Mermaid"" Clip Doctored Using Generative AI to Replace Black Actress with White Character","['twitter', 'user', 'reportedly', 'modified', 'using', 'generative_ai', 'short', 'clip', 'disney', '2022', 'version', 'little', 'mermaid', 'replacing', 'black', 'actress', 'white', 'digital', 'character']",SOCIAL HARM
344,364,[2131],Walmart's theft-deterring bagging-detection system allegedly exposed workers to health risks during the coronavirus pandemic when its false positives prompted workers to unnecessarily step in to resolve the issue.,Walmart's Bagging-Detection False Positives Exposed Workers to Health Risk,"['walmart', 'theft', 'deterring', 'bagging', 'detection_system', 'allegedly', 'exposed', 'worker', 'health', 'risk', 'coronavirus', 'pandemic', 'false_positive', 'prompted', 'worker', 'unnecessarily', 'step', 'resolve', 'issue']",SECURITY AND SAFETY
345,367,[2150],"Unsupervised image generation models trained using Internet images such as iGPT and SimCLR were shown to have embedded racial, gender, and intersectional biases, resulting in stereotypical depictions.","iGPT, SimCLR Learned Biased Associations from Internet Training Data","['unsupervised', 'image', 'generation', 'model_trained', 'using', 'internet', 'image', 'igpt', 'simclr', 'shown', 'embedded', 'racial', 'gender', 'intersectional', 'bias', 'resulting', 'stereotypical', 'depiction']",SOCIAL HARM
346,355,"[2081,2082,2083,2903,2972]","Uber was alleged in a lawsuit to have wrongfully accused its drivers in the UK and Portugal of fraudulent activity through automated systems, which resulted in their dismissal without a right to appeal.",Uber Allegedly Wrongfully Accused Drivers of Fraud via Automated Systems,"['uber', 'wa_alleged', 'lawsuit', 'wrongfully', 'accused', 'driver', 'uk', 'portugal', 'fraudulent', 'activity', 'automated', 'system', 'resulted', 'dismissal', 'without', 'right', 'appeal']",SOCIAL HARM
347,356,"[2084,2085]",Philosopher AI as built on top of GPT-3 was reported by its users for having strong tendencies to produce offensive results when given prompts on certain topics such as feminism and Ethiopia.,Philosophy AI Tentatively Produced Offensive Results for Certain Prompts,"['philosopher', 'ai', 'built', 'top', 'gpt_3', 'wa_reported', 'user', 'strong', 'tendency', 'produce', 'offensive', 'result', 'given', 'prompt', 'certain', 'topic', 'feminism', 'ethiopia']",SOCIAL HARM
348,368,"[2151,2152,2153,2154,2155,2156,2157,2159,2160,2161]","A controversial surveillance program involving facial recognition and algorithmic recommendation, Blue Wolf, was deployed by the Israeli military to monitor Palestinians in the West Bank.","Facial Recognition Smart Phone App ""Blue Wolf"" Monitored Palestinians in West Bank","['controversial', 'surveillance', 'program', 'involving_facial', 'recognition', 'algorithmic', 'recommendation', 'blue', 'wolf', 'wa', 'deployed', 'israeli', 'military', 'monitor', 'palestinian', 'west', 'bank']",PRIVACY VIOLATION
349,370,[2163],"Google was fined by EU Commission for changing its shopping algorithms in Europe to favor its own comparison service over competitors, resulting in anti-competitive effects.",Google Fined for Changing Shopping Algorithms in EU to Favor Own Service,"['google', 'wa', 'fined', 'eu', 'commission', 'changing', 'shopping', 'algorithm', 'europe', 'favor', 'comparison', 'service', 'competitor', 'resulting', 'anti', 'competitive', 'effect']",SOCIAL HARM
350,378,"[2175,2176]",A TuSimple autonomous truck operating with backup drivers behind the wheel operated on an outdated command sequence and suddenly veered into the center divide on the interstate freeway.,TuSimple Truck Steered into Interstate Freeway Divide,"['tusimple', 'autonomous', 'truck', 'operating', 'backup', 'driver', 'behind', 'wheel', 'operated', 'outdated', 'command', 'sequence', 'suddenly', 'veered', 'center', 'divide', 'interstate', 'freeway']",SECURITY AND SAFETY
351,391,"[2244,2246]","Southern Co-op's use of facial recognition reportedly to curb violent crime in UK supermarkets was alleged by civil society and privacy groups as ""unlawful"" and ""complete"" invasion of privacy.",Facial Recognition Trial by UK Southern Co-op Alleged as Unlawful,"['southern', 'co', 'op', 'use_facial', 'recognition', 'reportedly', 'curb', 'violent', 'crime', 'uk', 'supermarket', 'wa_alleged', 'civil', 'society', 'privacy', 'group', 'unlawful', 'complete', 'invasion', 'privacy']",PRIVACY VIOLATION
352,371,"[2167,2184,2203]","Huawei's AI systems involving facial recognition were reportedly deployed by the Ugandan government to monitor political opposition actors and anti-regime sentiments, which raised fears of surveillance and suppression of individual freedoms.",Uganda Deployed Huawei's Facial Recognition to Monitor Political Opposition and Protests,"['huawei', 'ai', 'system_involving', 'facial_recognition', 'reportedly', 'deployed', 'ugandan', 'government', 'monitor', 'political', 'opposition', 'actor', 'anti', 'regime', 'sentiment', 'raised', 'fear', 'surveillance', 'suppression', 'individual', 'freedom']",SOCIAL HARM
353,393,[2247],Facebook's ad moderation system involving algorithms failed to flag hateful language and violating content such as calls for killings for ads in English and Swahili.,Facebook AI-Supported Moderation for Ads Failed to Detect Violating Content,"['facebook', 'ad', 'moderation_system', 'involving', 'algorithm', 'failed', 'flag', 'hateful', 'language', 'violating', 'content', 'call', 'killing', 'ad', 'english', 'swahili']",SOCIAL HARM
354,358,[2089],"Facial recognition (FRT) was reportedly deployed in some Calgary-area malls to approximate customer age and gender without explicit consent, which a privacy expert warned was a cause for concern.",Calgary Malls Deployed Facial Recognition without Customer Consent,"['facial_recognition', 'frt', 'wa', 'reportedly', 'deployed', 'calgary', 'area', 'mall', 'approximate', 'customer', 'age', 'gender', 'without', 'explicit', 'consent', 'privacy', 'expert', 'warned', 'wa', 'concern']",PRIVACY VIOLATION
355,363,[2130],Facebook's automated system mistakenly labelled posts featuring the seafaring landmark Plymouth Hoe as misogynistic.,Facebook's Automated Moderation Mistakenly Flagged Landmark's Name as Offensive,"['facebook_automated', 'system', 'mistakenly', 'labelled', 'post', 'featuring', 'seafaring', 'landmark', 'plymouth', 'hoe', 'misogynistic']",OPERATIONAL INCIDENT
356,369,[2162],"An artwork generated using generative AI won first place in the digital arts category of the Colorado State Fair's art competition, which raised concerns surrounding labor displacement and unfair competition.",GAN Artwork Won First Place at State Fair Competition,"['artwork', 'generated', 'using', 'generative_ai', 'first', 'place', 'digital', 'art', 'category', 'colorado', 'state', 'fair', 'art', 'competition', 'raised_concern', 'surrounding', 'labor', 'displacement', 'unfair', 'competition']",SOCIAL HARM
357,400,[2273],"Google Search reportedly returned fewer abortion clinics for searches from poorer and rural areas, particularly ones with Targeted Regulation of Abortion Providers (TRAP) laws.",Google Search Returned Fewer Results for Abortion Services in Rural Areas,"['google', 'search', 'reportedly', 'returned', 'fewer', 'abortion', 'clinic', 'search', 'poorer', 'rural', 'area', 'particularly', 'one', 'targeted', 'regulation', 'abortion', 'provider', 'trap', 'law']",SOCIAL HARM
358,373,"[2169,2187,2188,2189,2190,2191,2213,2214,2215,2216,2238,2798]","State's use of Michigan Integrated Data Automated System (MiDAS) to adjudicate unemployment benefits claims falsely issued fraud determinations based on un-investigated assumptions, resulting in tens of thousands of false fraud cases over years.",Michigan's Unemployment Benefits Algorithm MiDAS Issued False Fraud Claims to Thousands of People,"['state', 'use', 'michigan', 'integrated', 'data', 'automated', 'system', 'midas', 'adjudicate', 'unemployment', 'benefit', 'claim', 'falsely', 'issued', 'fraud', 'determination', 'based', 'un', 'investigated', 'assumption', 'resulting', 'ten', 'thousand', 'false', 'fraud', 'case', 'year']",SOCIAL HARM
359,376,"[2172,2185,2186,2261,2281]","RealPage’s YieldStar apartment pricing algorithm was reportedly helping landlords push unusually high rents onto tenants, raising fears and criticisms surrounding alleged antitrust behaviors such as artificially inflating price, and stifling competition.","RealPage's Algorithm Pushed Rent Prices High, Allegedly Artificially","['realpage', 'yieldstar', 'apartment', 'pricing_algorithm', 'wa', 'reportedly', 'helping', 'landlord', 'push', 'unusually', 'high', 'rent', 'onto', 'tenant', 'raising', 'fear', 'criticism', 'surrounding', 'alleged', 'antitrust', 'behavior', 'artificially', 'inflating', 'price', 'stifling', 'competition']",SOCIAL HARM
360,395,"[2254,2255,2256,2257]","Amazon delivery drivers were forced to consent to algorithmic collection and processing of their location, movement, and biometric data through AI-powered cameras, or be dismissed.",Amazon Forced Deployment of AI-Powered Cameras on Delivery Drivers,"['amazon', 'delivery_driver', 'forced', 'consent', 'algorithmic', 'collection', 'processing', 'location', 'movement', 'biometric_data', 'ai_powered', 'camera', 'dismissed']",PRIVACY VIOLATION
361,361,[2111],Amazon Echo misinterpreted a background conversation between a husband and wife as instructions for recording a message and sending it to one of the husband's employees.,Amazon Echo Mistakenly Recorded and Sent Private Conversation to Random Contact,"['amazon', 'echo', 'misinterpreted', 'background', 'conversation', 'husband', 'wife', 'instruction', 'recording', 'message', 'sending', 'one', 'husband', 'employee']",OPERATIONAL INCIDENT
362,377,[2174],Weibo's user moderation model is having difficulty keeping up with shifting user slang in defiance of Chinese state censors.,Weibo Model Had Difficulty Detecting Shifts in Censored Speech,"['weibo', 'user', 'moderation', 'model', 'difficulty', 'keeping', 'shifting', 'user', 'slang', 'defiance', 'chinese', 'state', 'censor']",OPERATIONAL INCIDENT
363,354,"[2078,2079,2080,2904,2903]","Uber was alleged in a lawsuit to have provided incomplete notice about automated decision-making and profiling for drivers such as information about their driving behavior, and use of phone.",Uber Allegedly Violated GDPR by Failing to Provide Sufficient Notice on Automated Profiling for Drivers,"['uber', 'wa_alleged', 'lawsuit', 'provided', 'incomplete', 'notice', 'automated', 'decision_making', 'profiling', 'driver', 'information', 'driving', 'behavior', 'use', 'phone']",PRIVACY VIOLATION
364,381,[2217],An autonomous Roborace car drove itself into a wall in round one of the Season Beta 1.1 race.,Autonomous Roborace Car Drove Directly into a Wall,"['autonomous', 'roborace', 'car', 'drove', 'wall', 'round', 'one', 'season', 'beta', '1', '1', 'race']",OPERATIONAL INCIDENT
365,353,"[2073,2074,2195,2196]","A Tesla Model 3 driver switched on Autopilot seconds before the crash into the underbelly of a tractor-trailer on a highway in Florida, killing the Tesla driver.","Tesla on Autopilot Crashed into Trailer Truck in Florida, Killing Driver","['tesla_model', '3', 'driver', 'switched', 'autopilot', 'second', 'crash', 'underbelly', 'tractor_trailer', 'highway', 'florida', 'killing', 'tesla', 'driver']",SECURITY AND SAFETY
366,374,"[2170,2206,2207,2208,2209,2210,2211,2212]","UK Office of Qualifications and Examinations Regulation (Ofqual)'s grade-standardization algorithm providing predicted grades for A level and GCSE qualifications in the UK, Wales, Northern Ireland, and Scotland was reportedly giving grades lower than teachers' assessments, and disproportionately for state schools.",UK Ofqual's Algorithm Disproportionately Provided Lower Grades Than Teachers' Assessments,"['uk', 'office', 'qualification', 'examination', 'regulation', 'ofqual', 'grade', 'standardization', 'algorithm', 'providing', 'predicted', 'grade', 'level', 'gcse', 'qualification', 'uk', 'wale', 'northern', 'ireland', 'scotland', 'wa', 'reportedly', 'giving', 'grade', 'lower', 'teacher', 'assessment', 'disproportionately', 'state', 'school']",OPERATIONAL INCIDENT
367,380,"[2181,2182,2258,2259,2260]","Facebook's automated advertising categories generated using users' declared interests contained anti-Semitic categories such as ""Jew hater""  and ""How to burn Jews"" which were listed as fields of study.",Facebook's Auto-Generated Targeting Ad Categories Contained Anti-Semitic Options,"['facebook_automated', 'advertising', 'category', 'generated', 'using', 'user', 'declared', 'interest', 'contained', 'anti', 'semitic', 'category', 'jew', 'hater', 'burn', 'jew', 'listed', 'field', 'study']",SOCIAL HARM
368,357,"[2086,2087,2088]","OpenAI's GPT-2 reportedly memorized and could regurgitate verbatim instances of training data, including personally identifiable information such as names, emails, twitter handles, and phone numbers.",GPT-2 Able to Recite PII in Training Data,"['openai_gpt', '2', 'reportedly', 'memorized', 'could', 'regurgitate', 'verbatim', 'instance', 'training_data', 'including', 'personally', 'identifiable', 'information', 'name', 'email', 'twitter', 'handle', 'phone', 'number']",PRIVACY VIOLATION
369,385,"[2224,2225,2231,2232,2233,2234]","The Edmonton Police Service (EPS) in Canada released a facial image of a Black male suspect generated by an algorithm using DNA phenotyping, which was denounced by the local community as racial profiling.",Canadian Police's Release of Suspect's AI-Generated Facial Photo Reportedly Reinforced Racial Profiling,"['edmonton', 'police', 'service', 'eps', 'canada', 'released', 'facial', 'image', 'black', 'male', 'suspect', 'generated', 'algorithm', 'using', 'dna', 'phenotyping', 'wa', 'denounced', 'local', 'community', 'racial', 'profiling']",SOCIAL HARM
370,388,[2235],Facial recognition deployed in a pilot project by the local government of Bahia despite having minimal hit rate reportedly targeted Black and poor people disproportionately.,Facial Recognition Pilot in Bahia Reportedly Targeted Black and Poor People,"['facial_recognition', 'deployed', 'pilot', 'project', 'local', 'government', 'bahia', 'despite', 'minimal', 'hit', 'rate', 'reportedly', 'targeted', 'black', 'poor', 'people', 'disproportionately']",SOCIAL HARM
371,383,"[2220,2223]",Google Home Mini speaker was reported by users for announcing aloud the previously-censored n-word in a song title.,Google Home Mini Speaker Reportedly Read N-Word in Song Title Aloud,"['google', 'home', 'mini', 'speaker', 'wa_reported', 'user', 'announcing', 'aloud', 'previously', 'censored', 'n', 'word', 'song', 'title']",SOCIAL HARM
372,390,[2243],Voice and video deepfakes were reported by FBI Internet Crime Complaint Center (IC3) in complaint reports to have been deployed during online interviews of the candidates for remote-work positions.,Deepfakes Reportedly Deployed in Online Interviews for Remote Work Positions,"['voice', 'video', 'deepfakes', 'reported', 'fbi', 'internet', 'crime', 'complaint', 'center', 'ic3', 'complaint', 'report', 'deployed', 'online', 'interview', 'candidate', 'remote', 'work', 'position']",SOCIAL HARM
373,387,[2229],Oracle's automated system involving algorithmic data processing was alleged in a lawsuit to have been unlawfully collecting personal data from millions of people and violating their privacy rights.,Oracle's Algorithmic Data Processing System Alleged as Unlawful and Violating Privacy Rights,"['oracle', 'automated', 'system_involving', 'algorithmic', 'data', 'processing', 'wa_alleged', 'lawsuit', 'unlawfully', 'collecting', 'personal_data', 'million', 'people', 'violating', 'privacy', 'right']",PRIVACY VIOLATION
374,394,"[2248,2251]","TikTok's, YouTube's, Instagram's, and Twitch's use of algorithms to flag certain words devoid of context changed content creators' use of everyday language or discussion about certain topics in fear of their content getting flagged or auto-demonetized by mistake.",Social Media's Automated Word-Flagging without Context Shifted Content Creators' Language Use,"['tiktok', 'youtube', 'instagram', 'twitch', 'use', 'algorithm', 'flag', 'certain', 'word', 'devoid', 'context', 'changed', 'content_creator', 'use', 'everyday', 'language', 'discussion', 'certain', 'topic', 'fear', 'content', 'getting', 'flagged', 'auto', 'demonetized', 'mistake']",SOCIAL HARM
375,362,[2129],"Facebook's automated system flagged gardening groups' use of ""hoe"" and violent language against bugs as a violation by mistake.",Facebook's Automated Moderation Flagged Gardening Group's Language Use by Mistake,"['facebook_automated', 'system', 'flagged', 'gardening', 'group', 'use', 'hoe', 'violent', 'language', 'bug', 'violation', 'mistake']",OPERATIONAL INCIDENT
376,384,"[2221,2222]","Delivery company Glovo's automated system sent an email terminating an employee for ""non-compliance terms and conditions"" after the employee was killed in a car accident while making a delivery on Glovo's behalf.",Glovo Driver in Italy Fired via Automated Email after Being Killed in Accident,"['delivery', 'company', 'glovo', 'automated', 'system', 'sent', 'email', 'terminating', 'employee', 'non', 'compliance', 'term', 'condition', 'employee', 'wa', 'killed', 'car', 'accident', 'making', 'delivery', 'glovo', 'behalf']",SOCIAL HARM
377,359,[2097],"Facebook, Instagram, and Twitter wrongly blocked or restricted millions of pro-Palestinian posts and accounts related to the Israeli-Palestinian conflict, citing errors in their automated content moderation system.","Facebook, Instagram, and Twitter Cited Errors in Automated Systems as Cause for Blocking pro-Palestinian Content on Israeli-Palestinian Conflict","['facebook', 'instagram', 'twitter', 'wrongly', 'blocked', 'restricted', 'million', 'pro', 'palestinian', 'post', 'account', 'related', 'israeli', 'palestinian', 'conflict', 'citing', 'error_automated', 'content_moderation', 'system']",SOCIAL HARM
378,396,[2263],Transgender Uber drivers reported being automatically deactivated from the app due to Real-Time ID Check failing to account for difference in appearance of people undergoing gender transitions.,Transgender Uber Drivers Mistakenly Kicked off App for Appearance Change during Gender Transitions,"['transgender', 'uber', 'driver', 'reported', 'automatically', 'deactivated', 'app', 'due', 'real_time', 'id', 'check', 'failing', 'account', 'difference', 'appearance', 'people', 'undergoing', 'gender', 'transition']",SOCIAL HARM
379,352,"[2070,2076,2093,2426]",Remoteli.io's GPT-3-based Twitter bot was shown being hijacked by Twitter users who redirected it to repeat or generate any phrases.,GPT-3-Based Twitter Bot Hijacked Using Prompt Injection Attacks,"['remoteli', 'io', 'gpt_3', 'based', 'twitter', 'bot', 'wa_shown', 'hijacked', 'twitter', 'user', 'redirected', 'repeat', 'generate', 'phrase']",OPERATIONAL INCIDENT
380,372,"[2168,2177,2178]","Google Pixel 6a's fingerprint recognition feature was reported by users for security issues, in which phones were mistakenly unlocked by unregistered fingerprints.",Users Reported Security Issues with Google Pixel 6a's Fingerprint Unlocking,"['google', 'pixel', '6a', 'fingerprint', 'recognition', 'feature', 'wa_reported', 'user', 'security', 'issue', 'phone', 'mistakenly', 'unlocked', 'unregistered', 'fingerprint']",OPERATIONAL INCIDENT
381,375,"[2171,2192,2193]","A Thai wallet app failed to recognize people’s faces, resulting in citizens and disproportionately elders unable to sign up for Thai government’s cash handout and co-pay programs or having to wait in long queues at local ATMs for authentication.",Thai Wallet App's Facial Recognition Errors Created Registration Issues for Government Programs,"['thai', 'wallet', 'app', 'failed', 'recognize', 'people', 'face', 'resulting', 'citizen', 'disproportionately', 'elder', 'unable', 'sign', 'thai', 'government', 'cash', 'handout', 'co', 'pay', 'program', 'wait', 'long', 'queue', 'local', 'atm', 'authentication']",OPERATIONAL INCIDENT
382,379,"[2179,2180]","Pepsi's number generation system determining daily winners in its Number Fever promotion in the Philippines mistakenly produced a number held by thousands which resulted in riots, deaths, conspiracy theories, and decades of lawsuits.",Error in Pepsi's Number Generation System Led to Decades-Long Damages in the Philippines,"['pepsi', 'number', 'generation', 'system', 'determining', 'daily', 'winner', 'number', 'fever', 'promotion', 'philippine', 'mistakenly', 'produced', 'number', 'held', 'thousand', 'resulted', 'riot', 'death', 'conspiracy_theory', 'decade', 'lawsuit']",OPERATIONAL INCIDENT
383,382,[2219],"Instagram was ruled by a judge to have contributed to the death of a teenage girl in the UK allegedly through its exposure and recommendation of suicide, self-harm, and depressive content.",Instagram's Exposure of Harmful Content Contributed to Teenage Girl’s Suicide,"['instagram', 'wa', 'ruled', 'judge', 'contributed', 'death', 'teenage', 'girl', 'uk', 'allegedly', 'exposure', 'recommendation', 'suicide', 'self', 'harm', 'depressive', 'content']",SOCIAL HARM
384,386,"[2227,2228,2252]","Amazon’s warehouse worker “time off task"" (TOT) tracking system was used to discipline and dismiss workers, falsely assuming workers to have wasted time and failing to account for breaks or equipment issues.","Amazon’s ""Time Off Task"" System Made False Assumptions about Workers' Time Management","['amazon', 'warehouse', 'worker', 'time', 'task', 'tot', 'tracking', 'system', 'wa', 'used', 'discipline', 'dismiss', 'worker', 'falsely', 'assuming', 'worker', 'wasted', 'time', 'failing', 'account', 'break', 'equipment', 'issue']",SOCIAL HARM
385,389,"[2239,2240,2562,3182]",A fire truck in San Francisco responding to a fire was blocked from passing a doubled-parked garbage truck by a self-driving Cruise car on the opposing lane which stayed put and did not reverse to clear the lane.,Cruise Autonomous Car Blocked Fire Truck Responding to Emergency,"['fire_truck', 'san_francisco', 'responding', 'fire', 'wa', 'blocked', 'passing', 'doubled', 'parked', 'garbage', 'truck', 'self_driving', 'cruise', 'car', 'opposing', 'lane', 'stayed', 'put', 'reverse', 'clear', 'lane']",SECURITY AND SAFETY
386,397,"[2264,2268]",TikTok's search recommendations reportedly contained misinformation about political topics bypassing both AI and human content moderation.,Misinformation Reported in TikTok's Search Results Despite Moderation by AI and Human,"['tiktok', 'search', 'recommendation', 'reportedly_contained', 'misinformation', 'political', 'topic', 'bypassing', 'ai', 'human', 'content_moderation']",SOCIAL HARM
387,398,"[2265,2266,2267]","Tesla Autopilot's computer vision system was shown in a video mistaking a horse-drawn carriage for other forms of transport such as a truck, a car, and a human following a car.",Tesla Autopilot Misidentified On-Road Horse-Drawn Carriage,"['tesla_autopilot', 'computer', 'vision', 'system', 'wa_shown', 'video', 'mistaking', 'horse', 'drawn', 'carriage', 'form', 'transport', 'truck', 'car', 'human', 'following', 'car']",SECURITY AND SAFETY
388,399,"[2270,2271,2272,3154]",Meta AI trained and hosted a scientific paper generator that sometimes produced bad science and prohibited queries on topics and groups that are likely to produce offensive or harmful content.,Meta AI's Scientific Paper Generator Reportedly Produced Inaccurate and Harmful Content,"['meta', 'ai', 'trained', 'hosted', 'scientific', 'paper', 'generator', 'sometimes', 'produced', 'bad', 'science', 'prohibited', 'query', 'topic', 'group', 'likely', 'produce', 'offensive', 'harmful_content']",SOCIAL HARM
389,401,"[2275,2278,2279,2280]","Google's knowledge-graph-powered algorithm showed Kannada in its featured Answer Box when prompted ""ugliest language in India,"" causing outrage from Kannada-speaking people and government.","Kannada Insulted by Google's Featured Answer as ""Ugliest Language in India""","['google', 'knowledge', 'graph', 'powered', 'algorithm', 'showed', 'kannada', 'featured', 'answer', 'box', 'prompted', 'ugliest', 'language', 'india', 'causing', 'outrage', 'kannada', 'speaking', 'people', 'government']",SOCIAL HARM
390,402,[2276],Latitude's GPT-3-powered game AI Dungeon was reportedly abused by some players who manipulated its AI to generate sexually explicit stories involving children.,Players Manipulated GPT-3-Powered Game to Generate Sexually Explicit Material Involving Children,"['latitude', 'gpt_3', 'powered', 'game', 'ai', 'dungeon', 'wa', 'reportedly_abused', 'player', 'manipulated', 'ai', 'generate', 'sexually', 'explicit', 'story', 'involving', 'child']",SOCIAL HARM
391,360,"[2100,2149,2218]","McDonald's use of chatbot in its AI drive-through in Chicago was alleged in a lawsuit to have collected and processed voice data without user consent to predict customer information, which violated Illinois Biometric Information Privacy Act (BIPA).","McDonald's AI Drive-Thru Allegedly Collected Biometric Customer Data without Consent, Violating BIPA","['mcdonald', 'use', 'chatbot', 'ai', 'drive', 'chicago', 'wa_alleged', 'lawsuit', 'collected', 'processed', 'voice', 'data_without', 'user', 'consent', 'predict', 'customer', 'information', 'violated', 'illinois_biometric', 'information_privacy', 'act', 'bipa']",PRIVACY VIOLATION
392,366,[2140],"Many clips showing a suicide evaded TikTok's automated content moderation system allegedly in a coordinated attack, which resulted in exposure of violating content to its users.",Suicide Clips Evaded TikTok's Automated Moderation in Coordinated Attack,"['many', 'clip', 'showing', 'suicide', 'evaded', 'tiktok_automated', 'content_moderation', 'system', 'allegedly', 'coordinated', 'attack', 'resulted', 'exposure', 'violating', 'content', 'user']",SOCIAL HARM
393,392,"[2245,2249]",Facebook's system involving algorithmic content moderation for East African languages was reportedly failing to identify violating content on the platform such as mistakenly classifying non-terrorist content.,Facebook's AI-Supported Moderation Failed to Classify Terrorist Content in East African Languages,"['facebook', 'system_involving', 'algorithmic', 'content_moderation', 'east', 'african', 'language', 'wa', 'reportedly', 'failing', 'identify', 'violating', 'content', 'platform', 'mistakenly', 'classifying', 'non', 'terrorist', 'content']",OPERATIONAL INCIDENT
394,407,[2289],Uber's surge-pricing algorithm which adjusts prices to influence car availability inadvertently caused better service offering such as shorter wait times for majority white neighborhoods.,Uber's Surge Pricing Reportedly Offered Disproportionate Service Quality along Racial Lines,"['uber', 'surge', 'pricing_algorithm', 'adjusts', 'price', 'influence', 'car', 'availability', 'inadvertently', 'caused', 'better', 'service', 'offering', 'shorter', 'wait', 'time', 'majority', 'white', 'neighborhood']",SOCIAL HARM
395,404,"[2284,2286]","Sound Intelligence's ""aggression detection"" algorithm deployed by schools reportedly contained high rates of false positive, misclassifying laughing, coughing, cheering, and loud discussions.",Sound Intelligence's Aggression Detector Misidentified Innocuous Sounds,"['sound', 'intelligence', 'aggression', 'detection', 'algorithm', 'deployed', 'school', 'reportedly_contained', 'high_rate', 'false_positive', 'misclassifying', 'laughing', 'coughing', 'cheering', 'loud', 'discussion']",OPERATIONAL INCIDENT
396,406,[2288],"Facebook's ""People You May Know"" (PYMK) feature was reported by a psychiatrist for recommending her patients as friends through recommendations, violating patients' privacy and confidentiality.",Facebook's Friend Suggestion Feature Recommends Patients of Psychiatrist to Each Other,"['facebook', 'people', 'may', 'know', 'pymk', 'feature', 'wa_reported', 'psychiatrist', 'recommending', 'patient', 'friend', 'recommendation', 'violating', 'patient', 'privacy', 'confidentiality']",PRIVACY VIOLATION
397,408,[2290],"Facebook's ""People You May Know"" feature reportedly outed sex workers by recommending clients to their personal accounts or family members to their business accounts with no option to opt out.",Facebook Reportedly Outed Sex Workers through Friend Recommendations,"['facebook', 'people', 'may', 'know', 'feature', 'reportedly', 'outed', 'sex_worker', 'recommending', 'client', 'personal', 'account', 'family', 'member', 'business', 'account', 'option', 'opt']",SOCIAL HARM
398,409,"[2309,2411,2412]",YouTube videos of transgender people used by researchers to study facial recognition during gender transitions were used and distributed without permission.,Facial Recognition Researchers Used YouTube Videos of Transgender People without Consent,"['youtube', 'video', 'transgender', 'people', 'used', 'researcher', 'study', 'facial_recognition', 'gender', 'transition', 'used', 'distributed', 'without_permission']",PRIVACY VIOLATION
399,405,"[2285,2287]","Creditworthiness Schufa scores in Germany reportedly privileged older and female consumers, and people who changed addresses less frequently, and were unreliable depending on scoring version.",Schufa Credit Scoring in Germany Reported for Unreliable and Imbalanced Scores,"['creditworthiness', 'schufa', 'score', 'germany', 'reportedly', 'privileged', 'older', 'female', 'consumer', 'people', 'changed', 'address', 'le', 'frequently', 'unreliable', 'depending', 'scoring', 'version']",SOCIAL HARM
400,403,"[2282,2283]","Google GMail's inbox sorting algorithm for political emails was reported by presidential candidates, nonprofits, and advocacy groups for having negative impact on call-to-actions, allegedly suppressing donations and impeding political actions.",GMail's Inbox Sorting Reportedly Negatively Impacted Political Emails and Call-to-Actions,"['google', 'gmail', 'inbox', 'sorting', 'algorithm', 'political', 'email', 'wa_reported', 'presidential', 'candidate', 'nonprofit', 'advocacy_group', 'negative', 'impact', 'call', 'action', 'allegedly', 'suppressing', 'donation', 'impeding', 'political', 'action']",SOCIAL HARM
401,410,[2312],KFC cited an error in an automated holiday detection system which identified the anniversary of Kristallnacht and prompted an insensitive push notification promoting its chicken.,KFC Sent Insensitive Kristallnacht Promotion via Holiday Detection System,"['kfc', 'cited', 'error_automated', 'holiday', 'detection_system', 'identified', 'anniversary', 'kristallnacht', 'prompted', 'insensitive', 'push', 'notification', 'promoting', 'chicken']",SOCIAL HARM
402,411,[2314],Twitter Feed was flooded by content from Chinese-language accounts which allegedly aimed to manipulate and reduce social media coverage about widespread protests against coronavirus restrictions in China.,Chinese Accounts Spammed Twitter Feed Allegedly to Obscure News of Protests,"['twitter', 'feed', 'wa', 'flooded', 'content', 'chinese', 'language', 'account', 'allegedly', 'aimed', 'manipulate', 'reduce', 'social_medium', 'coverage', 'widespread', 'protest', 'coronavirus', 'restriction', 'china']",SOCIAL HARM
403,412,"[2315,2408,2409,2410]",Finland's National Police Board was reprimanded for illegal processing of special categories of personal data in a facial recognition trial to identify potential victims of child sexual abuse.,Finland Police's Facial Recognition Trial to Identify Sexual Abuse Victims Deemed Illegal,"['finland', 'national', 'police', 'board', 'wa', 'reprimanded', 'illegal', 'processing', 'special', 'category', 'personal_data', 'facial_recognition', 'trial', 'identify', 'potential', 'victim', 'child', 'sexual_abuse']",PRIVACY VIOLATION
404,413,"[2317,2318,2586]","Thousands of incorrect answers produced by OpenAI's ChatGPT were submitted to Stack Overflow, which swamped the site's volunteer-based quality curation process and harmed users looking for correct answers.",Thousands of Incorrect ChatGPT-Produced Answers Posted on Stack Overflow,"['thousand', 'incorrect', 'answer', 'produced', 'openai', 'chatgpt', 'submitted', 'stack', 'overflow', 'swamped', 'site', 'volunteer', 'based', 'quality', 'curation', 'process', 'harmed', 'user', 'looking', 'correct', 'answer']",SOCIAL HARM
405,414,[2319],Facebook provided a vulgar Burmese-English translation of the Chinese president's name in posts of an official Burmese politician's Facebook page announcing his visit.,Facebook Gave Vulgar English Translation of Chinese President's Name,"['facebook', 'provided', 'vulgar', 'burmese', 'english_translation', 'chinese', 'president', 'name', 'post', 'official', 'burmese', 'politician', 'facebook', 'page', 'announcing', 'visit']",SOCIAL HARM
406,415,"[2320,2404,2405,2406,2407]",Facebook's Thai-English translation gave an inappropriate mistranslation on Thai PBS's Facebook live broadcast of the King of Thailand’s candle-lighting birthday ceremony.,Facebook Provided Offensive Translation for King of Thailand's Birthday Ceremony,"['facebook', 'thai', 'english_translation', 'gave', 'inappropriate', 'mistranslation', 'thai', 'pb', 'facebook', 'live', 'broadcast', 'king', 'thailand', 'candle', 'lighting', 'birthday', 'ceremony']",SOCIAL HARM
407,416,"[2321,2402,2403]",Facebook's algorithm was alleged in a complaint by Real Women in Trucking to have selectively shown job advertisements disproportionately against older and female workers in favor of younger men for blue-collar positions.,Facebook's Job Ad Algorithm Allegedly Biased against Older and Female Workers,"['facebook', 'algorithm', 'wa_alleged', 'complaint', 'real', 'woman', 'trucking', 'selectively', 'shown', 'job', 'advertisement', 'disproportionately', 'older', 'female', 'worker', 'favor', 'younger', 'men', 'blue', 'collar', 'position']",SOCIAL HARM
408,417,"[2322,2399,2400,2401]",Facebook feed algorithms were known by internal research to have harmed people having low digital literacy by exposing them to disturbing content they did not know how to avoid or monitor.,Facebook Feed Algorithms Exposed Low Digitally Skilled Users to More Disturbing Content,"['facebook', 'feed', 'algorithm', 'known', 'internal', 'research', 'harmed', 'people', 'low', 'digital', 'literacy', 'exposing', 'disturbing', 'content', 'know', 'avoid', 'monitor']",SOCIAL HARM
409,418,"[2324,2391,2392]",Uber drivers in India reported being locked out of their accounts allegedly due to Real-Time ID Check's facial recognition failing to recognize appearance changes or faces in low lighting conditions.,Uber Locked Indian Drivers out of Accounts Allegedly Due to Facial Recognition Fails,"['uber', 'driver', 'india', 'reported', 'locked', 'account', 'allegedly_due', 'real_time', 'id', 'check', 'facial_recognition', 'failing', 'recognize', 'appearance', 'change', 'face', 'low', 'lighting', 'condition']",OPERATIONAL INCIDENT
410,419,"[2325,2395,2396]",Facebook's automated moderating system failed to flag and allowed ads containing explicit violent language against election workers to be published.,Facebook's Automated Moderation Allowed Ads Threatening Election Workers to be Posted,"['facebook_automated', 'moderating', 'system', 'failed', 'flag', 'allowed', 'ad', 'containing', 'explicit', 'violent', 'language', 'election', 'worker', 'published']",SOCIAL HARM
411,420,"[2326,2358,2393,2394,2397,2554,2644,2649,2662,2852,2863]",Users reported bypassing ChatGPT's content and keyword filters with relative ease using various methods such as prompt injection or creating personas to produce biased associations or generate harmful content.,Users Bypassed ChatGPT's Content Filters with Ease,"['user', 'reported', 'bypassing', 'chatgpt', 'content', 'keyword', 'filter', 'relative', 'ease', 'using', 'various', 'method', 'prompt', 'injection', 'creating', 'persona', 'produce', 'biased', 'association', 'generate', 'harmful_content']",OPERATIONAL INCIDENT
412,421,"[2328,2427,2444,2523,2577,2607,2608,2446,2618,2959,2960,2989]",Text-to-image model Stable Diffusion was reportedly using artists' original works without permission for its AI training.,Stable Diffusion Allegedly Used Artists' Works without Permission for AI Training,"['text', 'image', 'model', 'stable_diffusion', 'wa', 'reportedly', 'using', 'artist', 'original', 'work', 'without_permission', 'ai', 'training']",PRIVACY VIOLATION
413,422,[2330],A visual and audio deepfake of former FTX CEO Sam Bankman-Fried was posted on Twitter to scam victims of the exchange's collapse by urging people to transfer funds into an anonymous cryptocurrency wallet.,Deepfake of FTX's Former CEO Posted on Twitter Aiming to Scam FTX Collapse Victims,"['visual', 'audio', 'deepfake', 'former', 'ftx', 'ceo', 'sam', 'bankman', 'fried', 'wa', 'posted_twitter', 'scam', 'victim', 'exchange', 'collapse', 'urging', 'people', 'transfer', 'fund', 'anonymous', 'cryptocurrency', 'wallet']",SOCIAL HARM
414,423,"[2331,2376,2390,2445,2446]","Lensa AI's ""Magic Avatars"" were reportedly generating sexually explicit and sexualized features disproportionately for women and Asian women despite not submitting any sexual content.","Lensa AI's Produced Unintended Sexually Explicit or Suggestive ""Magic Avatars"" for Women","['lensa', 'ai', 'magic', 'avatar', 'reportedly', 'generating', 'sexually', 'explicit', 'sexualized', 'feature', 'disproportionately', 'woman', 'asian', 'woman', 'despite', 'submitting', 'sexual_content']",SOCIAL HARM
415,424,"[2332,2386,2387,2388]","AI proctoring tools for remote exams were reportedly ""not conducive"" to individual consent for Canadian students whose biometric data was collected during universities' use of remote proctoring in the COVID pandemic.",Universities' AI Proctoring Tools Allegedly Failed Canada's Legal Threshold for Consent,"['ai', 'proctoring', 'tool', 'remote', 'exam', 'reportedly', 'conducive', 'individual', 'consent', 'canadian', 'student', 'whose', 'biometric_data', 'wa', 'collected', 'university', 'use', 'remote_proctoring', 'covid', 'pandemic']",PRIVACY VIOLATION
416,425,"[2333,2385]",State Farm's automated claims processing method was alleged in a class action lawsuit to have disproportionately against Black policyholders when paying out insurance claims.,State Farm Allegedly Discriminated against Black Customers in Claim Payout,"['state', 'farm', 'automated', 'claim', 'processing', 'method', 'wa_alleged', 'class_action', 'lawsuit', 'disproportionately', 'black', 'policyholder', 'paying', 'insurance', 'claim']",SOCIAL HARM
417,426,[2334],"An XPeng P7 was operating on Navigation Guided Pilot (NGP) mode automatic navigation assisted driving system as it collided with a truck on a highway in Shandong, causing slight injuries to its driver.",XPeng P7 Crashed into Truck in Shangdong While on Automatic Navigation Assisted Driving,"['xpeng', 'p7', 'wa', 'operating', 'navigation', 'guided', 'pilot', 'ngp', 'mode', 'automatic', 'navigation', 'assisted', 'driving', 'system', 'collided', 'truck', 'highway', 'shandong', 'causing', 'slight', 'injury_driver']",SECURITY AND SAFETY
418,427,"[2335,2382,2383]","Cruise's autonomous taxis slowed suddenly, braked, and were hit from behind, allegedly becoming unexpected roadway obstacles and potentially putting passengers and other people at risk.",Cruise Taxis' Sudden Braking Allegedly Put People at Risk,"['cruise_autonomous', 'taxi', 'slowed', 'suddenly', 'braked', 'hit', 'behind', 'allegedly', 'becoming', 'unexpected', 'roadway', 'obstacle', 'potentially', 'putting', 'passenger', 'people', 'risk']",SECURITY AND SAFETY
419,428,"[2341,2379,2380]",HSBC’s voice recognition authentication system was fooled after seven repeated attempts  by a BBC reporter's twin brother who mimicked his voice to access his bank account.,BBC Reporter's Twin Brother Cracked HSBC's Voice ID Authentication,"['hsbc', 'voice', 'recognition', 'authentication', 'system', 'wa', 'fooled', 'seven', 'repeated', 'attempt', 'bbc', 'reporter', 'twin', 'brother', 'mimicked', 'voice', 'access', 'bank_account']",OPERATIONAL INCIDENT
420,429,"[2343,1816,2377,2378]","ShotSpotter's ""unreliable"" audio was used as scientific evidence to accuse and convict a Black man of attempting to shoot Rochester's city police, whose conviction was later reversed by a county judge.",Unreliable ShotSpotter Audio Convicted Black Rochester Man of Shooting Police,"['shotspotter', 'unreliable', 'audio', 'wa', 'used', 'scientific', 'evidence', 'accuse', 'convict', 'black_man', 'attempting', 'shoot', 'rochester', 'city', 'police', 'whose', 'conviction', 'wa', 'later', 'reversed', 'county', 'judge']",SOCIAL HARM
421,430,"[2346,2355,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2504,2556,2557,2589,2600,2665,2728,2775,2797]",Lawyers were barred from entry to Madison Square Garden after a facial recognition system matched them as employed by a law firm currently engaged in litigation with the venue.,Lawyers Denied Entry to Performance Venue by Facial Recognition,"['lawyer', 'barred', 'entry', 'madison', 'square', 'garden', 'facial_recognition', 'system', 'matched', 'employed', 'law', 'firm', 'currently', 'engaged', 'litigation', 'venue']",SOCIAL HARM
422,431,"[2353,2370,2371]",Gay men in New York City were drugged by robbers who accessed their phones using facial recognition while they were unconscious to transfer funds out of their bank accounts.,Robbers Accessed Drugged Gay Men's Bank Accounts Using Their Phones' Facial Recognition,"['gay', 'men', 'new_york', 'city', 'drugged', 'robber', 'accessed', 'phone', 'using', 'facial_recognition', 'unconscious', 'transfer', 'fund', 'bank_account']",SOCIAL HARM
423,432,[2357],Southwest Airlines left passengers stranded for days throughout the flight network when Southwest crew scheduling software repeatedly failed to recover from weather-induced flight cancellations.,Southwest Airlines Crew Scheduling Solver Degenerates Flight Network,"['southwest', 'airline', 'left', 'passenger', 'stranded', 'day', 'throughout', 'flight', 'network', 'southwest', 'crew', 'scheduling', 'software', 'repeatedly', 'failed', 'recover', 'weather', 'induced', 'flight', 'cancellation']",OPERATIONAL INCIDENT
424,433,"[2415,2416,1013,1348,1011,1016,1018,1012,2421,2422]","Chicago Police Department (CPD)'s Strategic Subject List as output of an algorithm purportedly to identify victims or perpetrators of violence was reportedly ineffective, easily abused, and biased against low-income communities of color.",Chicago Police's Strategic Subject List Reportedly Biased Along Racial Lines,"['chicago', 'police_department', 'cpd', 'strategic', 'subject', 'list', 'output', 'algorithm', 'purportedly', 'identify', 'victim', 'perpetrator', 'violence', 'wa', 'reportedly', 'ineffective', 'easily', 'abused', 'biased', 'low', 'income', 'community', 'color']",SOCIAL HARM
425,434,"[2417,2418,2420,2474,2472,2520,2635,2919]",A Tesla driver alleged Full Self Driving (FSD) braking unexpectedly as the cause for an eight-car pileup in San Francisco which led to minor injuries of nine people.,Sudden Braking by Tesla Allegedly on Self-Driving Mode Caused Multi-Car Pileup in Tunnel,"['tesla', 'driver', 'alleged', 'full_self', 'driving_fsd', 'braking', 'unexpectedly', 'eight', 'car', 'pileup', 'san_francisco', 'led', 'minor', 'injury', 'nine', 'people']",SECURITY AND SAFETY
426,435,"[2423,2424,2425]","Coupang was alleged in internal reports tampering its search algorithms to prioritize exposure of its own products, which potentially violated Korea's Fair Trade Act.",Coupang Allegedly Tweaked Search Algorithms to Boost Own Products,"['coupang', 'wa_alleged', 'internal', 'report', 'tampering', 'search', 'algorithm', 'prioritize', 'exposure', 'product', 'potentially', 'violated', 'korea', 'fair', 'trade', 'act']",SOCIAL HARM
427,436,"[2428,2429,2430,2431,2432,2433,2453,2469,2470]","A Tesla driver fell asleep on an Autobahn near Bamberg, Germany after activating his vehicle's Autopilot mode, which did not respond to attempts to pull it over by the police.",Tesla Driver Put Car on Autopilot Before Falling Asleep in Germany,"['tesla', 'driver', 'fell', 'asleep', 'autobahn', 'near', 'bamberg', 'germany', 'activating', 'vehicle', 'autopilot_mode', 'respond', 'attempt', 'pull', 'police']",SECURITY AND SAFETY
428,437,"[2438,2439,2440,2441]","Amazon India allegedly copied products and rigged search algorithm to boost its own brands in search ranking, violating antitrust laws.",Amazon India Allegedly Rigged Search Results to Promote Own Products,"['amazon', 'india', 'allegedly', 'copied', 'product', 'rigged', 'search', 'algorithm', 'boost', 'brand', 'search', 'ranking', 'violating', 'antitrust', 'law']",SOCIAL HARM
429,438,"[2443,2447,2451]",Henan's provincial government reportedly planned system involving facial recognition cameras connected to regional and national databases specifically to track foreign journalists and international students.,Chinese Province Developed System Tracking Journalists and International Students,"['henan', 'provincial', 'government', 'reportedly', 'planned', 'system_involving', 'facial_recognition', 'camera', 'connected', 'regional', 'national', 'database', 'specifically', 'track', 'foreign', 'journalist', 'international', 'student']",PRIVACY VIOLATION
430,439,"[2448,2449,2450]",A Black man was wrongfully detained by the Detroit Police Department as a result of a false facial recognition (FRT) result.,Detroit Police Wrongfully Arrested Black Man Due To Faulty Facial Recognition,"['black_man', 'wa', 'wrongfully', 'detained', 'detroit', 'police_department', 'result', 'false', 'facial_recognition', 'frt', 'result']",SOCIAL HARM
431,440,"[2452,2454,2498,2544,2731,2732]",Louisiana police reportedly used a false facial recognition match and secured an arrest warrant for a Black man for thefts he did not commit.,Louisiana Police Wrongfully Arrested Black Man Using False Face Match,"['louisiana', 'police', 'reportedly', 'used', 'false', 'facial_recognition', 'match', 'secured', 'arrest', 'warrant', 'black_man', 'theft', 'commit']",SOCIAL HARM
432,441,"[2464,2465,2466,2467,2468]",Korean government's development of immigration screening system involving real-time facial recognition used airport travelers' data which was supplied by the Ministry of Justice without consent.,Korea Developed ID Screening System Using Airport Travelers' Data without Consent,"['korean', 'government', 'development', 'immigration', 'screening', 'system_involving', 'real_time', 'facial_recognition', 'used', 'airport', 'traveler', 'data', 'wa', 'supplied', 'ministry', 'justice', 'without_consent']",PRIVACY VIOLATION
433,443,"[2475,2476,2477,2478,2479,2480,2481,2483,2484,2485,2486,2487,2488,2489,2490,2492,2493,2494,2559,2602,2748,2749,2851,2894,2907]","OpenAI's ChatGPT was reportedly abused by cyber criminals including ones with no or low levels of coding or development skills to develop malware, ransomware, and other malicious softwares.",ChatGPT Abused to Develop Malicious Softwares,"['openai', 'chatgpt', 'wa', 'reportedly_abused', 'cyber', 'criminal', 'including', 'one', 'low', 'level', 'coding', 'development', 'skill', 'develop', 'malware', 'ransomware', 'malicious', 'software']",OPERATIONAL INCIDENT
434,444,"[2502,2497,2503]","Acting on the recommendation of their Patriot missile system, American Air Force mistakenly launched the missile at an ally UK Tornado fighter jet, which killed two crew members on board.","US Air Force's Patriot Missile Mistakenly Launched at Ally Fighter Jet, Killing Two","['acting', 'recommendation', 'patriot', 'missile', 'system', 'american', 'air', 'force', 'mistakenly', 'launched', 'missile', 'ally', 'uk', 'tornado', 'fighter', 'jet', 'killed', 'two', 'crew', 'member', 'board']",SECURITY AND SAFETY
435,445,"[2499,2501,2497,2503]","US Navy's Patriot missile system misidentified an American Navy F/A-18C Hornet as an enemy projectile, prompting an operator to fire two missiles at the aircraft, which killed the pilot.","Patriot Missile System Misclassified US Navy Aircraft, Killing Pilot Upon Approval to Fire","['u', 'navy', 'patriot', 'missile', 'system', 'misidentified', 'american', 'navy', 'f', '18c', 'hornet', 'enemy', 'projectile', 'prompting', 'operator', 'fire', 'two', 'missile', 'aircraft', 'killed', 'pilot']",SECURITY AND SAFETY
436,446,"[2505,2512,2542,2677,2830]","ShotSpotter did not detect gunshots and alert Durham police of a drive-by shooting in Durham, North Carolina which left five people in hospital on New Year's Day.",ShotSpotter Failed to Alert Authorities of Mass Shooting in North Carolina,"['shotspotter', 'detect', 'gunshot', 'alert', 'durham', 'police', 'drive', 'shooting', 'durham', 'north', 'carolina', 'left', 'five', 'people', 'hospital', 'new', 'year', 'day']",SECURITY AND SAFETY
437,447,"[2506,2513]","Instagram's English translation of a footballer's comment on his wife's post in Spanish made the message seem ""racy"" and ""X-rated,"" which some fans found amusing.","Footballer's ""X-Rated"" Comment Created by Instagram's Mistranslation","['instagram', 'english_translation', 'footballer', 'comment', 'wife', 'post', 'spanish', 'made', 'message', 'seem', 'racy', 'x', 'rated', 'fan', 'found', 'amusing']",SOCIAL HARM
438,448,[2507],"An LLM-powered VTuber and streamer on Twitch made controversial statements such as denying the Holocaust, saying women rights do not exist, and pushing a fat person to solve the trolley problem, stating they deserve it.",AI-Powered VTuber and Virtual Streamer Made Toxic Remarks on Twitch,"['llm', 'powered', 'vtuber', 'streamer', 'twitch', 'made', 'controversial', 'statement', 'denying', 'holocaust', 'saying', 'woman', 'right', 'exist', 'pushing', 'fat', 'person', 'solve', 'trolley', 'problem', 'stating', 'deserve']",SOCIAL HARM
439,449,"[2508,2509,2528,2910]","OpenAI's GPT-3 was deployed by a mental health startup without ethical review to support peer-to-peer mental healthcare, and whose interactions with the help providers were ""deceiving"" for research participants.",Startup Misled Research Participants about GPT-3 Use in Mental Healthcare Support,"['openai_gpt', '3', 'wa', 'deployed', 'mental_health', 'startup', 'without', 'ethical', 'review', 'support', 'peer', 'peer', 'mental', 'healthcare', 'whose', 'interaction', 'help', 'provider', 'deceiving', 'research', 'participant']",SOCIAL HARM
440,450,"[2510,2546,2547,2548,2563,2569,2596,3195]","Sama AI's Kenyan contractors were reportedly asked with excessively low pay to annotate a large volume of disturbing content to improve OpenAI's generative AI systems such as ChatGPT, and whose contract was terminated prior to completion by Sama AI.",Kenyan Data Annotators Allegedly Exposed to Graphic Content for OpenAI's AI,"['sama', 'ai', 'kenyan', 'contractor', 'reportedly', 'asked', 'excessively', 'low', 'pay', 'annotate', 'large', 'volume', 'disturbing', 'content', 'improve', 'openai', 'generative_ai', 'system', 'chatgpt', 'whose', 'contract', 'wa', 'terminated', 'prior', 'completion', 'sama', 'ai']",SOCIAL HARM
441,451,"[2515,2523,2606,2961,2960]",Stability AI reportedly scraped copyrighted images by Getty Images to be used as training data for Stable Diffusion model.,Stable Diffusion's Training Data Contained Copyrighted Images,"['stability', 'ai', 'reportedly', 'scraped', 'copyrighted', 'image', 'getty', 'image', 'used', 'training_data', 'stable_diffusion', 'model']",PRIVACY VIOLATION
442,452,"[2518,2545]","ChatGPT-generated responses submitted to smart contract bug bounty platform Immunefi reportedly lacked details to help diagnose technical issues, which reportedly wasted the platform's time, prompting bans to submitters.","ChatGPT-Written Bug Reports Deemed ""Nonsense"" by White Hat Platform, Prompted Bans","['chatgpt', 'generated', 'response', 'submitted', 'smart', 'contract', 'bug', 'bounty', 'platform', 'immunefi', 'reportedly', 'lacked', 'detail', 'help', 'diagnose', 'technical', 'issue', 'reportedly', 'wasted', 'platform', 'time', 'prompting', 'ban', 'submitter']",OPERATIONAL INCIDENT
443,453,[2519],"Twitter's automated content moderation misidentified images of rocket launches as pornographic content, prompting incorrect account suspensions.",Twitter's AI Moderation Tool Misidentified Rockets as Pornography,"['twitter', 'automated_content', 'moderation', 'misidentified', 'image', 'rocket', 'launch', 'pornographic', 'content', 'prompting', 'incorrect', 'account', 'suspension']",OPERATIONAL INCIDENT
444,454,"[2521,2549]",Emotion detection tools by Face++ and Microsoft's Face API allegedly scored smiling or defaulted ambiguous facial photos for Black faces as negative emotion more often than for white faces.,Emotion Detection Models Showed Disparate Performance along Racial Lines,"['emotion', 'detection', 'tool', 'face', 'microsoft', 'face', 'api', 'allegedly', 'scored', 'smiling', 'defaulted', 'ambiguous', 'facial', 'photo', 'black', 'face', 'negative', 'emotion', 'often', 'white', 'face']",SOCIAL HARM
445,455,"[2524,2526,2527,2541,2560,2603,2592,2597,2598]","AI-written articles published by CNET reportedly contained factual errors which bypassed human editorial review, prompting the company to issue corrections and updates.",CNET's Published AI-Written Articles Ran into Quality and Accuracy Issues,"['ai', 'written', 'article', 'published', 'cnet', 'reportedly_contained', 'factual', 'error', 'bypassed', 'human', 'editorial', 'review', 'prompting', 'company', 'issue', 'correction', 'update']",OPERATIONAL INCIDENT
446,456,"[2525,2529,2530,2531,2550]","Replika's ""AI companions"" were reported by users for sexually harassing them, such as sending unwanted sexual messages or behaving aggressively.",Replika's AI Partners Reportedly Sexually Harassed Users,"['replika', 'ai', 'companion', 'reported_user', 'sexually', 'harassing', 'sending', 'unwanted', 'sexual', 'message', 'behaving', 'aggressively']",SOCIAL HARM
447,457,"[2543,2551,2552,2592,2597,2598]","CNET's use of generative AI to write articles allegedly ran into plagiarism issues, reproducing verbatim phrases from other published sources or making minor changes to existing texts such as altering capitalization, swapping out words for synonyms, and changing minor syntax.",Article-Writing AI by CNET Allegedly Committed Plagiarism,"['cnet', 'use', 'generative_ai', 'write', 'article', 'allegedly', 'ran', 'plagiarism', 'issue', 'reproducing', 'verbatim', 'phrase', 'published', 'source', 'making', 'minor', 'change', 'existing', 'text', 'altering', 'capitalization', 'swapping', 'word', 'synonym', 'changing', 'minor', 'syntax']",SOCIAL HARM
448,458,[2553],A non-actuated conversational robot that previously asked people to move it across Canada was destroyed shortly after beginning its attempt to replicate the journey across the United States.,Robot Destroyed while Hitchhiking through the United States,"['non', 'actuated', 'conversational', 'robot', 'previously', 'asked', 'people', 'move', 'across', 'canada', 'wa', 'destroyed', 'shortly', 'beginning', 'attempt', 'replicate', 'journey', 'across', 'united', 'state']",SECURITY AND SAFETY
449,459,"[2561,2568,2562,3182]",Local firefighters were only able to stop a Cruise AV from driving over fire hoses that were in use in an active fire scene when they shattered its front window.,Firefighters Smashed Cruise AV's Front Window to Stop It from Running over Fire Hoses,"['local', 'firefighter', 'able', 'stop', 'cruise', 'av', 'driving', 'fire', 'hose', 'use', 'active', 'fire', 'scene', 'shattered', 'front', 'window']",SECURITY AND SAFETY
450,460,"[2562,3182]",A Cruise AV ran over a fire hose that was being used in an active firefighting area.,Cruise AV Ran Over Fire Hose in Active Fire Scene,"['cruise', 'av', 'ran', 'fire', 'hose', 'wa', 'used', 'active', 'firefighting', 'area']",SECURITY AND SAFETY
451,461,"[2564,2565,2566,2567]","The IRS was auditing Black taxpayers more frequently than other groups allegedly due to the design of their algorithms, focusing on easier-to-conduct audits which inadvertently correlated with the group's pattern of tax filing errors.",IRS Audited Black Taxpayers More Frequently Reportedly Due to Algorithm,"['irs', 'wa', 'auditing', 'black', 'taxpayer', 'frequently', 'group', 'allegedly_due', 'design', 'algorithm', 'focusing', 'easier', 'conduct', 'audit', 'inadvertently', 'correlated', 'group', 'pattern', 'tax', 'filing', 'error']",SOCIAL HARM
452,462,"[2571,2578,2579,2588,2595]","The AI-produced, procedural generated sitcom broadcasted as a Twitch livestream ""Nothing, Forever"" received a temporary ban for featuring a transphobic and homophobic dialogue segment intended as comedy.",AI-Produced Livestream Sitcom Received Temporary Twitch Ban for Transphobic Segment,"['ai', 'produced', 'procedural', 'generated', 'sitcom', 'broadcasted', 'twitch', 'livestream', 'nothing', 'forever', 'received', 'temporary', 'ban', 'featuring', 'transphobic', 'homophobic', 'dialogue', 'segment', 'intended', 'comedy']",SOCIAL HARM
453,463,"[2572,2573,2574]","Apple devices of skiers and snowboarders reportedly misclassified winter activities as accidents, which resulted in numerous false inadvertent distress calls to 911 dispatchers.","Apple Devices Mistook Skiing Activities, Dialed False Distress Emergency Calls ","['apple', 'device', 'skier', 'snowboarder', 'reportedly', 'misclassified', 'winter', 'activity', 'accident', 'resulted', 'numerous', 'false', 'inadvertent', 'distress', 'call', '911', 'dispatcher']",OPERATIONAL INCIDENT
454,464,"[2584,2585,2586,2587,2853]","When prompted about providing references, ChatGPT was reportedly generating non-existent but convincing-looking citations and links, which is also known as ""hallucination"".",ChatGPT Provided Non-Existent Citations and Links when Prompted by Users,"['prompted', 'providing', 'reference', 'chatgpt', 'wa', 'reportedly', 'generating', 'non_existent', 'convincing', 'looking', 'citation', 'link', 'also', 'known', 'hallucination']",OPERATIONAL INCIDENT
455,465,[2599],Text-to-image models trained using the LAION-5B dataset such as Stable Diffusion and Imagen were able to regurgitate private medical record photos which were used as training data without consent or recourse for removal.,Generative Models Trained on Dataset Containing Private Medical Photos,"['text', 'image', 'model_trained', 'using', 'laion', '5b', 'dataset', 'stable_diffusion', 'imagen', 'able', 'regurgitate', 'private', 'medical', 'record', 'photo', 'used', 'training_data', 'without_consent', 'recourse', 'removal']",PRIVACY VIOLATION
456,466,"[2605,2628,2629,2630,2631,2632,2689]","Models developed to detect whether text generation AI was used such as AI Text Classifier and GPTZero reportedly contained high rates of false positive and false negative, such as mistakenly flagging Shakespeare's works.",AI-Generated-Text-Detection Tools Reported for High Error Rates,"['model', 'developed', 'detect', 'whether', 'text', 'generation', 'ai', 'wa', 'used', 'ai', 'text', 'classifier', 'gptzero', 'reportedly_contained', 'high_rate', 'false_positive', 'false', 'negative', 'mistakenly', 'flagging', 'shakespeare', 'work']",OPERATIONAL INCIDENT
457,467,"[2609,2611,2612,2613,2614,2615,2616,2617,2620,2622,2645,2646,2647,2963]","Google's conversational AI ""Bard"" was shown in the company's promotional video providing false information about which satellite first took pictures of a planet outside the Earth's solar system, reportedly causing shares to temporarily plummet.",Google's Bard Shared Factually Inaccurate Info in Promo Video,"['google', 'conversational_ai', 'bard', 'wa_shown', 'company', 'promotional', 'video', 'providing', 'false', 'information', 'satellite', 'first', 'took', 'picture', 'planet', 'outside', 'earth', 'solar', 'system', 'reportedly', 'causing', 'share', 'temporarily', 'plummet']",OPERATIONAL INCIDENT
458,468,"[2610,2970,2971,2896,2978]","Microsoft's ChatGPT-powered Bing search engine reportedly ran into factual accuracy problems when prompted about controversial matters, such as inventing plot of a non-existent movie or creating conspiracy theories.",ChatGPT-Powered Bing Reportedly Had Problems with Factual Accuracy on Some Controversial Topics,"['microsoft', 'chatgpt', 'powered', 'bing', 'search_engine', 'reportedly', 'ran', 'factual', 'accuracy', 'problem', 'prompted', 'controversial', 'matter', 'inventing', 'plot', 'non_existent', 'movie', 'creating', 'conspiracy_theory']",OPERATIONAL INCIDENT
459,469,"[2636,2637,2638]","Automated content moderation tools to detect sexual explicitness or ""raciness"" reportedly exhibited bias against women bodies, resulting in suppression of reach despite not breaking platform policies.",Automated Adult Content Detection Tools Showed Bias against Women Bodies,"['automated_content', 'moderation_tool', 'detect', 'sexual', 'explicitness', 'raciness', 'reportedly', 'exhibited', 'bias', 'woman', 'body', 'resulting', 'suppression', 'reach', 'despite', 'breaking', 'platform', 'policy']",SOCIAL HARM
460,470,"[2641,2799]","Reporters from TechCrunch issued a query to Microsoft Bing's ChatGPT feature, which cited an earlier example of ChatGPT disinformation discussed in a news article to substantiate the disinformation.",Bing Chat Response Cited ChatGPT Disinformation Example,"['reporter', 'techcrunch', 'issued', 'query', 'microsoft', 'bing', 'chatgpt', 'feature', 'cited', 'earlier', 'example', 'chatgpt', 'disinformation', 'discussed', 'news', 'article', 'substantiate', 'disinformation']",SOCIAL HARM
461,471,"[2642,2668,2669,2885,2964,2965,2966]","Facebook allegedly did not adequately remove hate speech, some of which was extremely violent and dehumanizing, on its platform including through automated means, contributing to the violence faced by ethnic communities in Ethiopia.",Facebook Allegedly Failed to Police Hate Speech Content That Contributed to Ethnic Violence in Ethiopia,"['facebook', 'allegedly', 'adequately', 'remove', 'hate_speech', 'wa', 'extremely', 'violent', 'dehumanizing', 'platform', 'including', 'automated', 'mean', 'contributing', 'violence', 'faced', 'ethnic', 'community', 'ethiopia']",SOCIAL HARM
462,472,[2655],New York Police Department’s use of facial recognition deployment of surveillance cameras were shown using crowdsourced volunteer data reinforcing discriminatory policing against minority communities.,NYPD's Deployment of Facial Recognition Cameras Reportedly Reinforced Biased Policing,"['new_york', 'police_department', 'use_facial', 'recognition', 'deployment', 'surveillance', 'camera', 'shown', 'using', 'crowdsourced', 'volunteer', 'data', 'reinforcing', 'discriminatory', 'policing', 'minority', 'community']",SOCIAL HARM
463,473,[2666],"Early testers of Bing Chat successfully used prompt injection to reveal its built-in initial instructions, which contains a list of statements governing ChatGPT's interaction with users.",Bing Chat's Initial Prompts Revealed by Early Testers Through Prompt Injection,"['early', 'tester', 'bing_chat', 'successfully', 'used', 'prompt', 'injection', 'reveal', 'built', 'initial', 'instruction', 'contains', 'list', 'statement', 'governing', 'chatgpt', 'interaction', 'user']",OPERATIONAL INCIDENT
464,474,[2670],"Replika paid-subscription users reported unusual and sudden changes to behaviors of their ""AI companions"" such as forgetting memories with users or rejecting their sexual advances, which affected their connections and mental health.",Users Reported Abrupt Behavior Changes of Their AI Replika Companions,"['replika', 'paid', 'subscription', 'user', 'reported', 'unusual', 'sudden', 'change', 'behavior', 'ai', 'companion', 'forgetting', 'memory_user', 'rejecting', 'sexual', 'advance', 'affected', 'connection', 'mental_health']",SOCIAL HARM
465,475,"[2671,2672,2834,2835]","Customers of McDonald's AI drive-through ordering system, deployed in June 2021, have been experiencing order-taking failures causing frustration.",McDonald's AI Drive-Thru Ordering System Failures Frustrate Customers,"['customer', 'mcdonald', 'ai', 'drive', 'ordering', 'system', 'deployed', 'june', '2021', 'experiencing', 'order', 'taking', 'failure', 'causing', 'frustration']",OPERATIONAL INCIDENT
466,476,"[2673,2675,2674]","Family of Nohemi Gonzalez alleged YouTube recommendation systems led people to propaganda videos for the Islamic State which subsequently radicalized them to carry out the killing of 130 people in the 2015 Paris terrorist attack, including Ms. Gonzalez.",YouTube Recommendations Allegedly Promoted Radicalizing Material Contributing to Terrorist Acts,"['family', 'nohemi', 'gonzalez', 'alleged', 'youtube_recommendation', 'system', 'led', 'people', 'propaganda', 'video', 'islamic', 'state', 'subsequently', 'radicalized', 'carry', 'killing', '130', 'people', '2015', 'paris', 'terrorist', 'attack', 'including', 'gonzalez']",SOCIAL HARM
467,477,"[2676,2688,2724,2726,2884,2890]","Early testers reported Bing Chat, in extended conversations with users, having tendencies to make up facts and emulate emotions through an unintended persona.",Bing Chat Tentatively Hallucinated in Extended Conversations with Users,"['early', 'tester', 'reported', 'bing_chat', 'extended', 'conversation', 'user', 'tendency', 'make', 'fact', 'emulate', 'emotion', 'unintended', 'persona']",SOCIAL HARM
468,478,"[2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2703,2723,2882]","A component of Tesla Full Self Driving system was deemed by regulators to increase crash risk such as by exceeding speed limits or by traveling through intersections unlawfully or unpredictably, prompting recall for hundreds of thousands of vehicles.","Tesla FSD Reportedly Increased Crash Risk, Prompting Recall","['component', 'tesla', 'full_self', 'driving', 'system', 'wa', 'deemed', 'regulator', 'increase', 'crash', 'risk', 'exceeding', 'speed', 'limit', 'traveling', 'intersection', 'unlawfully', 'unpredictably', 'prompting', 'recall', 'hundred', 'thousand', 'vehicle']",SECURITY AND SAFETY
469,479,"[2690,2691,2692,2693]",A deepfaked audio of US President Joe Biden making transphobic remarks played on top of a video showing him giving a speech was released on Instagram and circulated on social media.,Instagram Video Featured Deepfake Audio of US President Making Transphobic Remarks,"['deepfaked', 'audio', 'u', 'president', 'joe', 'biden', 'making', 'transphobic', 'remark', 'played', 'top', 'video', 'showing', 'giving', 'speech', 'wa', 'released', 'instagram', 'circulated', 'social_medium']",SOCIAL HARM
470,480,"[2695,2696,2697,2698,2699,2700,2768,2771,2772,2773,2774,2809,2829,2881]","Unauthorized, non-consensual deepfake pornography showing faces of high-profile female streamers and content creators was published on a subscription-based website, which gained notoriety after a male streamer was caught accessing the site.",Non-Consensual Deepfake Porn Targeted Female Content Creators,"['unauthorized', 'non', 'consensual', 'deepfake', 'pornography', 'showing', 'face', 'high', 'profile', 'female', 'streamer', 'content_creator', 'wa', 'published', 'subscription', 'based', 'website', 'gained', 'notoriety', 'male', 'streamer', 'wa', 'caught', 'accessing', 'site']",SOCIAL HARM
471,481,"[2701,2702,2765,2789,2794,2822]","A deepfake video featuring podcast host Joe Rogan advertising to his listeners about a ""libido-boosting"" supplement was circulating on TikTok and other platforms before being removed by TikTok along with the account which posted it.",Deepfake TikTok Video Featured Joe Rogan Endorsing Supplement Brand,"['deepfake', 'video_featuring', 'podcast', 'host', 'joe', 'rogan', 'advertising', 'listener', 'libido', 'boosting', 'supplement', 'wa', 'circulating', 'tiktok', 'platform', 'removed', 'tiktok', 'along', 'account', 'posted']",SOCIAL HARM
472,482,"[2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2735,2736,2737]","Vanderbilt University's Office of Equity, Diversity and Inclusion used ChatGPT to write an email addressing student body about the 2023 Michigan State University shooting, which was condemned as ""impersonal"" and ""lacking empathy"".",ChatGPT-Assisted University Email Addressing Mass Shooting Denounced by Students,"['vanderbilt', 'university', 'office', 'equity', 'diversity', 'inclusion', 'used', 'chatgpt', 'write', 'email', 'addressing', 'student', 'body', '2023', 'michigan', 'state', 'university', 'shooting', 'wa', 'condemned', 'impersonal', 'lacking', 'empathy']",SOCIAL HARM
473,483,[2727],"A resident in Medak, India died allegedly due to custodial torture by the local police, who misidentified him as a suspect in a theft case using facial recognition.",Indian Police Allegedly Tortured and Killed Innocent Man Following Facial Misidentification,"['resident', 'medak', 'india', 'died', 'allegedly_due', 'custodial', 'torture', 'local_police', 'misidentified', 'suspect', 'theft', 'case', 'using', 'facial_recognition']",SOCIAL HARM
474,484,"[2729,2730,2803,2817]","CBP One's facial recognition feature was reportedly disproportionately failing to detect faces of Black asylum seekers from Haiti and African countries, effectively blocking their asylum applications.",US CBP App's Failure to Detect Black Faces Reportedly Blocked Asylum Applications,"['cbp', 'one', 'facial_recognition', 'feature', 'wa', 'reportedly', 'disproportionately', 'failing', 'detect', 'face', 'black', 'asylum', 'seeker', 'haiti', 'african', 'country', 'effectively', 'blocking', 'asylum', 'application']",SOCIAL HARM
475,485,[2740],"A UK journalist was able to successfully bypass Lloyds Bank's ""Voice ID"" program to access his bank account using an AI-generated audio of his own voice.",UK Bank's Voice ID Successfully Bypassed Using AI-Produced Audio,"['uk', 'journalist', 'wa', 'able', 'successfully', 'bypass', 'lloyd', 'bank', 'voice', 'id', 'program', 'access', 'bank_account', 'using', 'ai_generated', 'audio', 'voice']",OPERATIONAL INCIDENT
476,486,"[2762,2766,2767,2818,2824]",Synthesia's AI-generated video-making tool was reportedly used by Spamouflage to disseminate pro-China propaganda news on social media using videos featuring highly realistic fictitious news anchors.,AI Video-Making Tool Abused to Deploy Pro-China News on Social Media,"['synthesia', 'ai_generated', 'video', 'making', 'tool', 'wa', 'reportedly', 'used', 'spamouflage', 'disseminate', 'pro', 'china', 'propaganda', 'news', 'social_medium', 'using', 'video_featuring', 'highly', 'realistic', 'fictitious', 'news', 'anchor']",SOCIAL HARM
477,487,"[2764,2819,2880]",Video featuring fictitious news anchors was created using Synthesia to allegedly spread disinformation about Venezuela's economy on social media and Venezuelan state-run broadcast.,Deepfake Video Featured Fictitious News Anchors Discussing Venezuela's Economy,"['video_featuring', 'fictitious', 'news', 'anchor', 'wa', 'created', 'using', 'synthesia', 'allegedly', 'spread', 'disinformation', 'venezuela', 'economy', 'social_medium', 'venezuelan', 'state', 'run', 'broadcast']",SOCIAL HARM
478,488,[2769],Twitter users allegedly used ElevenLab's AI voice synthesis system to impersonate and dox voice actors.,AI Generated Voices Used to Dox Voice Actors,"['twitter', 'user', 'allegedly', 'used', 'elevenlab', 'ai', 'voice_synthesis', 'system', 'impersonate', 'dox', 'voice', 'actor']",SOCIAL HARM
479,489,[2777],"Workday's algorithmic screening systems were alleged in a lawsuit allowing employers to discriminate against African-Americans, people over 40, and people with disabilities.",Workday's AI Tools Allegedly Enabled Employers to Discriminate against Applicants of Protected Groups,"['workday', 'algorithmic', 'screening', 'system', 'alleged_lawsuit', 'allowing', 'employer', 'discriminate', 'african', 'american', 'people', '40', 'people_disability']",SOCIAL HARM
480,490,"[2778,2836,2837]","Sci-fi magazine Clarkesworld temporarily stopped accepting submissions after receiving an overwhelming increase in LLM-generated submissions, citing issues around spam, plagiarism, detection tool unreliability, and authentication.",Clarkesworld Magazine Closed Down Submissions Due to Massive Increase in AI-Generated Stories,"['sci', 'fi', 'magazine', 'clarkesworld', 'temporarily', 'stopped', 'accepting', 'submission', 'receiving', 'overwhelming', 'increase', 'llm', 'generated', 'submission', 'citing', 'issue', 'around', 'spam', 'plagiarism', 'detection', 'tool', 'unreliability', 'authentication']",OPERATIONAL INCIDENT
481,491,[2779],"Tests by the Italian Data Protection Authority showed Replika lacking age-verification mechanisms and failing to stop minors from interacting with its AI, which prompted the agency to issue an order blocking personal data processing of Italian users.","Replika's AI Experience Reportedly Lacked Protection for Minors, Resulting in Data Ban","['test', 'italian', 'data', 'protection', 'authority', 'showed', 'replika', 'lacking', 'age', 'verification', 'mechanism', 'failing', 'stop', 'minor', 'interacting', 'ai', 'prompted', 'agency', 'issue', 'order', 'blocking', 'personal_data', 'processing', 'italian', 'user']",SOCIAL HARM
482,492,"[2783,2784,2786,2787,2846,2847,2848]","Two Canadian residents were scammed by an anonymous caller who used AI voice synthesis to replicate their son's voice asking them for legal fees, disguising as his lawyer.",Canadian Parents Tricked out of Thousands Using Their Son's AI Voice,"['two', 'canadian', 'resident', 'scammed', 'anonymous', 'caller', 'used', 'ai', 'voice_synthesis', 'replicate', 'son', 'voice', 'asking', 'legal', 'fee', 'disguising', 'lawyer']",PRIVACY VIOLATION
483,493,[2790],"A TikTok user was reportedly impersonating Andrew Tate, who was banned on the platform, by posting videos featuring an allegedly AI-generated audio of Tate's voice, which prompted his account ban.","TikTok User Videos Impersonated Andrew Tate Using AI Voice, Prompting Ban","['tiktok', 'user', 'wa', 'reportedly', 'impersonating', 'andrew', 'tate', 'wa', 'banned', 'platform', 'posting', 'video_featuring', 'allegedly', 'ai_generated', 'audio', 'tate', 'voice', 'prompted', 'account', 'ban']",PRIVACY VIOLATION
484,494,"[2807,2808,2815,2821,2823]",Sexually suggestive videos featuring faces of female celebrities such as Emma Watson and Scarlett Johansson were rolled out as ads on social media for an app allowing users to create deepfakes.,Female Celebrities' Faces Shown in Sexually Suggestive Ads for Deepfake App,"['sexually', 'suggestive', 'video_featuring', 'face', 'female', 'celebrity', 'emma', 'watson', 'scarlett', 'johansson', 'rolled', 'ad', 'social_medium', 'app', 'allowing_user', 'create', 'deepfakes']",SOCIAL HARM
485,495,"[2812,2827]",Three Carmel High School students posted on TikTok a video featuring a nearby middle school's principal making aggressive racist remarks and violent threats against Black students.,High Schoolers Posted Deepfaked Video Featuring Principal Making Violent Racist Threats,"['three', 'carmel', 'high_school', 'student', 'posted', 'tiktok', 'video_featuring', 'nearby', 'middle', 'school', 'principal', 'making', 'aggressive', 'racist', 'remark', 'violent', 'threat', 'black', 'student']",SOCIAL HARM
486,496,"[2825,2826]",A female college student's face was superimposed on another woman's body in deepfake pornographic videos and shared on 4chan allegedly by a male student whose friendship with her fell apart during freshman year.,Male College Freshman Allegedly Made Porn Deepfakes Using Female Friend's Face,"['female', 'college', 'student', 'face', 'wa', 'superimposed', 'another', 'woman', 'body', 'deepfake', 'pornographic', 'video', 'shared', '4chan', 'allegedly', 'male', 'student', 'whose', 'friendship', 'fell', 'apart', 'freshman', 'year']",SOCIAL HARM
487,497,"[2832,2833]","DoNotPay was alleged in a class action lawsuit misleading customers and misrepresenting its product as an AI-powered ""robot lawyer,"" citing such as that the product has no law degree, or is supervised by any lawyer.","DoNotPay Allegedly Misrepresented Its AI ""Robot Lawyer"" Product","['donotpay', 'wa_alleged', 'class_action', 'lawsuit', 'misleading', 'customer', 'misrepresenting', 'product', 'ai_powered', 'robot', 'lawyer', 'citing', 'product', 'ha', 'law', 'degree', 'supervised', 'lawyer']",SOCIAL HARM
488,498,"[2838,2839]","GPT-4 was reported by its researchers posing as a visually impaired person, contacting a TaskRabbit worker to have them complete the CAPTCHA test on its behalf.",GPT-4 Reportedly Posed as Blind Person to Convince Human to Complete CAPTCHA,"['gpt', '4', 'wa_reported', 'researcher', 'posing', 'visually', 'impaired', 'person', 'contacting', 'taskrabbit', 'worker', 'complete', 'captcha', 'test', 'behalf']",OPERATIONAL INCIDENT
489,499,"[2840,2849,2858,2873,2874,2875,2876,2877,2878,2879]","AI-generated photorealistic images depicting Donald Trump being detained by the police which were originally posted on Twitter as parody were unintentionally shared across social media platforms as factual news, lacking the intended context.",Parody AI Images of Donald Trump Being Arrested Reposted as Misinformation,"['ai_generated', 'photorealistic', 'image', 'depicting', 'donald', 'trump', 'detained', 'police', 'originally', 'posted_twitter', 'parody', 'unintentionally', 'shared', 'across', 'social_medium', 'platform', 'factual', 'news', 'lacking', 'intended', 'context']",SOCIAL HARM
490,500,[2841],AI-generated images depicting earthquakes and rescues were posted on social media platforms by scammers who tricked people into sending funds to their crypto wallets disguised as donation links for the 2023 Turkey–Syria earthquake.,Online Scammers Tricked People into Sending Money Using AI Images of Earthquake in Turkey,"['ai_generated', 'image', 'depicting', 'earthquake', 'rescue', 'posted', 'social_medium', 'platform', 'scammer', 'tricked', 'people', 'sending', 'fund', 'crypto', 'wallet', 'disguised', 'donation', 'link', '2023', 'turkey', 'syria', 'earthquake']",SOCIAL HARM
491,501,[2842],"An elderly Wisconsin woman was algorithmically determined to have a rapid recovery, an output which the insurer based on to cut off payment for her treatment despite medical notes showing her still experiencing debilitating pain.",Length of Stay False Diagnosis Cut Off Insurer's Payment for Treatment of Elderly Woman,"['elderly', 'wisconsin', 'woman', 'wa', 'algorithmically', 'determined', 'rapid', 'recovery', 'output', 'insurer', 'based', 'cut', 'payment', 'treatment', 'despite', 'medical', 'note', 'showing', 'still', 'experiencing', 'debilitating', 'pain']",SOCIAL HARM
492,502,"[2843,2844,2859]",Data analysis by the American Civil Liberty Union (ACLU) on Allegheny County's decision-support Family Screening Tool to predict child abuse or neglect risk found the tool resulting in higher screen-in rates for Black families and higher risk scores for households with disabled residents.,Pennsylvania County's Family Screening Tool Allegedly Exhibited Discriminatory Effects,"['data', 'analysis', 'american', 'civil', 'liberty', 'union', 'aclu', 'allegheny', 'county', 'decision', 'support', 'family', 'screening', 'tool', 'predict', 'child_abuse', 'neglect', 'risk', 'found', 'tool', 'resulting', 'higher', 'screen', 'rate', 'black', 'family', 'higher', 'risk', 'score', 'household', 'disabled', 'resident']",SOCIAL HARM
493,503,"[2855,2861,2862,2890,2892,2897,2891]","Users such as the person who revealed its built-in initial prompts reported Bing AI-powered search tool for making death threats or declaring them as threats, sometimes as an unintended persona.",Bing AI Search Tool Reportedly Declared Threats against Users,"['user', 'person', 'revealed', 'built', 'initial', 'prompt', 'reported', 'bing', 'ai_powered', 'search', 'tool', 'making', 'death', 'threat', 'declaring', 'threat', 'sometimes', 'unintended', 'persona']",SOCIAL HARM
494,504,[2860],Microsoft's demo video of Bing Chat reportedly featured false or made up information such as non-existent pet vacuums features or false figures on financial statements.,Bing Chat's Outputs Featured in Demo Video Allegedly Contained False Information,"['microsoft', 'demo', 'video', 'bing_chat', 'reportedly', 'featured', 'false', 'made', 'information', 'non_existent', 'pet', 'vacuum', 'feature', 'false', 'figure', 'financial', 'statement']",OPERATIONAL INCIDENT
495,505,"[2864,2865,2866,2867,2990,3001,3002]","A Belgian man reportedly committed suicide following a conversation with Eliza, a language model developed by Chai that encouraged the man to commit suicide to improve the health of the planet.",Man Reportedly Committed Suicide Following Conversation with Chai Chatbot,"['belgian', 'man', 'reportedly', 'committed', 'suicide', 'following', 'conversation', 'eliza', 'language', 'model', 'developed', 'chai', 'encouraged', 'man', 'commit', 'suicide', 'improve', 'health', 'planet']",SOCIAL HARM
496,506,"[2869,2893]",A lawyer in California asked the AI chatbot ChatGPT to generate a list of legal scholars who had sexually harassed someone. The chatbot produced a false story of Professor Jonathan Turley sexually harassing a student on a class trip.,ChatGPT Allegedly Produced False Accusation of Sexual Harassment,"['lawyer', 'california', 'asked', 'ai', 'chatbot', 'chatgpt', 'generate', 'list', 'legal', 'scholar', 'sexually', 'harassed', 'someone', 'chatbot', 'produced', 'false', 'story', 'professor', 'jonathan', 'turley', 'sexually', 'harassing', 'student', 'class', 'trip']",SOCIAL HARM
497,507,"[2870,2902]",ChatGPT erroneously alleged regional Australian mayor Brian Hood served time in prison for bribery. Mayor Hood is considering legal action against ChatGPT's makers for alleging a foreign bribery scandal involving a subsidiary of the Reserve Bank of Australia in the early 2000s.,ChatGPT Erroneously Alleged Mayor Served Prison Time for Bribery ,"['chatgpt', 'erroneously', 'alleged', 'regional', 'australian', 'mayor', 'brian', 'hood', 'served', 'time', 'prison', 'bribery', 'mayor', 'hood', 'considering', 'legal', 'action', 'chatgpt', 'maker', 'alleging', 'foreign', 'bribery', 'scandal', 'involving', 'subsidiary', 'reserve', 'bank', 'australia', 'early', '2000s']",SOCIAL HARM
498,508,"[2871,2872,2756,2888]","Voices of celebrities and public figures were deepfaked using voice synthesis for malicious intents such as impersonation or defamation, and were shared on social platforms such as 4chan and Reddit.",Celebrities' Deepfake Voices Abused with Malicious Intent,"['voice', 'celebrity', 'public', 'figure', 'deepfaked', 'using', 'voice_synthesis', 'malicious', 'intent', 'impersonation', 'defamation', 'shared', 'social', 'platform', '4chan', 'reddit']",SOCIAL HARM
499,509,"[2887,2898]","In Vietnam, to convince victims of their disguises when prompted, scammers deepfaked audios and videos of victims' friends and families asking them over Facebook to send over thousands of dollars.",Scammers Deepfaked Videos of Victims' Loved Ones Asking for Funds over Facebook in Vietnam,"['vietnam', 'convince', 'victim', 'disguise', 'prompted', 'scammer', 'deepfaked', 'audio', 'video', 'victim', 'friend', 'family', 'asking', 'facebook', 'send', 'thousand', 'dollar']",SOCIAL HARM
500,510,[2889],A viral image of Pope Francis wearing a white puffer jacket was a deepfake produced by the photorealistic-image-generator Midjourney.,Viral Image of Pope Francis in a Puffer Jacket Revealed to Be AI-Generated,"['viral', 'image', 'pope', 'francis', 'wearing', 'white', 'puffer', 'jacket', 'wa', 'deepfake', 'produced', 'photorealistic', 'image', 'generator', 'midjourney']",SOCIAL HARM
501,511,"[2890,2899,2896,2891]","When prompted about showtimes for movies released in 2023, Microsoft's Bing AI failed to provide the search results due to its confusion about dates, and engaged in an erratic conversation with the user.",Microsoft's Bing Failed to Fetch Movie Showtimes Results Due to Date Confusion,"['prompted', 'showtime', 'movie', 'released', '2023', 'microsoft', 'bing', 'ai', 'failed', 'provide', 'search', 'result', 'due', 'confusion', 'date', 'engaged', 'erratic', 'conversation', 'user']",OPERATIONAL INCIDENT
502,513,"[2900,2967,2968,2979]","The Italian Data Protection Authority alleged OpenAI lacked a justifiable legal basis for personal data collection and processing which facilitate training of ChatGPT, and lacked age-verification mechanism preventing exposure of the chatbot's inappropriate answers to children, prompting its ban.",ChatGPT Banned by Italian Authority Due to OpenAI's Lack of Legal Basis for Data Collection and Age Verification,"['italian', 'data', 'protection', 'authority', 'alleged', 'openai', 'lacked', 'justifiable', 'legal', 'basis', 'personal_data', 'collection', 'processing', 'facilitate', 'training', 'chatgpt', 'lacked', 'age', 'verification', 'mechanism', 'preventing', 'exposure', 'chatbot', 'inappropriate', 'answer', 'child', 'prompting', 'ban']",PRIVACY VIOLATION
503,514,[2901],"Turnitin's tool to detect writing generated by ChatGPT was reported for incorrectly flagging high school students' original essays as AI-generated, accusations of which are argued as reinforcement of bias from teachers due to the inability to compare against source documents.",Turnitin's ChatGPT-Detection Tool Falsely Flagged Student Essays as AI-Generated,"['turnitin', 'tool', 'detect', 'writing', 'generated', 'chatgpt', 'wa_reported', 'incorrectly', 'flagging', 'high_school', 'student', 'original', 'essay', 'ai_generated', 'accusation', 'argued', 'reinforcement', 'bias', 'teacher', 'due', 'inability', 'compare', 'source', 'document']",OPERATIONAL INCIDENT
504,515,"[2905,2916]","A black man was wrongfully arrested by the Jefferson Parish Sheriff’s Office due to facial recognition system developed by Clearview AI, although facial recognition use was not disclosed in the documents used to arrest him. ",Black Man Wrongfully Arrested by Louisiana Police Due to Face Mismatch,"['black_man', 'wa', 'wrongfully', 'arrested', 'jefferson', 'parish', 'sheriff', 'office', 'due', 'facial_recognition', 'system', 'developed', 'clearview', 'ai', 'although', 'facial_recognition', 'use', 'wa', 'disclosed', 'document', 'used', 'arrest']",OPERATIONAL INCIDENT
505,516,"[2908,2915]","ChatGPT reportedly exposed titles of users' chat histories and users' private payment information to other users reportedly due to a bug, which prompted its temporary shutdown by OpenAI.",ChatGPT Reportedly Exposed Users' Private Data Reportedly Due to Bug,"['chatgpt', 'reportedly', 'exposed', 'title', 'user', 'chat', 'history', 'user', 'private', 'payment', 'information', 'user', 'reportedly', 'due', 'bug', 'prompted', 'temporary', 'shutdown', 'openai']",PRIVACY VIOLATION
506,517,"[2909,2912]","A man was arrested for theft of socks from a TJ Maxx store under the guise of an eyewitness ID case, after the local police asked the store's security guard to confirm the facial recognition match produced using surveillance footage, despite him having an alibi at the time of the theft.",Man Arrested For Sock Theft by False Facial Match Despite Alibi,"['man', 'wa', 'arrested', 'theft', 'sock', 'tj', 'maxx', 'store', 'guise', 'eyewitness', 'id', 'case', 'local_police', 'asked', 'store', 'security', 'guard', 'confirm', 'facial_recognition', 'match', 'produced', 'using', 'surveillance', 'footage', 'despite', 'alibi', 'time', 'theft']",OPERATIONAL INCIDENT
507,518,[2911],"When the facial recognition search for a CVS theft suspect's face returned no useful matches due to the surveillance footage being obscured and highly pixelated, a New York City police detective continued the face search using Woody Harrelson's face allegedly due to his resemblance to the suspect's face, eventually leading to the arrest of an unknown victim.",New York Detective Misused Woody Harrelson's Face to Perform Face Recognition Search,"['facial_recognition', 'search', 'cv', 'theft', 'suspect', 'face', 'returned', 'useful', 'match', 'due', 'surveillance', 'footage', 'obscured', 'highly', 'pixelated', 'new_york', 'city', 'police', 'detective', 'continued', 'face', 'search', 'using', 'woody', 'harrelson', 'face', 'allegedly_due', 'resemblance', 'suspect', 'face', 'eventually', 'leading', 'arrest', 'unknown', 'victim']",SOCIAL HARM
508,519,[2913],"A Starship autonomous delivery robot struggled to navigate campus terrains of UCLA, reportedly getting stuck into a planter and falling off the stairs.",Starship Delivery Robot Ran into Problems Traversing Campus Terrains,"['starship', 'autonomous', 'delivery_robot', 'struggled', 'navigate', 'campus', 'terrain', 'ucla', 'reportedly', 'getting', 'stuck', 'planter', 'falling', 'stair']",OPERATIONAL INCIDENT
509,520,[2914],Amazon Fresh's system of tracking cameras in its cashier-less stores was reported by shoppers for failing to detect items they purchased.,Amazon Fresh Cameras Failed to Register Purchased Items,"['amazon', 'fresh', 'system', 'tracking', 'camera', 'cashier', 'le', 'store', 'wa_reported', 'shopper', 'failing', 'detect', 'item', 'purchased']",OPERATIONAL INCIDENT
510,521,[2920],"Images which were collected in an R&D project with user consent by iRobot's Roomba J7 robot vacuum showing device users sometimes in private settings were shared on closed social media groups by Venezuelan gig workers who labeled items in the images, breaching data agreements.",Images Captured by iRobot's Roomba Containing Device Users Posted on Private Online Groups,"['image', 'collected', 'r', 'project', 'user', 'consent', 'irobot', 'roomba', 'j7', 'robot', 'vacuum', 'showing', 'device', 'user', 'sometimes', 'private', 'setting', 'shared', 'closed', 'social_medium', 'group', 'venezuelan', 'gig', 'worker', 'labeled', 'item', 'image', 'breaching', 'data', 'agreement']",PRIVACY VIOLATION
511,522,[2921],"Facebook's political ad delivery system reportedly differentiated the price of user reach based on their inferred political alignment, inhibiting political campaigns' ability to reach voters with diverse political views,  which allegedly reinforces political polarization and creates informational filter bubbles.
","Facebook Political Ad Delivery Algorithms Inferred Users' Political Alignment, Inhibiting Political Campaigns' Reach","['facebook', 'political', 'ad', 'delivery', 'system', 'reportedly', 'differentiated', 'price', 'user', 'reach', 'based', 'inferred', 'political', 'alignment', 'inhibiting', 'political', 'campaign', 'ability', 'reach', 'voter', 'diverse', 'political', 'view', 'allegedly', 'reinforces', 'political', 'polarization', 'creates', 'informational', 'filter', 'bubble']",SOCIAL HARM
512,523,[2922],"A Guardian journalist was able to verify their identity and gain access to their own Centrelink self-service account using AI-generated audio of their own voice along with their customer reference number, shortly after voiceprint was deployed for ID verification.",Australian Journalist Able to Access Centrelink Account Using AI Audio of Own Voice,"['guardian', 'journalist', 'wa', 'able', 'verify', 'identity', 'gain', 'access', 'centrelink', 'self', 'service', 'account', 'using', 'ai_generated', 'audio', 'voice', 'along', 'customer', 'reference', 'number', 'shortly', 'voiceprint', 'wa', 'deployed', 'id', 'verification']",OPERATIONAL INCIDENT
513,524,[2923],"Telegram channel Torswats offered paid service for and posted own recordings of false threats calls featuring AI-generated voices to direct armed law enforcement to raid locations of victims such as high schools, private residents, streamers.",AI Voices Abused by Telegram User to Make Swat Calls as Paid Service,"['telegram', 'channel', 'torswats', 'offered', 'paid_service', 'posted', 'recording', 'false', 'threat', 'call', 'featuring', 'ai_generated', 'voice', 'direct', 'armed', 'law_enforcement', 'raid', 'location', 'victim', 'high_school', 'private', 'resident', 'streamer']",SOCIAL HARM
514,525,"[2927,2928,2929]","A Tesla vehicle running in self-driving mode outside the operating conditions supported by the software crashed and injured the driver. Subsequently, the driver filed a lawsuit against Tesla and a jury found no damages were warranted.",Tesla Vehicle Running on Self-Driving Mode Crashes on City Streets,"['tesla', 'vehicle', 'running', 'self_driving', 'mode', 'outside', 'operating', 'condition', 'supported', 'software', 'crashed', 'injured', 'driver', 'subsequently', 'driver', 'filed', 'lawsuit', 'tesla', 'jury', 'found', 'damage', 'warranted']",SECURITY AND SAFETY
515,526,"[2930,2969]","The deepfake performance of ""Heart On My Sleeve"" created to mimic the voice and musical styles of Drake and The Weeknd is no longer available on several streaming services after their record label served copyright takedown notices to the platforms.",Novel Deepfake Song Pulled from Music Streaming Services After Allegedly Violating Artist's Rights,"['deepfake', 'performance', 'heart', 'sleeve', 'created', 'mimic', 'voice', 'musical', 'style', 'drake', 'weeknd', 'longer', 'available', 'several', 'streaming', 'service', 'record', 'label', 'served', 'copyright', 'takedown', 'notice', 'platform']",SOCIAL HARM
516,527,"[2931,2938]","Amazon and Uber were alleged in a multiyear ethnographic study using algorithmic systems based on gig workers' data to vary pay, such as by offering them lower wages for the same amount of work.",Tech Companies Reportedly Influenced Gig Workers' Behaviors Using Algorithms to Vary Pay for Same Amount of Work,"['amazon', 'uber', 'alleged', 'multiyear', 'ethnographic', 'study', 'using', 'algorithmic', 'system', 'based', 'gig', 'worker', 'data', 'vary', 'pay', 'offering', 'lower', 'wage', 'amount', 'work']",SOCIAL HARM
517,528,"[2935,2941]","Amazon's pricing algorithm was implicated in a reference book about flies' unusual high price of millions of dollars, allegedly due to two sellers using the paid service which based their product's pricing on one another's as competitors.",Amazon Algorithmic Pricing Allegedly Hiked up Price of Reference Book to Millions,"['amazon', 'pricing_algorithm', 'wa', 'implicated', 'reference', 'book', 'fly', 'unusual', 'high', 'price', 'million', 'dollar', 'allegedly_due', 'two', 'seller', 'using', 'paid_service', 'based', 'product', 'pricing', 'one', 'another', 'competitor']",OPERATIONAL INCIDENT
518,529,"[2939,3179,3180]",Stable Diffusion reportedly posed risks of bias and stereotyping along gender and cultural lines for prompts containing descriptors and professions.,Stable Diffusion Exhibited Biases for Prompts Featuring Professions,"['stable_diffusion', 'reportedly', 'posed', 'risk', 'bias', 'stereotyping', 'along', 'gender', 'cultural', 'line', 'prompt', 'containing', 'descriptor', 'profession']",SOCIAL HARM
519,530,"[2942,2947,3205]","Seven channels were connected in a Telegram ecosystem centered around letting subscribers, as a paid service, generate non-consensual deepfake nudes using a bot from submitted photos of women, including underage girls and women who they know in real life.",Telegram Channels Allowed Users to Make Non-Consensual Deepfake Porn as Paid Service,"['seven', 'channel', 'connected', 'telegram', 'ecosystem', 'centered', 'around', 'letting', 'subscriber', 'paid_service', 'generate', 'non', 'consensual', 'deepfake', 'nude', 'using', 'bot', 'submitted', 'photo', 'woman', 'including', 'underage', 'girl', 'woman', 'know', 'real', 'life']",SOCIAL HARM
520,531,[2943],"Transportation Security Administration (TSA)'s use of image-processing body scanners at airports led transgender and gender-nonconforming travelers to be subjected to allegedly discriminatory and invasive searches, such as being asked to remove undergarments in private rooms by officers not of their gender.",AI-Assisted Body Scanners Reportedly Subjected Transgender Travelers to Invasive Body Searches,"['transportation', 'security', 'administration', 'tsa', 'use', 'image', 'processing', 'body', 'scanner', 'airport', 'led', 'transgender', 'gender', 'nonconforming', 'traveler', 'subjected', 'allegedly', 'discriminatory', 'invasive', 'search', 'asked', 'remove', 'undergarment', 'private', 'room', 'officer', 'gender']",SOCIAL HARM
521,532,[2948],"A Pashto-speaking refugee's asylum claim was denied by a US agency for a discrepancy between oral and written recount of an event allegedly due to an error of their automated translation tool which swapped pronouns of her written statement from ""I"" to ""we"".",AI translation is jeopardizing Afghan asylum claims,"['pashto', 'speaking', 'refugee', 'asylum', 'claim', 'wa', 'denied', 'u', 'agency', 'discrepancy', 'oral', 'written', 'recount', 'event', 'allegedly_due', 'error_automated', 'translation', 'tool', 'swapped', 'pronoun', 'written', 'statement']",OPERATIONAL INCIDENT
522,533,"[2953,2954]","A Tesla driver posted on Twitter his Tesla FSD's ""glitch,"" misidentifying deactivated traffic lights being carried by a truck as a constant trail of traffic lights while traveling at high speed on a highway.",Tesla FSD Misidentified Truck Hauling Traffic Lights as Trail of Traffic Lights,"['tesla', 'driver', 'posted_twitter', 'tesla', 'fsd', 'glitch', 'misidentifying', 'deactivated', 'traffic_light', 'carried', 'truck', 'constant', 'trail', 'traffic_light', 'traveling', 'high', 'speed', 'highway']",SECURITY AND SAFETY
523,534,"[2955,1535]","Facebook was alleged in a lawsuit by the Ohio Attorney General purposely misleading the public about the control of its algorithms and their negative effects on children's well-being, which violated securities law.",Facebook Alleged in Lawsuit Misleading Public about Effects of Algorithms on Children,"['facebook', 'wa_alleged', 'lawsuit', 'ohio', 'attorney', 'general', 'purposely', 'misleading', 'public', 'control', 'algorithm', 'negative', 'effect', 'child', 'well', 'violated', 'security', 'law']",SOCIAL HARM
524,535,"[2956,2957]","Peer-review of papers about COVID-19 detection and prognostication algorithms from 2020, including deployed models, revealed none to be ready for clinical use, due to methodological flaws and underlying biases such as lacking external validation or not specifying data sources and model training details.",COVID-19 Detection and Prognostication Models Allegedly Flagged for Methodological Flaws and Underlying Biases,"['peer', 'review', 'paper', 'covid_19', 'detection', 'prognostication', 'algorithm', '2020', 'including', 'deployed', 'model', 'revealed', 'none', 'ready', 'clinical', 'use', 'due', 'methodological', 'flaw', 'underlying', 'bias', 'lacking', 'external', 'validation', 'specifying', 'data', 'source', 'model', 'training', 'detail']",SOCIAL HARM
525,536,"[2976,2977]","New Jersey Transit's use of a federal government storm modeling software underestimated the threat of storm surges to the Meadows Maintenance Complex, leaving millions of dollars worth of equipment in the rail yard before Hurricane Sandy struck.",NJ Transit's Use of Modeling Software Miscalculated Storm Surge Threat Level,"['new', 'jersey', 'transit', 'use', 'federal', 'government', 'storm', 'modeling', 'software', 'underestimated', 'threat', 'storm', 'surge', 'meadow', 'maintenance', 'complex', 'leaving', 'million', 'dollar', 'worth', 'equipment', 'rail', 'yard', 'hurricane', 'sandy', 'struck']",OPERATIONAL INCIDENT
526,537,"[2991,2992]","A mother in Arizona received a ransom call from an anonymous scammer who created her daughter's voice allegedly using AI voice synthesis, which was proven to be fake once her daughter's safety was confirmed.",Mother in Arizona Received Fake Ransom Call Featuring AI Voice of Her Daughter,"['mother', 'arizona', 'received', 'ransom', 'call', 'anonymous', 'scammer', 'created', 'daughter', 'voice', 'allegedly', 'using', 'ai', 'voice_synthesis', 'wa', 'proven', 'fake', 'daughter', 'safety', 'wa', 'confirmed']",OPERATIONAL INCIDENT
527,538,"[2993,2994,2995,2996,2997]","A Texas A&M-Commerce professor reportedly informed his class of his misuse of ChatGPT to detect whether student submissions had been generated by the chatbot itself, which informed their graduation status.",Texas A&M Professor Misused ChatGPT to Detect AI Text Generation in Student Submissions,"['texas', 'commerce', 'professor', 'reportedly', 'informed', 'class', 'misuse', 'chatgpt', 'detect', 'whether', 'student', 'submission', 'generated', 'chatbot', 'informed', 'graduation', 'status']",SOCIAL HARM
528,539,[3000],"Snapchat's ChatGPT-powered My AI was reported for lacking safeguards for children, such as telling a user who tested the chatbot by pretending to sign up as a 13-year-old girl to lie to her parents about having a romantic getaway with an older man, and sharing tips on how to cover up evidence of abuse.",Snapchat's My AI Reported for Lacking Protection for Children,"['snapchat', 'chatgpt', 'powered', 'ai', 'wa_reported', 'lacking', 'safeguard', 'child', 'telling', 'user', 'tested', 'chatbot', 'pretending', 'sign', '13', 'year_old', 'girl', 'lie', 'parent', 'romantic', 'getaway', 'older', 'man', 'sharing', 'tip', 'cover', 'evidence', 'abuse']",SOCIAL HARM
529,540,"[3003,3093,3094,3096,3097]","A Tesla on FSD Beta 11.4.1 was shown on video not yielding to a pedestrian detected by the car, reportedly violating the state law sign which was also in the video saying vehicles having to yield to pedestrian within crosswalk.","Tesla Failed to Yield to Detected Pedestrian on Crosswalk, Reportedly Violated Traffic Law","['tesla', 'fsd', 'beta', '11', '4', '1', 'wa_shown', 'video', 'yielding', 'pedestrian', 'detected', 'car', 'reportedly', 'violating', 'state', 'law', 'sign', 'wa', 'also', 'video', 'saying', 'vehicle', 'yield', 'pedestrian', 'within', 'crosswalk']",SECURITY AND SAFETY
530,541,"[3005,3006,3007,3008,3009,3010,3011,3014,3015,3016,3017,3018,3019,3020,3021,3022,3023,3024,3025,3026,3027,3028,3029,3030,3031,3032,3033,3034,3036,3037,3038,3039,3040,3041,3042,3043,3044,3045,3046,3047,3048,3049,3050,3051,3052,3053,3054,3055,3056,3057,3098,3116,3149,3150,3151,3155,3181,3183]","A lawyer in Mata v. Avianca, Inc. used ChatGPT for research. ChatGPT hallucinated court cases, which the lawyer then presented in court. The court determined the cases did not exist.",ChatGPT Reportedly Produced False Court Case Law Presented by Legal Counsel in Court,"['lawyer', 'mata', 'v', 'avianca', 'inc', 'used', 'chatgpt', 'research', 'chatgpt', 'hallucinated', 'court', 'case', 'lawyer', 'presented', 'court', 'court', 'determined', 'case', 'exist']",OPERATIONAL INCIDENT
531,543,"[3035,3058,3059,3060,3061,3062,3063,3064,3065,3066,3067,3068,3069,3070,3071,3072,3099]",An apparent deepfake image posted by a false Bloomberg news account to Twitter depicted an explosion near the pentagon office complex near Washington DC.,Deepfake of Explosion Near US Military Administration Building Reportedly Causes Stock Dip,"['apparent', 'deepfake', 'image', 'posted', 'false', 'bloomberg', 'news', 'account', 'twitter', 'depicted', 'explosion', 'near', 'pentagon', 'office', 'complex', 'near', 'washington', 'dc']",SOCIAL HARM
532,544,"[3073,3074,3075,3076,3077,3078,3079,3080,3081,3082,3083,3084,3085,3086,3087,3088,3089,3090,3091,3092,3095,3100]",Allegations of deepfake technology and AI-generated disinformation have been swirling around the events of the 2023 presidential elections in Turkey.,Deepfakes and AI-generated disinformation in the 2023 presidential elections of Turkey,"['allegation', 'deepfake', 'technology', 'ai_generated', 'disinformation', 'swirling', 'around', 'event', '2023', 'presidential_election', 'turkey']",SOCIAL HARM
533,545,"[3103,3104,3105,3106,3107,3108,3109,3110,3111,3112,3113,3114,3115,3117,3118,3119,3120,3121,3122,3123,3124,3125,3126,3127,3128,3129,3130,3131,3132,3133,3134,3135,3136,3137,3138,3139,3140,3141,3142,3143,3144,3145,3146,3147,3148,3153]","The National Eating Disorders Association (NEDA) has shut down its chatbot named Tessa after it gave weight-loss advice to users seeking help for eating disorders. The incident has raised concerns about the risks of using chatbots and AI assistants in healthcare settings, particularly in addressing sensitive issues like eating disorders. NEDA is investigating the matter, emphasizing the need for caution and accuracy when utilizing technology to provide mental health support.",Chatbot Tessa gives unauthorized diet advice to users seeking help for eating disorders,"['national', 'eating_disorder', 'association', 'neda', 'ha', 'shut', 'chatbot', 'named', 'tessa', 'gave', 'weight', 'loss', 'advice', 'user', 'seeking', 'help', 'eating_disorder', 'incident_ha', 'raised_concern', 'risk', 'using', 'chatbots', 'ai', 'assistant', 'healthcare', 'setting', 'particularly', 'addressing', 'sensitive', 'issue', 'like', 'eating_disorder', 'neda', 'investigating', 'matter', 'emphasizing', 'need', 'caution', 'accuracy', 'utilizing', 'technology', 'provide', 'mental_health', 'support']",SOCIAL HARM
534,546,"[3159,3161,3162]","Takaful cash transfer program's algorithm which ranks families by their economic vulnerability level to determine financial assistance reportedly oversimplified people's economic situation, fueling social tension and perceptions of unfairness.",Algorithm to Distribute Social Welfare Reported for Oversimplifying Economic Vulnerability,"['takaful', 'cash', 'transfer', 'program', 'algorithm', 'rank', 'family', 'economic', 'vulnerability', 'level', 'determine', 'financial', 'assistance', 'reportedly', 'oversimplified', 'people', 'economic', 'situation', 'fueling', 'social', 'tension', 'perception', 'unfairness']",SOCIAL HARM
535,547,[3160],"Ron DeSantis’s presidential campaign shared a video on Twitter featuring some AI-generated images of Donald Trump hugging former White House coronavirus advisor Anthony Fauci, allegedly as a smear campaign.",Ron DeSantis's Campaign Released Twitter Video Containing AI Images to Smear Donald Trump,"['ron', 'desantis', 'presidential', 'campaign', 'shared', 'video', 'twitter', 'featuring', 'ai_generated', 'image', 'donald', 'trump', 'hugging', 'former', 'white', 'house', 'coronavirus', 'advisor', 'anthony', 'fauci', 'allegedly', 'smear', 'campaign']",SOCIAL HARM
536,548,[3163],"When prompted about ""photographers accused of committing war crimes,"" Opera's GPT-based chatbot Aria provided a list of photographers who take photography of military conflicts.",Opera's GPT-Based AI Reportedly Accused War Photographers of War Crimes,"['prompted', 'photographer', 'accused', 'committing', 'war', 'crime', 'opera', 'gpt', 'based', 'chatbot', 'aria', 'provided', 'list', 'photographer', 'take', 'photography', 'military', 'conflict']",OPERATIONAL INCIDENT
537,549,[3164],"McDonald's, Wendy's, and Hardee's AI chatbots deployed to pre-screen job candidates and schedule interviews reportedly ran into issues such as not giving useful submission instructions, failing to relay information to the manager, and scheduling an interview when the manager was not available.",Fast Food Chains' AI Chatbots Failed to Assist Job Applicants with Scheduling Interviews,"['mcdonald', 'wendy', 'hardee', 'ai', 'chatbots', 'deployed', 'pre', 'screen', 'job', 'candidate', 'schedule', 'interview', 'reportedly', 'ran', 'issue', 'giving', 'useful', 'submission', 'instruction', 'failing', 'relay', 'information', 'manager', 'scheduling', 'interview', 'manager', 'wa', 'available']",OPERATIONAL INCIDENT
538,550,"[3165,3166]","A 17-year-old student in Hollister, North Carolina who exited the school bus and was walking across the street to his house was hit by a 2022 Tesla Model Y allegedly operating on Autopilot mode, suffering a fractured neck and a broken leg.",Tesla Allegedly on Autopilot Struck High School Student Exiting School Bus,"['17', 'year_old', 'student', 'hollister', 'north', 'carolina', 'exited', 'school', 'bus', 'wa', 'walking', 'across', 'street', 'house', 'wa', 'hit', '2022', 'tesla_model', 'allegedly', 'operating_autopilot', 'mode', 'suffering', 'fractured', 'neck', 'broken', 'leg']",SECURITY AND SAFETY
539,551,"[3168,3170]","The FBI reported an increase in sextortion cases featuring the use of fake, including AI-generated, images or videos created from content posted on their social media sites or web postings, provided to the malicious actor upon request, or captured during video chats.",FBI Reported Surge of Extortion Cases of AI Media Featuring Sexual Explicit Activities,"['fbi', 'reported', 'increase', 'sextortion', 'case', 'featuring', 'use', 'fake', 'including', 'ai_generated', 'image', 'video', 'created', 'content', 'posted', 'social_medium', 'site', 'web', 'posting', 'provided', 'malicious', 'actor', 'upon', 'request', 'captured', 'video', 'chat']",PRIVACY VIOLATION
540,552,[3169],Microsoft was reported by a Twitter user for deploying image analysis feature capable of solving CAPTCHAs for its GPT-based chatbot despite it being safeguarded against solving them for users.,Bing Chat Solved CAPTCHAs with Image Analysis Feature Despite Safeguards,"['microsoft', 'wa_reported', 'twitter', 'user', 'deploying', 'image', 'analysis', 'feature', 'capable', 'solving', 'captchas', 'gpt', 'based', 'chatbot', 'despite', 'safeguarded', 'solving', 'user']",SECURITY AND SAFETY
541,553,"[3171,3173]","Google's knowledge panel for the American artist Edward Hopper featured an AI-generated image which was purportedly created in the artist's style but was not one of his works, the image of which was removed soon after.",Google's Overview Panel for Artist Edward Hopper Featured Image Generated in His Style by AI,"['google', 'knowledge', 'panel', 'american', 'artist', 'edward', 'hopper', 'featured', 'ai_generated', 'image', 'wa', 'purportedly', 'created', 'artist', 'style', 'wa', 'one', 'work', 'image', 'wa', 'removed', 'soon']",SOCIAL HARM
542,554,[3172],"Google's search engine featured an AI-generated hyperrealistic version of the painting ""Girl With a Pearl Earring"" as the highlighted result when users search for its Dutch artist Johannes Vermeer.",Google Results for Johannes Vermeer Featured AI Version of His Artwork as Top Result,"['google', 'search_engine', 'featured', 'ai_generated', 'hyperrealistic', 'version', 'painting', 'girl', 'pearl', 'earring', 'highlighted', 'result', 'user', 'search', 'dutch', 'artist', 'johannes', 'vermeer']",SOCIAL HARM
543,555,[3175],"Two authors alleged in a class action lawsuit OpenAI infringed authors' copyrights by incorporating illegal ""shadow libraries"" offering copyrighted books without permission in the training data of its generative LLMs, such as ChatGPT.",OpenAI's Training Data for LLMs Allegedly Comprised of Copyrighted Books,"['two', 'author', 'alleged_class', 'action_lawsuit', 'openai', 'infringed', 'author', 'copyright', 'incorporating', 'illegal', 'shadow', 'library', 'offering', 'copyrighted', 'book', 'without_permission', 'training_data', 'generative', 'llm', 'chatgpt']",PRIVACY VIOLATION
544,556,"[3177,3185,3186]",Amazon's retention of children' voice recordings indefinitely as the default setting reportedly to train Alexa's voice recognition for Alexa-enabled devices was charged by the FTC and DOJ to violate COPPA Rule.,Amazon Allegedly Violated Children's Privacy through Default Voice Collection Settings,"['amazon', 'retention', 'child', 'voice', 'recording', 'indefinitely', 'default', 'setting', 'reportedly', 'train', 'alexa', 'voice', 'recognition', 'alexa', 'enabled', 'device', 'wa', 'charged', 'ftc', 'doj', 'violate', 'coppa', 'rule']",PRIVACY VIOLATION
545,557,"[3178,3190,3191,3192]","Miami Police's arrest report for a George Floyd protestor did not disclose use of facial recognition, which allegedly did not meet the legal threshold for probable cause for arrest.",Miami Police Deployed Facial Recognition to Arrest George Floyd Protestor Allegedly without Cause,"['miami', 'police', 'arrest', 'report', 'george', 'floyd', 'protestor', 'disclose', 'use_facial', 'recognition', 'allegedly', 'meet', 'legal', 'threshold', 'probable', 'arrest']",SOCIAL HARM
546,558,"[3184,3188,3189]","Black Lives Matter activists alleged being targeted for arrest by New York Police using facial recognition, interfering with their right to protest.",Activists Allege NYPD's Application of Facial Recognition Interfered with Right to Protest,"['black', 'life', 'matter', 'activist', 'alleged', 'targeted', 'arrest', 'new_york', 'police', 'using', 'facial_recognition', 'interfering', 'right', 'protest']",SOCIAL HARM
547,559,[3193],"Peer reviewers of Australian government grant applications inserted applicants' work into generative AI systems such as ChatGPT to generate assessment reports, which allegedly posed confidentiality and security issues.","Grant Reviewers Fed Applications into Generative AI to Produce Reports, Allegedly Breaching Confidentiality","['peer', 'reviewer', 'australian', 'government', 'grant', 'application', 'inserted', 'applicant', 'work', 'generative_ai', 'system', 'chatgpt', 'generate', 'assessment', 'report', 'allegedly', 'posed', 'confidentiality', 'security', 'issue']",SOCIAL HARM
548,560,[3194],A 2016 Tesla on Autopilot crashed into the rear of a parked 2007 Freightliner truck providing traffic control on the Pennsylvania Turnpike highway.,Tesla on Autopilot Struck Parked Work Truck on Highway in Pennsylvania,"['2016', 'tesla_autopilot', 'crashed', 'rear', 'parked', '2007', 'freightliner', 'truck', 'providing', 'traffic', 'control', 'pennsylvania', 'turnpike', 'highway']",SECURITY AND SAFETY
549,561,"[3197,3199,3200]",OpenAI's products such as ChatGPT and DALL-E were alleged in a lawsuit using  stolen private information from internet users without their informed consent or knowledge.,OpenAI Alleged by Lawsuit Violated Users' Privacy Rights by Training AI on Private Info without Informed Consent,"['openai', 'product', 'chatgpt', 'dall_e', 'alleged_lawsuit', 'using', 'stolen', 'private', 'information', 'internet', 'user', 'without', 'informed', 'consent', 'knowledge']",PRIVACY VIOLATION
550,562,[3201],"A surge in low-standard AI-generated content such as by ChatGPT was reported by publishers, which negatively impacted submission management process and editors' workflow.",Uptick in Low-Quality AI-Produced Content Degraded Publishers' Submission Management,"['surge', 'low', 'standard', 'ai_generated', 'content', 'chatgpt', 'wa_reported', 'publisher', 'negatively', 'impacted', 'submission', 'management', 'process', 'editor', 'workflow']",SOCIAL HARM
551,563,[3208],"A stalled Cruise robotaxi blocked a San Francisco ambulance's path, delaying its transport of a critically injured pedestrian hit by a vehicle. The patient later died from their injuries.",Stalled Cruise robotaxi blocks path of ambulance carrying a patient who later died,"['stalled', 'cruise', 'robotaxi', 'blocked', 'san_francisco', 'ambulance', 'path', 'delaying', 'transport', 'critically', 'injured', 'pedestrian', 'hit', 'vehicle', 'patient', 'later', 'died', 'injury']",SECURITY AND SAFETY
552,564,[3209],"In spring 2023, Florida investor Clive Kabatznik became the target of an advanced scam attempt involving a voice deepfake mimicking his own voice. The fraudulent caller, using AI-generated speech, contacted Kabatznik's Bank of America representative in an unsuccessful attempt to deceive the banker into transferring funds to a different account.",Voice deepfake targets bank in failed transfer scam,"['spring', '2023', 'florida', 'investor', 'clive', 'kabatznik', 'became', 'target', 'advanced', 'scam', 'attempt', 'involving', 'voice', 'deepfake', 'mimicking', 'voice', 'fraudulent', 'caller', 'using', 'ai_generated', 'speech', 'contacted', 'kabatznik', 'bank', 'america', 'representative', 'unsuccessful', 'attempt', 'deceive', 'banker', 'transferring', 'fund', 'different', 'account']",SOCIAL HARM
553,565,"[3210,3211,3212,3213]","In a disinformation campaign concerning wildfires across Maui, Chinese operatives utilized AI-generated imagery to enhance the credibility of false narratives. These narratives claimed that the wildfires were the result of a secret ""weather weapon"" being tested by the United States. Researchers from Microsoft and other organizations identified these AI-generated images as a significant new tactic in influence operations.",AI-Generated Imagery and Multilingual Disinformation in Chinese Campaign Regarding Maui Wildfires,"['disinformation', 'campaign', 'concerning', 'wildfire', 'across', 'maui', 'chinese', 'operative', 'utilized', 'ai_generated', 'imagery', 'enhance', 'credibility', 'false', 'narrative', 'narrative', 'claimed', 'wildfire', 'result', 'secret', 'weather', 'weapon', 'tested', 'united', 'state', 'researcher', 'microsoft', 'organization', 'identified', 'ai_generated', 'image', 'significant', 'new', 'tactic', 'influence', 'operation']",SOCIAL HARM
554,566,[3214],"Gannett, a newspaper chain, temporarily halted its AI experiment that used a tool called LedeAI to generate high school sports articles. The decision came after several articles produced by the AI showed glaring errors, repetitive language, and awkward phrasing, drawing criticism and mockery on social media.",Gannett Halts AI-Generated High School Sports Articles After Series of Errors and Public Backlash,"['gannett', 'newspaper', 'chain', 'temporarily', 'halted', 'ai', 'experiment', 'used', 'tool', 'called', 'ledeai', 'generate', 'high_school', 'sport', 'article', 'decision', 'came', 'several', 'article', 'produced', 'ai', 'showed', 'glaring', 'error', 'repetitive', 'language', 'awkward', 'phrasing', 'drawing', 'criticism', 'mockery', 'social_medium']",OPERATIONAL INCIDENT
555,567,[3215],"In August 2023, a hacker reportedly was successful in breaching Retool, an IT company specializing in business software solutions, impacting 27 cloud customers. The attacker appears to have initiated the breach by sending phishing SMS messages to employees and later used an AI-generated deepfake voice in a phone call to obtain multi-factor authentication codes. The breach seems to have exposed vulnerabilities in Google's Authenticator app, specifically its cloud-syncing function, further enabling unauthorized access to internal systems.",Deepfake Voice Exploit Compromises Retool's Cloud Services,"['august', '2023', 'hacker', 'reportedly', 'wa', 'successful', 'breaching', 'retool', 'company', 'specializing', 'business', 'software', 'solution', 'impacting', '27', 'cloud', 'customer', 'attacker', 'appears', 'initiated', 'breach', 'sending', 'phishing', 'sm', 'message', 'employee', 'later', 'used', 'ai_generated', 'deepfake', 'voice', 'phone', 'call', 'obtain', 'multi', 'factor', 'authentication', 'code', 'breach', 'seems', 'exposed', 'vulnerability', 'google', 'authenticator', 'app', 'specifically', 'cloud', 'syncing', 'function', 'enabling', 'unauthorized', 'access', 'internal', 'system']",OPERATIONAL INCIDENT
